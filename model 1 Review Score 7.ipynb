{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fix the date because when Pandas opens the file it reads it incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Date'] = df['Review_Date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))\n",
    "df['Review_Month'] = df.Review_Month.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 74), (10000,), (10000, 74), (10000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.5958 | 0.1918\n",
      "Train: 0.7346 | 0.4689\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6537 | 0.3075\n",
      "Train: 0.6726 | 0.3452\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6474 | 0.2947\n",
      "Train: 0.6613 | 0.3234\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6514 | 0.3030\n",
      "Train: 0.6713 | 0.3422\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6537 | 0.3076\n",
      "Train: 0.6644 | 0.3280\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6416 | 0.2838\n",
      "Train: 0.6493 | 0.2962\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6494 | 0.2988\n",
      "Train: 0.6868 | 0.3737\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6472 | 0.2946\n",
      "Train: 0.6410 | 0.2815\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST logistic   knn   xgb   gbt    rf   svm  tree    nb\n",
       "0  Good      Bad   Bad   Bad   Bad   Bad   Bad  Good   Bad\n",
       "1   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad  Good\n",
       "2   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "3  Good     Good  Good  Good  Good   Bad  Good  Good   Bad\n",
       "4   Bad     Good  Good  Good  Good  Good  Good  Good  Good"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508691</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249556</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic  gbt   knn  svm  tree  xgb    nb   rf\n",
       "508691      Bad  Bad   Bad  Bad  Good  Bad   Bad  Bad\n",
       "249556      Bad  Bad  Good  Bad   Bad  Bad  Good  Bad"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Test : 0.6655 | 0.3312\n",
      "Train: 0.6591 | 0.3183\n",
      "----------------------\n",
      "XGB\n",
      "Test : 0.6605 | 0.3215\n",
      "Train: 0.6611 | 0.3220\n",
      "----------------------\n",
      "GBT\n",
      "Test : 0.6580 | 0.3165\n",
      "Train: 0.6575 | 0.3150\n",
      "----------------------\n",
      "Logistic\n",
      "Test : 0.6670 | 0.3345\n",
      "Train: 0.6558 | 0.3115\n",
      "----------------------\n",
      "SVM\n",
      "Test : 0.6660 | 0.3322\n",
      "Train: 0.6705 | 0.3412\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 90, max_depth = 4, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 2, max_depth=4, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    f1 = f1_score(prediccion, y_test, pos_label='Bad')\n",
    "    return(variable, acc_score, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Original Score: 0.667 | New score: 0.6675 | Variable to remove: Length_Recode_Stayed 8 nights\n",
      "1 Original Score: 0.6675 | New score: 0.6695 | Variable to remove: gbt\n",
      "2 Original Score: 0.6695 | New score: 0.6715 | Variable to remove: Length_Recode_Stayed 6 nights\n",
      "3 Original Score: 0.6715 | New score: 0.672 | Variable to remove: Review_Month_2\n",
      "4 Original Score: 0.672 | New score: 0.673 | Variable to remove: City_Barcelona\n",
      "5 Original Score: 0.673 | New score: 0.6755 | Variable to remove: Review_Month_4\n",
      "6 Original Score: 0.6755 | New score: 0.6765 | Variable to remove: Room_Recode_Suite\n",
      "7 Original Score: 0.6765 | New score: 0.677 | Variable to remove: Review_Month_3\n",
      "8 Original Score: 0.677 | New score: 0.678 | Variable to remove: food_Neg_Hotel\n",
      "9 Original Score: 0.678 | New score: 0.6785 | Variable to remove: Close_Landmarks\n",
      "10 Original Score: 0.6785 | New score: 0.6795 | Variable to remove: Length_Recode_Stayed 2 nights\n",
      "11 Original Score: 0.6795 | New score: 0.68 | Variable to remove: Room_Recode_Executive\n",
      "12 Original Score: 0.68 | New score: 0.6805 | Variable to remove: Dist_Train\n",
      "End of process\n"
     ]
    }
   ],
   "source": [
    "score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]   # 1=Accuracy | 2=F1\n",
    "varout = []\n",
    "varin = list(X_test_2.columns)\n",
    "\n",
    "for n in range(len(varin)):\n",
    "    max_score = score\n",
    "    max_feature = []\n",
    "    \n",
    "    random.seed(6) # 6 (0.6805)\n",
    "    for i in sample(varin, len(varin)):\n",
    "        var_test = varin.copy()\n",
    "        var_test.remove(i)\n",
    "        X_train_vartest = X_train_2[var_test]\n",
    "        X_test_vartest = X_test_2[var_test]\n",
    "        check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "        if check[1] > max_score:      # 1=Accuracy | 2=F1\n",
    "            max_feature = check[0]\n",
    "            max_score = check[1]      # 1=Accuracy | 2=F1\n",
    "            varin.remove(max_feature)   \n",
    "            varout.append(max_feature)\n",
    "            print(n, 'Original Score:', score, '| New score:', max_score, '| Variable to remove:', max_feature)\n",
    "            break\n",
    "    \n",
    "    if max_score > score:\n",
    "        score = max_score\n",
    "    else:\n",
    "        print('End of process')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 15.,  41.,  50.,  84., 104., 139., 129., 128., 168., 132., 149.,\n",
       "        144., 147., 141., 112., 114.,  72.,  60.,  55.,  16.]),\n",
       " array([0.05354644, 0.0963721 , 0.13919776, 0.18202342, 0.22484908,\n",
       "        0.26767474, 0.3105004 , 0.35332606, 0.39615172, 0.43897738,\n",
       "        0.48180304, 0.5246287 , 0.56745436, 0.61028003, 0.65310569,\n",
       "        0.69593135, 0.73875701, 0.78158267, 0.82440833, 0.86723399,\n",
       "        0.91005965]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>701</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>288</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       701   351\n",
       "Good      288   660"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6805 <- Accuracy\n",
      "0.3614 <- Kappa\n",
      "0.6869 <- F1\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(prediction, y_test_2):.4f}', '<- Accuracy')\n",
    "print(f'{cohen_kappa_score(prediction, y_test_2):.4f}', '<- Kappa')\n",
    "print(f'{f1_score(prediction, y_test_2, pos_label=\"Bad\"):.4f}', '<- F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.40 Accuracy: 0.6420 Kappa: 0.2871 F1: 0.6992 Avg: 0.6706\n",
      "Threshold: 0.41 Accuracy: 0.6430 Kappa: 0.2888 F1: 0.6964 Avg: 0.6697\n",
      "Threshold: 0.42 Accuracy: 0.6520 Kappa: 0.3065 F1: 0.7000 Avg: 0.6760\n",
      "Threshold: 0.43 Accuracy: 0.6600 Kappa: 0.3222 F1: 0.7018 Avg: 0.6809\n",
      "Threshold: 0.44 Accuracy: 0.6605 Kappa: 0.3230 F1: 0.6984 Avg: 0.6794\n",
      "Threshold: 0.45 Accuracy: 0.6605 Kappa: 0.3227 F1: 0.6940 Avg: 0.6773\n",
      "Threshold: 0.46 Accuracy: 0.6655 Kappa: 0.3324 F1: 0.6927 Avg: 0.6791\n",
      "Threshold: 0.47 Accuracy: 0.6655 Kappa: 0.3321 F1: 0.6878 Avg: 0.6767\n",
      "Threshold: 0.48 Accuracy: 0.6685 Kappa: 0.3378 F1: 0.6850 Avg: 0.6768\n",
      "Threshold: 0.49 Accuracy: 0.6715 Kappa: 0.3436 F1: 0.6831 Avg: 0.6773\n",
      "Threshold: 0.50 Accuracy: 0.6805 Kappa: 0.3614 F1: 0.6869 Avg: 0.6837\n",
      "Threshold: 0.51 Accuracy: 0.6815 Kappa: 0.3631 F1: 0.6826 Avg: 0.6821\n",
      "Threshold: 0.52 Accuracy: 0.6735 Kappa: 0.3469 F1: 0.6687 Avg: 0.6711\n",
      "Threshold: 0.53 Accuracy: 0.6670 Kappa: 0.3336 F1: 0.6553 Avg: 0.6611\n",
      "Threshold: 0.54 Accuracy: 0.6580 Kappa: 0.3154 F1: 0.6419 Avg: 0.6499\n",
      "Threshold: 0.55 Accuracy: 0.6600 Kappa: 0.3192 F1: 0.6375 Avg: 0.6488\n",
      "Threshold: 0.56 Accuracy: 0.6570 Kappa: 0.3129 F1: 0.6288 Avg: 0.6429\n",
      "Threshold: 0.57 Accuracy: 0.6540 Kappa: 0.3066 F1: 0.6168 Avg: 0.6354\n",
      "Threshold: 0.58 Accuracy: 0.6525 Kappa: 0.3033 F1: 0.6080 Avg: 0.6303\n",
      "Threshold: 0.59 Accuracy: 0.6515 Kappa: 0.3010 F1: 0.5964 Avg: 0.6240\n"
     ]
    }
   ],
   "source": [
    "prob_bad = probability[:,0]\n",
    "for thr in np.arange(0.4, 0.6, 0.01):\n",
    "    classification = ['Bad' if i > thr else 'Good' for i in prob_bad]\n",
    "    accuracy = accuracy_score(classification, y_test_2)\n",
    "    kappa = cohen_kappa_score(classification, y_test_2)\n",
    "    f1 = f1_score(classification, y_test_2, pos_label='Bad')\n",
    "    avg =np.mean([accuracy, f1])\n",
    "    print('Threshold:', f'{thr:.2f}', 'Accuracy:', f'{accuracy:.4f}', 'Kappa:', f'{kappa:.4f}', 'F1:', f'{f1:.4f}', \n",
    "          'Avg:', f'{avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 4, max_depth=5, random_state=1))]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    prob_stck_2 = clf.predict_proba(X_test_2)\n",
    "\n",
    "    pred[i[0]] = pred_stck_2\n",
    "    prob[i[0]] = prob_stck_2[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test_2):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test_2):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
