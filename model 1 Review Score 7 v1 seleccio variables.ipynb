{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode',\n",
    "                 'Stars']\n",
    "x_numerical = ['Total_Number_of_Reviews_Reviewer_Has_Given', 'food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', \n",
    "               'value_Neg_Hotel','comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 62), (10000,), (10000, 62), (10000,))"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6036 | 0.2074\n",
      "Train: 0.7271 | 0.4539\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6516 | 0.3033\n",
      "Train: 0.6733 | 0.3465\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6480 | 0.2959\n",
      "Train: 0.6620 | 0.3248\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6517 | 0.3035\n",
      "Train: 0.6713 | 0.3425\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6560 | 0.3122\n",
      "Train: 0.6635 | 0.3262\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6416 | 0.2838\n",
      "Train: 0.6493 | 0.2962\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6526 | 0.3053\n",
      "Train: 0.6686 | 0.3370\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6452 | 0.2906\n",
      "Train: 0.6389 | 0.2774\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST logistic   knn   xgb   gbt    rf   svm  tree    nb\n",
       "0  Good      Bad   Bad   Bad   Bad   Bad   Bad  Good   Bad\n",
       "1   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad  Good\n",
       "2   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "3  Good     Good  Good  Good  Good   Bad  Good  Good   Bad\n",
       "4   Bad     Good  Good  Good  Good  Good  Good  Good  Good"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1)),\n",
    "           ('GBT', GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))\n",
    "          ]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_ens = clf.predict(X_train)\n",
    "    pred_ens = clf.predict(X_test)\n",
    "    prob_ens = clf.predict_proba(X_test)\n",
    "\n",
    "    pred[i[0]] = pred_ens\n",
    "    prob[i[0]] = prob_ens[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.6540 | 0.3081\n"
     ]
    }
   ],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test):.4f}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508691</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249556</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic  gbt   knn  svm  tree  xgb    nb   rf\n",
       "508691      Bad  Bad   Bad  Bad  Good  Bad   Bad  Bad\n",
       "249556      Bad  Bad  Good  Bad   Bad  Bad  Good  Bad"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Test : 0.6630 | 0.3262\n",
      "Train: 0.6669 | 0.3338\n",
      "----------------------\n",
      "XGB\n",
      "Test : 0.6605 | 0.3213\n",
      "Train: 0.6629 | 0.3257\n",
      "----------------------\n",
      "GBT\n",
      "Test : 0.6635 | 0.3277\n",
      "Train: 0.6562 | 0.3122\n",
      "----------------------\n",
      "Logistic\n",
      "Test : 0.6700 | 0.3404\n",
      "Train: 0.6562 | 0.3125\n",
      "----------------------\n",
      "SVM\n",
      "Test : 0.6600 | 0.3201\n",
      "Train: 0.6595 | 0.3191\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 2, max_depth=4, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reserva = 0.58\n",
    "Distancia = 0.61\n",
    "Avg.Score = 0.64\n",
    "Hotel = 0.65\n",
    "Describe = 0.65\n",
    "\n",
    "Hotel + Describe = 0.65x\n",
    "Hotel + Distancia = 0.65\n",
    "Hotel + Avg.Score = 0.65\n",
    "Hotel + Reserva = 0.66\n",
    "\n",
    "Describe + Reserva  = 0.66\n",
    "Describe + Distancia = 0.65\n",
    "Describe + Avg.Score = 0.66\n",
    "\n",
    "Avg.Score + Reserva = 0.67\n",
    "Avg.Score + Distancia = 0.64x\n",
    "\n",
    "Describe + Reserva + Hotel = 0.67\n",
    "Avg.Score + Reserva + Hotel = 0.66x\n",
    "Avg.Score + Reserva + Describe = 0.66\n",
    "Avg.Score + Distancia + Hotel = 0.66\n",
    "Reserva + Describe + Distancia  = 0.65x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    f1 = f1_score(prediccion, y_test, pos_label='Bad')\n",
    "    return(variable, acc_score, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=False):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          '| Variable to remove:', max_feature)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', score)\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.6795\n",
      "Seed: 1 <- 0.683\n",
      "Seed: 2 <- 0.6785\n",
      "Seed: 3 <- 0.677\n",
      "Seed: 4 <- 0.673\n",
      "Seed: 5 <- 0.678\n",
      "Seed: 6 <- 0.682\n",
      "Seed: 7 <- 0.682\n",
      "Seed: 8 <- 0.68\n",
      "Seed: 9 <- 0.6815\n",
      "Seed: 10 <- 0.6785\n",
      "Seed: 11 <- 0.6815\n",
      "Seed: 12 <- 0.678\n",
      "Seed: 13 <- 0.6795\n",
      "Seed: 14 <- 0.6815\n",
      "Seed: 15 <- 0.6755\n",
      "Seed: 16 <- 0.6815\n",
      "Seed: 17 <- 0.692\n",
      "Seed: 18 <- 0.678\n",
      "Seed: 19 <- 0.6815\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "varin = []\n",
    "for seed in range(20):\n",
    "    vartest, score = try_seed(seed)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        varin = vartest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 70)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(varin), len(X_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)  \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 27.,  50.,  58.,  89., 105., 120., 114., 157., 137., 150., 138.,\n",
       "        134., 144., 165., 121.,  95.,  85.,  60.,  42.,   9.]),\n",
       " array([0.06931097, 0.11124704, 0.15318311, 0.19511918, 0.23705525,\n",
       "        0.27899132, 0.32092739, 0.36286346, 0.40479953, 0.4467356 ,\n",
       "        0.48867167, 0.53060774, 0.57254381, 0.61447988, 0.65641595,\n",
       "        0.69835202, 0.74028809, 0.78222416, 0.82416023, 0.8660963 ,\n",
       "        0.90803237]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>709</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>280</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       709   336\n",
       "Good      280   675"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6920 <- Accuracy\n",
      "0.3843 <- Kappa\n",
      "0.6971 <- F1\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(prediction, y_test_2):.4f}', '<- Accuracy')\n",
    "print(f'{cohen_kappa_score(prediction, y_test_2):.4f}', '<- Kappa')\n",
    "print(f'{f1_score(prediction, y_test_2, pos_label=\"Bad\"):.4f}', '<- F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.40 | Accuracy: 0.6515 | Kappa: 0.3059 | F1: 0.7050 | Avg: 0.6783\n",
      "Threshold: 0.41 | Accuracy: 0.6590 | Kappa: 0.3205 | F1: 0.7070 | Avg: 0.6830\n",
      "Threshold: 0.42 | Accuracy: 0.6590 | Kappa: 0.3203 | F1: 0.7030 | Avg: 0.6810\n",
      "Threshold: 0.43 | Accuracy: 0.6625 | Kappa: 0.3270 | F1: 0.7009 | Avg: 0.6817\n",
      "Threshold: 0.44 | Accuracy: 0.6650 | Kappa: 0.3318 | F1: 0.6998 | Avg: 0.6824\n",
      "Threshold: 0.45 | Accuracy: 0.6695 | Kappa: 0.3405 | F1: 0.6994 | Avg: 0.6845\n",
      "Threshold: 0.46 | Accuracy: 0.6690 | Kappa: 0.3393 | F1: 0.6944 | Avg: 0.6817\n",
      "Threshold: 0.47 | Accuracy: 0.6735 | Kappa: 0.3480 | F1: 0.6936 | Avg: 0.6835\n",
      "Threshold: 0.48 | Accuracy: 0.6750 | Kappa: 0.3508 | F1: 0.6908 | Avg: 0.6829\n",
      "Threshold: 0.49 | Accuracy: 0.6810 | Kappa: 0.3625 | F1: 0.6912 | Avg: 0.6861\n",
      "Threshold: 0.50 | Accuracy: 0.6920 | Kappa: 0.3843 | F1: 0.6971 | Avg: 0.6946\n",
      "Threshold: 0.51 | Accuracy: 0.6855 | Kappa: 0.3711 | F1: 0.6853 | Avg: 0.6854\n",
      "Threshold: 0.52 | Accuracy: 0.6785 | Kappa: 0.3568 | F1: 0.6728 | Avg: 0.6756\n",
      "Threshold: 0.53 | Accuracy: 0.6740 | Kappa: 0.3476 | F1: 0.6618 | Avg: 0.6679\n",
      "Threshold: 0.54 | Accuracy: 0.6695 | Kappa: 0.3383 | F1: 0.6516 | Avg: 0.6605\n",
      "Threshold: 0.55 | Accuracy: 0.6660 | Kappa: 0.3310 | F1: 0.6405 | Avg: 0.6532\n",
      "Threshold: 0.56 | Accuracy: 0.6620 | Kappa: 0.3228 | F1: 0.6290 | Avg: 0.6455\n",
      "Threshold: 0.57 | Accuracy: 0.6595 | Kappa: 0.3175 | F1: 0.6202 | Avg: 0.6398\n",
      "Threshold: 0.58 | Accuracy: 0.6580 | Kappa: 0.3143 | F1: 0.6114 | Avg: 0.6347\n",
      "Threshold: 0.59 | Accuracy: 0.6535 | Kappa: 0.3050 | F1: 0.5992 | Avg: 0.6263\n"
     ]
    }
   ],
   "source": [
    "prob_bad = probability[:,0]\n",
    "for thr in np.arange(0.4, 0.6, 0.01):\n",
    "    classification = ['Bad' if i > thr else 'Good' for i in prob_bad]\n",
    "    accuracy = accuracy_score(classification, y_test_2)\n",
    "    kappa = cohen_kappa_score(classification, y_test_2)\n",
    "    f1 = f1_score(classification, y_test_2, pos_label='Bad')\n",
    "    avg =np.mean([accuracy, f1])\n",
    "    print('Threshold:', f'{thr:.2f}', '| Accuracy:', f'{accuracy:.4f}', '| Kappa:', f'{kappa:.4f}', '| F1:', f'{f1:.4f}', \n",
    "          '| Avg:', f'{avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
