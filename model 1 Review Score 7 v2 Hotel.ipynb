{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Britannia International Hotel Canary Wharf           4789\n",
       "Strand Palace Hotel                                  4256\n",
       "Park Plaza Westminster Bridge London                 4169\n",
       "Copthorne Tara Hotel London Kensington               3578\n",
       "DoubleTree by Hilton Hotel London Tower of London    3212\n",
       "Name: Hotel_Name, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Hotel_Name.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Hotel = df[df.Hotel_Name=='Britannia International Hotel Canary Wharf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4789.000000\n",
       "mean        6.826644\n",
       "std         2.025480\n",
       "min         2.500000\n",
       "25%         5.400000\n",
       "50%         7.100000\n",
       "75%         8.300000\n",
       "max        10.000000\n",
       "Name: Reviewer_Score, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Hotel.Reviewer_Score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    2512\n",
       "Bad     2277\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Hotel.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>facilities_Pos_Hotel</th>\n",
       "      <th>cleanliness_Pos_Hotel</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "      <td>512470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500.118391</td>\n",
       "      <td>8.397934</td>\n",
       "      <td>18.541864</td>\n",
       "      <td>2747.504902</td>\n",
       "      <td>17.765052</td>\n",
       "      <td>7.152272</td>\n",
       "      <td>8.395594</td>\n",
       "      <td>49.442439</td>\n",
       "      <td>2.823803</td>\n",
       "      <td>-0.002339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226761</td>\n",
       "      <td>0.194419</td>\n",
       "      <td>914.838874</td>\n",
       "      <td>-0.002339</td>\n",
       "      <td>1.497240</td>\n",
       "      <td>-5.588449</td>\n",
       "      <td>-0.795955</td>\n",
       "      <td>0.350036</td>\n",
       "      <td>1.192276</td>\n",
       "      <td>1.602178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>501.419262</td>\n",
       "      <td>0.549133</td>\n",
       "      <td>29.693695</td>\n",
       "      <td>2322.698454</td>\n",
       "      <td>21.789025</td>\n",
       "      <td>11.028943</td>\n",
       "      <td>1.638170</td>\n",
       "      <td>3.466325</td>\n",
       "      <td>4.579425</td>\n",
       "      <td>1.525948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072677</td>\n",
       "      <td>0.059396</td>\n",
       "      <td>893.183937</td>\n",
       "      <td>0.121667</td>\n",
       "      <td>0.280036</td>\n",
       "      <td>0.694523</td>\n",
       "      <td>0.416756</td>\n",
       "      <td>0.221606</td>\n",
       "      <td>0.251901</td>\n",
       "      <td>0.548241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>41.328376</td>\n",
       "      <td>-0.369758</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-1.347368</td>\n",
       "      <td>0.427710</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>169.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1161.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>48.214662</td>\n",
       "      <td>-0.143372</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174028</td>\n",
       "      <td>0.152866</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>-0.066016</td>\n",
       "      <td>1.319523</td>\n",
       "      <td>-6.100000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>343.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2134.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>51.499981</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210412</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>1.512393</td>\n",
       "      <td>-5.700000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>666.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3633.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>51.516288</td>\n",
       "      <td>4.834443</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267637</td>\n",
       "      <td>0.231061</td>\n",
       "      <td>1154.000000</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>1.692351</td>\n",
       "      <td>-5.200000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2682.000000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>16670.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>52.400181</td>\n",
       "      <td>16.429233</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>0.762162</td>\n",
       "      <td>2.754280</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Additional_Number_of_Scoring  Average_Score  \\\n",
       "count                 512470.000000  512470.000000   \n",
       "mean                     500.118391       8.397934   \n",
       "std                      501.419262       0.549133   \n",
       "min                        1.000000       5.200000   \n",
       "25%                      169.000000       8.100000   \n",
       "50%                      343.000000       8.400000   \n",
       "75%                      666.000000       8.800000   \n",
       "max                     2682.000000       9.800000   \n",
       "\n",
       "       Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "count                      512470.000000            512470.000000   \n",
       "mean                           18.541864              2747.504902   \n",
       "std                            29.693695              2322.698454   \n",
       "min                             0.000000                43.000000   \n",
       "25%                             2.000000              1161.000000   \n",
       "50%                             9.000000              2134.000000   \n",
       "75%                            23.000000              3633.000000   \n",
       "max                           408.000000             16670.000000   \n",
       "\n",
       "       Review_Total_Positive_Word_Counts  \\\n",
       "count                      512470.000000   \n",
       "mean                           17.765052   \n",
       "std                            21.789025   \n",
       "min                             0.000000   \n",
       "25%                             5.000000   \n",
       "50%                            11.000000   \n",
       "75%                            22.000000   \n",
       "max                           395.000000   \n",
       "\n",
       "       Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "count                               512470.000000   512470.000000   \n",
       "mean                                     7.152272        8.395594   \n",
       "std                                     11.028943        1.638170   \n",
       "min                                      1.000000        2.500000   \n",
       "25%                                      1.000000        7.500000   \n",
       "50%                                      3.000000        8.800000   \n",
       "75%                                      8.000000        9.600000   \n",
       "max                                    355.000000       10.000000   \n",
       "\n",
       "                 lat            lng           Diff  ...  facilities_Pos_Hotel  \\\n",
       "count  512470.000000  512470.000000  512470.000000  ...         512470.000000   \n",
       "mean       49.442439       2.823803      -0.002339  ...              0.226761   \n",
       "std         3.466325       4.579425       1.525948  ...              0.072677   \n",
       "min        41.328376      -0.369758      -7.000000  ...              0.041667   \n",
       "25%        48.214662      -0.143372      -0.800000  ...              0.174028   \n",
       "50%        51.499981       0.010607       0.400000  ...              0.210412   \n",
       "75%        51.516288       4.834443       1.100000  ...              0.267637   \n",
       "max        52.400181      16.429233       3.600000  ...              0.698630   \n",
       "\n",
       "       cleanliness_Pos_Hotel          count           mean            std  \\\n",
       "count          512470.000000  512470.000000  512470.000000  512470.000000   \n",
       "mean                0.194419     914.838874      -0.002339       1.497240   \n",
       "std                 0.059396     893.183937       0.121667       0.280036   \n",
       "min                 0.000000       8.000000      -1.347368       0.427710   \n",
       "25%                 0.152866     312.000000      -0.066016       1.319523   \n",
       "50%                 0.186047     651.000000      -0.001136       1.512393   \n",
       "75%                 0.231061    1154.000000       0.077416       1.692351   \n",
       "max                 0.692308    4789.000000       0.762162       2.754280   \n",
       "\n",
       "                 min            25%            50%            75%  \\\n",
       "count  512470.000000  512470.000000  512470.000000  512470.000000   \n",
       "mean       -5.588449      -0.795955       0.350036       1.192276   \n",
       "std         0.694523       0.416756       0.221606       0.251901   \n",
       "min        -7.000000      -3.000000      -1.400000       0.100000   \n",
       "25%        -6.100000      -1.000000       0.200000       1.000000   \n",
       "50%        -5.700000      -0.800000       0.400000       1.200000   \n",
       "75%        -5.200000      -0.500000       0.500000       1.400000   \n",
       "max        -0.900000       0.400000       1.600000       2.300000   \n",
       "\n",
       "                 max  \n",
       "count  512470.000000  \n",
       "mean        1.602178  \n",
       "std         0.548241  \n",
       "min         0.200000  \n",
       "25%         1.200000  \n",
       "50%         1.600000  \n",
       "75%         1.900000  \n",
       "max         3.600000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = balance_df(df_Hotel, Balance_Nationality=False, Balance_Category=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode',\n",
    "                 'Stars']\n",
    "x_numerical = ['Total_Number_of_Reviews_Reviewer_Has_Given','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1198, 36), (1198,), (3591, 36), (3591,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-da8e83776d41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-158-4276dce249c9>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \"\"\"\n\u001b[0;32m   1129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-1381fb6b0265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_gbt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-158-4276dce249c9>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1439\u001b[0m         \u001b[1;31m# Since check_array converts both X and y to the same dtype, but the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.05, max_depth=5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.8667 | 0.0000\n",
      "Train: 0.8765 | 0.0000\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 100, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.8667 | 0.0000\n",
      "Train: 0.8775 | 0.0135\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.8677 | 0.0124\n",
      "Train: 0.8762 | -0.0006\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.8639 | 0.0047\n",
      "Train: 0.8775 | 0.0396\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.8667 | 0.0000\n",
      "Train: 0.8765 | 0.0000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.8648 | 0.0267\n",
      "Train: 0.8740 | 0.0321\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1)),\n",
    "           ('GBT', GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))\n",
    "          ]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_ens = clf.predict(X_train)\n",
    "    pred_ens = clf.predict(X_test)\n",
    "    prob_ens = clf.predict_proba(X_test)\n",
    "\n",
    "    pred[i[0]] = pred_ens\n",
    "    prob[i[0]] = prob_ens[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.5735 | 0.1407\n"
     ]
    }
   ],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test):.4f}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
