{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.City == 'Vienna']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.869305\n",
       "Bad     0.130695\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, Balance_Nationality, Balance_Category, cut):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = cut\n",
    "            if len(nationality) < n:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6672, 78)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_1 = balance_df(df, Balance_Nationality=False, Balance_Category=True, cut=10000)\n",
    "df_balanced_2 = balance_df(df_balanced_1, Balance_Nationality=True, Balance_Category=True, \n",
    "                         cut=int(np.median(df_balanced_1.Nationality_Recode.value_counts())*2))\n",
    "df_balanced_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UK & Ireland           1185\n",
       "Eastern Europe         1184\n",
       "Western Europe         1183\n",
       "Middle east            1014\n",
       "North America           806\n",
       "Asia & Pacific          591\n",
       "Oceania                 390\n",
       "South/Latin America     110\n",
       "Sub-Saharian Africa      83\n",
       "China                    75\n",
       "Arab States              51\n",
       "Name: Nationality_Recode, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_2.Nationality_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6672, 78)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df_balanced_2) > 20000:\n",
    "    df_model = df_balanced_2.sample(n=20000, random_state=1)\n",
    "else:\n",
    "    df_model = df_balanced_2.copy()\n",
    "\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode','Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model['Review_Month'] = df_model['Review_Month'].astype(str)\n",
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3336, 72), (3336,), (3336, 72), (3336,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random(model, params, iterations, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    clf = RandomizedSearchCV(estimator = model, param_distributions = params, n_iter = iterations, \n",
    "                             n_jobs = -1, cv = 5, random_state = 27, verbose = verbose)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grid(model, params, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    f1 = make_scorer(f1_score, pos_label = \"Bad\")\n",
    "    clf = GridSearchCV(estimator = model, param_grid = params, n_jobs = -1, cv = 5, verbose = verbose)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(clf.predict(X_test), y_test):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}')\n",
    "    print('Accuracy Train:', f'{accuracy_score(clf.predict(X_train), y_train):.4f}', \n",
    "          '| F1 Train:', f'{f1_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.6112 | F1 Test : 0.6175\n",
      "Accuracy Train: 0.7350 | F1 Train: 0.7386\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate_model(KNeighborsClassifier(n_neighbors=5), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 1, 'n_estimators': 192, 'min_samples_split': 0.28181818181818186, 'min_samples_leaf': 0.06444444444444444, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.05} 0.6540749086534576\n",
      "Accuracy Test : 0.6289 | F1 Test : 0.6449\n",
      "Accuracy Train: 0.6799 | F1 Train: 0.6935\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {'learning_rate':  [0.001, 0.0025, 0.005 , 0.01, 0.025, 0.05, 0.1], \n",
    "          'n_estimators': range(100, 200),\n",
    "          'max_depth': [2, 3, 4, 5],\n",
    "          'min_samples_split': np.linspace(0.1, 1.0, 100, endpoint=True),\n",
    "          'min_samples_leaf': np.linspace(0.01, 0.5, 100, endpoint=True), \n",
    "          'subsample': [1], \n",
    "          'max_features': ['sqrt']}\n",
    "\n",
    "pred_gbt = evaluate_random(GradientBoostingClassifier(), params, iterations, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_gbt = evaluate_model(GradientBoostingClassifier(n_estimators = 165, \n",
    "#                                                      min_samples_split = 0.6272727272727272, \n",
    "#                                                      min_samples_leaf = 0.11888888888888888, \n",
    "#                                                      max_depth = 2, learning_rate = 0.001),\n",
    "#                           X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 168, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'auto', 'max_depth': 5, 'bootstrap': True} 0.643880006104732\n",
      "Accuracy Test : 0.6331 | F1 Test : 0.6606\n",
      "Accuracy Train: 0.6727 | F1 Train: 0.6941\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': range(1, 10),\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_leaf': range(1, 10),\n",
    "          'min_samples_split': range(1, 10),\n",
    "          'n_estimators': range(100, 200)}\n",
    "\n",
    "pred_rf = evaluate_random(RandomForestClassifier(random_state = 1), params, iterations, \n",
    "                          X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_rf = evaluate_model(RandomForestClassifier(n_estimators = 153, min_samples_split = 5,  min_samples_leaf = 7,\n",
    "#                                                 max_features = 'auto', max_depth = 2, bootstrap = False, random_state=1), \n",
    "#                          X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.25, 'gamma': 0.75, 'colsample_bytree': 0.8} 0.6528750594762499\n",
      "Accuracy Test : 0.6358 | F1 Test : 0.6601\n",
      "Accuracy Train: 0.6721 | F1 Train: 0.6899\n"
     ]
    }
   ],
   "source": [
    "iterations = 250\n",
    "params = {\"learning_rate\"    : [0.0001, 0.005, 0.001, 0.005, 0.01, 0.05, 0.10, 0.25, 0.50],\n",
    "          \"max_depth\"        : [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          \"min_child_weight\" : [1, 3, 5, 10, 25, 50, 100, 250],\n",
    "          \"gamma\"            : [0.01, 0.05, 0.1, 0.15, 0.25, 0.50, 0.75, 0.95],\n",
    "          \"colsample_bytree\" : [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2],\n",
    "          \"n_estimators\"     : [2, 3, 5, 7, 10, 15, 25, 50, 100]}\n",
    "\n",
    "pred_xgb = evaluate_random(xgb.XGBClassifier(), params, iterations, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_xgb = evaluate_model(xgb.XGBClassifier(n_estimators = 7, min_child_weight = 5, max_depth = 3, learning_rate = 0.005,\n",
    "#                                             gamma = 0.05, colsample_bytree = 1, random_state = 1), \n",
    "#                     X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.025, 'tol': 1e-05} 0.6525779026654337\n",
      "Accuracy Test : 0.6406 | F1 Test : 0.6593\n",
      "Accuracy Train: 0.6643 | F1 Train: 0.6782\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\": [0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1],\n",
    "          \"tol\": [0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]}\n",
    "\n",
    "pred_log = evaluate_grid(LogisticRegression(solver = 'lbfgs', max_iter = 1000, random_state = 1), \n",
    "                         params, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_log = evaluate_model(LogisticRegression(C = 0.1, tol = 0.00001, solver='lbfgs', max_iter=1000, random_state=1), \n",
    "#                           X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 2, 'max_features': 10, 'max_depth': 4, 'criterion': 'gini'} 0.6453850918851951\n",
      "Accuracy Test : 0.6256 | F1 Test : 0.6564\n",
      "Accuracy Train: 0.6589 | F1 Train: 0.6842\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "params = {\"max_depth\": range(1, 10),\n",
    "          \"max_features\": range(1, 20),\n",
    "          \"min_samples_leaf\": range(1, 20),\n",
    "          \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "pred_tree = evaluate_random(DecisionTreeClassifier(random_state = 1), params, iterations, \n",
    "                            X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_tree = evaluate_model(DecisionTreeClassifier(min_samples_leaf = 4, max_features = 19, max_depth = 3, \n",
    "#                                                   criterion = 'entropy', random_state = 1), \n",
    "#                      X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'degree': 2, 'kernel': 'poly'} 0.6405838996669331\n",
      "Accuracy Test : 0.6148 | F1 Test : 0.6359\n",
      "Accuracy Train: 0.6628 | F1 Train: 0.6763\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": [2, 3, 4],\n",
    "          \"kernel\": ['poly'], \n",
    "          \"C\":      [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2.5, 5]}\n",
    "\n",
    "pred_svm = evaluate_grid(SVC(random_state = 1), params, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_svm = evaluate_model(SVC(kernel = 'poly', degree = 2, C = 0.005, random_state = 1), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'fit_prior': True} 0.6318945317760282\n",
      "Accuracy Test : 0.6283 | F1 Test : 0.6550\n",
      "Accuracy Train: 0.6403 | F1 Train: 0.6604\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\": [0.1, 0.25, 0.5, 1, 2.5, 5, 10], \n",
    "          \"fit_prior\": [True, False]}\n",
    "\n",
    "pred_nb = evaluate_grid(BernoulliNB(), params, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_nb = evaluate_model(BernoulliNB(alpha=0.25, fit_prior=True), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23336</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18635</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      logistic  gbt   knn  svm tree  xgb   nb   rf\n",
       "23336      Bad  Bad  Good  Bad  Bad  Bad  Bad  Bad\n",
       "18635      Bad  Bad   Bad  Bad  Bad  Bad  Bad  Bad"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 1, 'n_estimators': 103, 'min_samples_split': 0.9636363636363636, 'min_samples_leaf': 0.12878787878787878, 'max_features': 'sqrt', 'max_depth': 2, 'learning_rate': 0.05} 0.6367947663919162\n",
      "Accuracy Test : 0.6437 | F1 Test : 0.6610\n",
      "Accuracy Train: 0.6443 | F1 Train: 0.6607\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {'learning_rate':  [0.001, 0.0025, 0.005 , 0.01, 0.025, 0.05, 0.1], \n",
    "          'n_estimators': range(100, 200),\n",
    "          'max_depth': [2, 3, 4, 5],\n",
    "          'min_samples_split': np.linspace(0.1, 1.0, 100, endpoint=True),\n",
    "          'min_samples_leaf': np.linspace(0.01, 0.5, 100, endpoint=True), \n",
    "          'subsample': [1], \n",
    "          'max_features': ['sqrt']}\n",
    "          \n",
    "pred_gbt_stck = evaluate_random(GradientBoostingClassifier(random_state = 1), params, iterations, \n",
    "                                X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'min_child_weight': 100, 'max_depth': 9, 'learning_rate': 0.005, 'gamma': 0.95, 'colsample_bytree': 0.6} 0.6367968744510263\n",
      "Accuracy Test : 0.6452 | F1 Test : 0.6629\n",
      "Accuracy Train: 0.6372 | F1 Train: 0.6570\n"
     ]
    }
   ],
   "source": [
    "iterations = 250\n",
    "params = {\"learning_rate\"    : [0.0001, 0.005, 0.001, 0.005, 0.01, 0.05, 0.10, 0.25, 0.50],\n",
    "          \"max_depth\"        : [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          \"min_child_weight\" : [1, 3, 5, 10, 25, 50, 100, 250],\n",
    "          \"gamma\"            : [0.01, 0.05, 0.1, 0.15, 0.25, 0.50, 0.75, 0.95],\n",
    "          \"colsample_bytree\" : [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2],\n",
    "          \"n_estimators\"     : [2, 3, 5, 7, 10, 15, 25, 50, 100]}\n",
    "\n",
    "pred_xgb_stck = evaluate_random(xgb.XGBClassifier(random_state = 1), params, iterations, \n",
    "                                X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'degree': 2, 'kernel': 'poly'} 0.6285550660173844\n",
      "Accuracy Test : 0.6257 | F1 Test : 0.6676\n",
      "Accuracy Train: 0.6383 | F1 Train: 0.6801\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": [2, 3, 4],\n",
    "          \"kernel\": ['poly'], \n",
    "          \"C\":      [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2.5]}\n",
    "\n",
    "pred_svm_stck = evaluate_grid(SVC(random_state = 1), params, X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.025, 'tol': 1e-05} 0.6352938283056124\n",
      "Accuracy Test : 0.6542 | F1 Test : 0.6695\n",
      "Accuracy Train: 0.6522 | F1 Train: 0.6621\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\": [0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1],\n",
    "          \"tol\": [0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]}\n",
    "\n",
    "pred_log_stck = evaluate_grid(LogisticRegression(solver = 'lbfgs', max_iter = 1000, random_state = 1), \n",
    "                                params, X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 14, 'max_features': 17, 'max_depth': 2, 'criterion': 'entropy'} 0.6356796031227383\n",
      "Accuracy Test : 0.6482 | F1 Test : 0.6579\n",
      "Accuracy Train: 0.6417 | F1 Train: 0.6566\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "params = {\"max_depth\": range(1, 10),\n",
    "          \"max_features\": range(1, 20),\n",
    "          \"min_samples_leaf\": range(1, 20),\n",
    "          \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "pred_tree_stck = evaluate_random(DecisionTreeClassifier(random_state = 1), params, iterations, \n",
    "                                 X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKWARD ELIMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=True):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          end='\\r', flush=True)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', f'{score:.4f}','                                                                       ')\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver = 'lbfgs', max_iter = 1000, random_state = 1, tol = 0.00001, C = 0.025)     \n",
    "    clf.fit(X_train, y_train)\n",
    "    score = accuracy_score(clf.predict(X_train), y_train)\n",
    "    return(variable, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.6668                                                                        \n",
      "Seed: 1 <- 0.6623                                                                        \n",
      "Seed: 2 <- 0.6664                                                                        \n",
      "Seed: 3 <- 0.6653                                                                        \n",
      "Seed: 4 <- 0.6675                                                                        \n",
      "Seed: 5 <- 0.6619                                                                        \n",
      "Seed: 6 <- 0.6645                                                                        \n",
      "Seed: 7 <- 0.6660                                                                        \n",
      "Seed: 8 <- 0.6604                                                                        \n",
      "Seed: 9 <- 0.6638                                                                        \n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "var_selec = []\n",
    "for seed in range(10):\n",
    "    varin, score = try_seed(seed, verbose=True)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        var_selec = varin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.6752503576537912\n",
      "Accuracy:  0.6601796407185628\n",
      "Recall:    0.6685552407932012\n",
      "Precision: 0.6820809248554913\n"
     ]
    }
   ],
   "source": [
    "X_train_varin = X_train_2\n",
    "X_test_varin = X_test_2\n",
    "\n",
    "clf = LogisticRegression(solver = 'lbfgs', max_iter = 1000, random_state = 1, tol = 0.001, C = 0.05)\n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "print(\"F1-Score: \", f1_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Accuracy: \", accuracy_score(clf.predict(X_test_varin), y_test_2))\n",
    "print(\"Recall:   \", recall_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Precision:\", precision_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>236</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>110</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       236   117\n",
       "Good      110   205"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(clf.predict(X_test_varin), y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIDENCE INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\r"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "\n",
    "for i in range(10000):\n",
    "    sample = np.random.randint(0, len(X_test_varin), size=len(X_test_varin))\n",
    "    X_sample = X_test_varin.iloc[sample]\n",
    "    y_sample = y_test_2.iloc[sample]\n",
    "    print(i, end='\\r', flush=True)\n",
    "    predicciones.append(accuracy_score(clf.predict(X_sample), y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 2.000e+00, 5.000e+00,\n",
       "        1.400e+01, 3.100e+01, 5.400e+01, 1.420e+02, 1.910e+02, 2.670e+02,\n",
       "        4.990e+02, 5.040e+02, 7.270e+02, 1.147e+03, 9.270e+02, 1.024e+03,\n",
       "        1.253e+03, 8.220e+02, 7.110e+02, 6.920e+02, 3.680e+02, 2.710e+02,\n",
       "        1.770e+02, 8.400e+01, 5.200e+01, 2.000e+01, 6.000e+00, 7.000e+00]),\n",
       " array([0.57335329, 0.57834331, 0.58333333, 0.58832335, 0.59331337,\n",
       "        0.59830339, 0.60329341, 0.60828343, 0.61327345, 0.61826347,\n",
       "        0.62325349, 0.62824351, 0.63323353, 0.63822355, 0.64321357,\n",
       "        0.64820359, 0.65319361, 0.65818363, 0.66317365, 0.66816367,\n",
       "        0.67315369, 0.67814371, 0.68313373, 0.68812375, 0.69311377,\n",
       "        0.69810379, 0.70309381, 0.70808383, 0.71307385, 0.71806387,\n",
       "        0.72305389]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicciones, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6362649294245385, 0.6666666666666666, 0.6959826275787188)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(predicciones, 2.5), np.percentile(predicciones, 50), np.percentile(predicciones, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
