{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, Balance_Nationality, Balance_Category, cut):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = cut\n",
    "            if len(nationality) < n:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75780, 78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_1 = balance_df(df, Balance_Nationality=False, Balance_Category=True, cut=10000)\n",
    "df_balanced_2 = balance_df(df_balanced_1, Balance_Nationality=True, Balance_Category=True, \n",
    "                         cut=int(np.median(df_balanced_1.Nationality_Recode.value_counts())*1.5))\n",
    "df_balanced_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "North America          11538\n",
       "Western Europe         11519\n",
       "UK & Ireland           11513\n",
       "Middle east            11477\n",
       "Eastern Europe          8829\n",
       "Asia & Pacific          7680\n",
       "Oceania                 7604\n",
       "Sub-Saharian Africa     2058\n",
       "South/Latin America     1610\n",
       "China                   1099\n",
       "Arab States              853\n",
       "Name: Nationality_Recode, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_2.Nationality_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 78)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df_balanced_2) > 20000:\n",
    "    df_model = df_balanced_2.sample(n=20000, random_state=1)\n",
    "else:\n",
    "    df_model = df_balanced_2.copy()\n",
    "\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode','Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model['Review_Month'] = df_model['Review_Month'].astype(str)\n",
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 76), (10000,), (10000, 76), (10000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_score(X_train, y_train):\n",
    "    acc = accuracy_score(X_train, y_train)\n",
    "    f1 = f1_score(X_train, y_train, pos_label = \"Bad\")\n",
    "    return(2 / ((1/acc)+(1/f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(clf.predict(X_test), y_test):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Test :', f'{precision_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}')\n",
    "    \n",
    "    print('Accuracy Train:', f'{accuracy_score(clf.predict(X_train), y_train):.4f}', \n",
    "          '| F1 Train:', f'{f1_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Train:', f'{precision_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian(space, X, y, modelo, nevals):\n",
    "    \n",
    "    H = make_scorer(H_score, greater_is_better=True) \n",
    "        \n",
    "    def objective(space):\n",
    "        \n",
    "        global best_score\n",
    "        \n",
    "        model = modelo(**space)   \n",
    "        kfold = KFold(n_splits=5, random_state=1985, shuffle=True)\n",
    "        score = -cross_val_score(model, X, y, cv=kfold, scoring=H, verbose=False).mean()\n",
    "        if (score < best_score):\n",
    "            best_score = score\n",
    "        return score\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    best = fmin(\n",
    "      objective, \n",
    "      space = space,\n",
    "      algo = tpe.suggest, \n",
    "      max_evals = nevals,\n",
    "      trials = Trials())\n",
    "\n",
    "    print(\"Hyperopt search took %.2f seconds for 200 candidates\" % ((time.time() - start)))\n",
    "    print(\"Best score: %.4f \" % (-best_score))\n",
    "    print(\"Best space: \", space_eval(params, best))\n",
    "    return(space_eval(params, best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.5991 | F1 Test : 0.5987 | Precision Test : 0.5941\n",
      "Accuracy Train: 0.7382 | F1 Train: 0.7402 | Precision Train: 0.7410\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate_model(KNeighborsClassifier(n_neighbors=5), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [07:54<00:00,  9.50s/trial, best loss: -0.6673451742883656]\n",
      "Hyperopt search took 474.92 seconds for 200 candidates\n",
      "Best score: 0.6673 \n",
      "Best space:  {'learning_rate': 0.05, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 0.01, 'min_samples_split': 0.12, 'n_estimators': 150, 'subsample': 1}\n",
      "Accuracy Test : 0.6527 | F1 Test : 0.6593 | Precision Test : 0.6678\n",
      "Accuracy Train: 0.6996 | F1 Train: 0.7069 | Precision Train: 0.7197\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005 , 0.01, 0.025, \n",
    "                                                          0.05, 0.1]), \n",
    "          'n_estimators':      hp.choice('n_estimators', [25, 50, 75, 125, 150, 175, 200, 250, 300, 400, 500]),\n",
    "          'max_depth':         hp.choice('max_depth',[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16]),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train, y_train, GradientBoostingClassifier, 50)\n",
    "pred_gbt = evaluate_model(GradientBoostingClassifier(**gbt_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:44<00:00,  6.89s/trial, best loss: -0.6557532754299848]\n",
      "Hyperopt search took 344.57 seconds for 200 candidates\n",
      "Best score: 0.6558 \n",
      "Best space:  {'bootstrap': True, 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 0.09999999999999999, 'min_samples_split': 0.03, 'n_estimators': 25}\n",
      "Accuracy Test : 0.6443 | F1 Test : 0.6680 | Precision Test : 0.7109\n",
      "Accuracy Train: 0.6490 | F1 Train: 0.6739 | Precision Train: 0.7203\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap':         hp.choice('bootstrap',[True, False]),\n",
    "          'max_depth':         hp.choice('max_depth', range(1, 20)),\n",
    "          'max_features':      hp.choice('max_features',['auto', 'sqrt']),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'n_estimators':      hp.choice('n_estimators', [25, 50, 75, 125, 150, 175, 200, 250, 300, 400, 500])}\n",
    "\n",
    "best_score = 1\n",
    "rf_params = bayesian(params, X_train, y_train, RandomForestClassifier, 50)\n",
    "pred_rf = evaluate_model(RandomForestClassifier(**rf_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:56<00:00,  7.13s/trial, best loss: -0.6652896378794967]\n",
      "Hyperopt search took 356.82 seconds for 200 candidates\n",
      "Best score: 0.6653 \n",
      "Best space:  {'colsample_bytree': 0.44, 'gamma': 0.55, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 0.19, 'n_estimators': 20}\n",
      "Accuracy Test : 0.6500 | F1 Test : 0.6583 | Precision Test : 0.6698\n",
      "Accuracy Train: 0.6774 | F1 Train: 0.6885 | Precision Train: 0.7084\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005 , 0.01, 0.025, \n",
    "                                                          0.05, 0.1]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', [2, 5, 10, 15, 20, 25, 50, 75])}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train, y_train, xgb.XGBClassifier, 50)\n",
    "pred_xgb = evaluate_model(xgb.XGBClassifier(**xgb_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:09<00:00,  1.39s/trial, best loss: -0.6633365163147591]\n",
      "Hyperopt search took 69.44 seconds for 200 candidates\n",
      "Best score: 0.6633 \n",
      "Best space:  {'C': 0.01, 'tol': 0.0025}\n",
      "Accuracy Test : 0.6555 | F1 Test : 0.6566 | Precision Test : 0.6545\n",
      "Accuracy Train: 0.6670 | F1 Train: 0.6719 | Precision Train: 0.6772\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]),\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, \n",
    "                                  0.05, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train, y_train, LogisticRegression, 50)\n",
    "pred_log = evaluate_model(LogisticRegression(**log_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [02:01<00:00,  1.23trial/s, best loss: -0.6578514930402085]\n",
      "Hyperopt search took 121.76 seconds for 200 candidates\n",
      "Best score: 0.6579 \n",
      "Best space:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 44, 'min_samples_leaf': 49}\n",
      "Accuracy Test : 0.6427 | F1 Test : 0.6697 | Precision Test : 0.7198\n",
      "Accuracy Train: 0.6562 | F1 Train: 0.6841 | Precision Train: 0.7396\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {\"max_depth\":        hp.choice('max_depth', range(1, 20)),\n",
    "          \"max_features\":     hp.choice('max_features', range(1, 50)),\n",
    "          \"min_samples_leaf\": hp.choice('min_samples_leaf', range(1, 50)),\n",
    "          \"criterion\":        hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best_score = 1\n",
    "tree_params = bayesian(params, X_train, y_train, DecisionTreeClassifier, 150)\n",
    "pred_tree = evaluate_model(DecisionTreeClassifier(**tree_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [15:30<00:00, 93.02s/trial, best loss: -0.6639890021486339]\n",
      "Hyperopt search took 930.19 seconds for 200 candidates\n",
      "Best score: 0.6640 \n",
      "Best space:  {'C': 0.05, 'degree': 3, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.6369 | F1 Test : 0.6746 | Precision Test : 0.7477\n",
      "Accuracy Train: 0.6577 | F1 Train: 0.6958 | Precision Train: 0.7775\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train, y_train, SVC, 10)\n",
    "pred_svm = evaluate_model(SVC(**svm_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:28<00:00,  1.78s/trial, best loss: -0.644064389331181]\n",
      "Hyperopt search took 88.90 seconds for 200 candidates\n",
      "Best score: 0.6441 \n",
      "Best space:  {'alpha': 0.75, 'fit_prior': True}\n",
      "Accuracy Test : 0.6465 | F1 Test : 0.6391 | Precision Test : 0.6219\n",
      "Accuracy Train: 0.6457 | F1 Train: 0.6417 | Precision Train: 0.6301\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\":     hp.choice('alpha', [0.025, 0.05, 0.075, 0.1, 0.15, 0.20, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, \n",
    "                                           2, 2.5, 5, 10]), \n",
    "          \"fit_prior\": hp.choice('fit_prior', [True, False])}\n",
    "\n",
    "best_score = 1\n",
    "nb_params = bayesian(params, X_train, y_train, BernoulliNB, 50)\n",
    "pred_nb = evaluate_model(BernoulliNB(**nb_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333373</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127076</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic  gbt  knn  svm tree  xgb   nb   rf\n",
       "333373      Bad  Bad  Bad  Bad  Bad  Bad  Bad  Bad\n",
       "127076      Bad  Bad  Bad  Bad  Bad  Bad  Bad  Bad"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [07:40<00:00,  9.21s/trial, best loss: -0.6690185829609094]\n",
      "Hyperopt search took 460.72 seconds for 200 candidates\n",
      "Best score: 0.6690 \n",
      "Best space:  {'learning_rate': 0.001, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 0.05, 'min_samples_split': 0.45, 'n_estimators': 175, 'subsample': 1}\n",
      "Accuracy Test : 0.6495 | F1 Test : 0.6692 | Precision Test : 0.7309\n",
      "Accuracy Train: 0.6536 | F1 Train: 0.6799 | Precision Train: 0.7243\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005 , 0.01, 0.025, \n",
    "                                                          0.05, 0.1]), \n",
    "          'n_estimators':      hp.choice('n_estimators', [25, 50, 75, 125, 150, 175, 200, 250, 300, 400, 500]),\n",
    "          'max_depth':         hp.choice('max_depth',[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16]),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train_2, y_train_2, GradientBoostingClassifier, 50)\n",
    "pred_gbt_stck = evaluate_model(GradientBoostingClassifier(**gbt_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [12:48<00:00, 15.37s/trial, best loss: -0.6630783740403652]\n",
      "Hyperopt search took 769.11 seconds for 200 candidates\n",
      "Best score: 0.6631 \n",
      "Best space:  {'colsample_bytree': 0.03, 'gamma': 0.55, 'learning_rate': 0.00025, 'max_depth': 3, 'min_child_weight': 0.03, 'n_estimators': 75}\n",
      "Accuracy Test : 0.6545 | F1 Test : 0.6654 | Precision Test : 0.7082\n",
      "Accuracy Train: 0.6589 | F1 Train: 0.6757 | Precision Train: 0.6997\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':    hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005 , 0.01, 0.025, \n",
    "                                                         0.05, 0.1]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', [2, 5, 10, 15, 20, 25, 50, 75])}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train_2, y_train_2, xgb.XGBClassifier, 50)\n",
    "pred_xgb_stck = evaluate_model(xgb.XGBClassifier(**xgb_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [09:57<00:00, 59.79s/trial, best loss: -0.6696341628674858]\n",
      "Hyperopt search took 597.93 seconds for 200 candidates\n",
      "Best score: 0.6696 \n",
      "Best space:  {'C': 0.05, 'degree': 2, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.6465 | F1 Test : 0.6734 | Precision Test : 0.7515\n",
      "Accuracy Train: 0.6567 | F1 Train: 0.6897 | Precision Train: 0.7512\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train_2, y_train_2, SVC, 10)\n",
    "pred_svm_stck = evaluate_model(SVC(**svm_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:55<00:00,  1.12s/trial, best loss: -0.6593705492884631]\n",
      "Hyperopt search took 55.82 seconds for 200 candidates\n",
      "Best score: 0.6594 \n",
      "Best space:  {'C': 0.0025, 'tol': 0.05}\n",
      "Accuracy Test : 0.6620 | F1 Test : 0.6620 | Precision Test : 0.6825\n",
      "Accuracy Train: 0.6573 | F1 Train: 0.6659 | Precision Train: 0.6727\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]),\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, \n",
    "                                  0.05, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train_2, y_train_2, LogisticRegression, 50)\n",
    "pred_log_stck = evaluate_model(LogisticRegression(**log_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:45<00:00,  1.42trial/s, best loss: -0.6652384950981534]\n",
      "Hyperopt search took 105.85 seconds for 200 candidates\n",
      "Best score: 0.6652 \n",
      "Best space:  {'criterion': 'entropy', 'max_depth': 4, 'max_features': 47, 'min_samples_leaf': 29}\n",
      "Accuracy Test : 0.6490 | F1 Test : 0.6562 | Precision Test : 0.6907\n",
      "Accuracy Train: 0.6580 | F1 Train: 0.6704 | Precision Train: 0.6847\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {\"max_depth\":        hp.choice('max_depth', range(1, 20)),\n",
    "          \"max_features\":     hp.choice('max_features', range(1, 50)),\n",
    "          \"min_samples_leaf\": hp.choice('min_samples_leaf', range(1, 50)),\n",
    "          \"criterion\":        hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best_score = 1\n",
    "tree_params = bayesian(params, X_train_2, y_train_2, DecisionTreeClassifier, 150)\n",
    "pred_tree_stck = evaluate_model(DecisionTreeClassifier(**tree_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>729</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>241</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       729   466\n",
       "Good      241   564"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pred_svm_stck, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKWARD ELIMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=True):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          end='\\r', flush=True)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', f'{score:.4f}','                                                                       ')\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'learning_rate': 0.001, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 0.05, \n",
    "        'min_samples_split': 0.45, 'n_estimators': 175, 'subsample': 1}\n",
    "    \n",
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = GradientBoostingClassifier(**best, random_state=1)            \n",
    "    clf.fit(X_train, y_train)\n",
    "    score = H_score(clf.predict(X_train), y_train)\n",
    "    return(variable, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.6692: 0.6687 | New score: 0.6692 | Variable to remove: Dist_Airportrs with friends\n",
      "Seed: 1 <- 0.6691: 0.6672 | New score: 0.6691 | Variable to remove: value_Pos_Hoteltayed 8 nights\n",
      "Seed: 2 <- 0.6694: 0.6685 | New score: 0.6694 | Variable to remove: location_Neg_Hotelel\n",
      "Seed: 3 <- 0.6696: 0.6687 | New score: 0.6696 | Variable to remove: location_Pos_Hotel\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "var_selec = []\n",
    "for seed in range(4):\n",
    "    varin, score = try_seed(seed, verbose=True)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        var_selec = varin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.6701176470588235\n",
      "Accuracy:  0.6495\n",
      "Recall:    0.6164502164502165\n",
      "Precision: 0.734020618556701\n",
      "H-Score  : 0.6596477589319545\n"
     ]
    }
   ],
   "source": [
    "X_train_varin = X_train_2[var_selec]\n",
    "X_test_varin = X_test_2[var_selec] \n",
    "\n",
    "X_train_varin = X_train_2\n",
    "X_test_varin = X_test_2\n",
    "\n",
    "clf = GradientBoostingClassifier(**best, random_state=1)\n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "print(\"F1-Score: \", f1_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Accuracy: \", accuracy_score(clf.predict(X_test_varin), y_test_2))\n",
    "print(\"Recall:   \", recall_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Precision:\", precision_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"H-Score  :\", H_score(clf.predict(X_test_varin), y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>712</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>258</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       712   443\n",
       "Good      258   587"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(clf.predict(X_test_varin), y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIDENCE INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\r"
     ]
    }
   ],
   "source": [
    "pred_f1 = []\n",
    "pred_ac = []\n",
    "pred_H = []\n",
    "\n",
    "for i in range(10000):\n",
    "    sample = np.random.randint(0, len(X_test_varin), size=len(X_test_varin))\n",
    "    X_sample = X_test_varin.iloc[sample]\n",
    "    y_sample = y_test_2.iloc[sample]\n",
    "    print(i, end='\\r', flush=True)\n",
    "    pred_f1.append(f1_score(clf.predict(X_sample), y_sample, pos_label='Bad'))\n",
    "    pred_ac.append(accuracy_score(clf.predict(X_sample), y_sample))\n",
    "    pred_H.append(H_score(clf.predict(X_sample), y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   6.,   10.,   29.,   38.,   89.,  153.,  271.,  385.,  572.,\n",
       "         757.,  920., 1056., 1090., 1129.,  963.,  822.,  590.,  452.,\n",
       "         311.,  182.,   86.,   53.,   21.,   12.,    3.]),\n",
       " array([0.62120884, 0.62425561, 0.62730238, 0.63034914, 0.63339591,\n",
       "        0.63644268, 0.63948944, 0.64253621, 0.64558298, 0.64862974,\n",
       "        0.65167651, 0.65472328, 0.65777004, 0.66081681, 0.66386358,\n",
       "        0.66691034, 0.66995711, 0.67300388, 0.67605064, 0.67909741,\n",
       "        0.68214418, 0.68519094, 0.68823771, 0.69128447, 0.69433124,\n",
       "        0.69737801]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_H, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            2.5%    50%  97.5%\n",
      "H-Score:  0.6382 0.6598 0.6805\n",
      "Accuracy: 0.6285 0.6495 0.6705\n",
      "F1-Score: 0.6468 0.6701 0.6927\n"
     ]
    }
   ],
   "source": [
    "print('            2.5%    50%  97.5%')\n",
    "print('H-Score: ',f'{np.percentile(pred_H, 2.5):.4f}',f'{np.percentile(pred_H, 50):.4f}',f'{np.percentile(pred_H, 97.5):.4f}')\n",
    "print('Accuracy:',f'{np.percentile(pred_ac,2.5):.4f}',f'{np.percentile(pred_ac,50):.4f}',f'{np.percentile(pred_ac,97.5):.4f}')\n",
    "print('F1-Score:',f'{np.percentile(pred_f1,2.5):.4f}',f'{np.percentile(pred_f1,50):.4f}',f'{np.percentile(pred_f1,97.5):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
