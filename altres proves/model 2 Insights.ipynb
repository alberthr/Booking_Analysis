{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Bad Reviews & Category to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df_original[df_original.Category==\"Bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category = df.cleanliness_Neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, Balance_Nationality, Balance_Category, cut):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = cut\n",
    "            if len(nationality) < n:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10988, 78)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_1 = balance_df(df, Balance_Nationality=False, Balance_Category=True, cut=10000)\n",
    "df_balanced_2 = balance_df(df_balanced_1, Balance_Nationality=True, Balance_Category=True, \n",
    "                         cut=int(np.median(df_balanced_1.Nationality_Recode.value_counts())*1.5))\n",
    "df_balanced_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Middle east            1711\n",
       "UK & Ireland           1708\n",
       "Western Europe         1707\n",
       "North America          1556\n",
       "Eastern Europe         1517\n",
       "Asia & Pacific         1145\n",
       "Oceania                 847\n",
       "Sub-Saharian Africa     289\n",
       "South/Latin America     232\n",
       "Arab States             143\n",
       "China                   133\n",
       "Name: Nationality_Recode, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_2.Nationality_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10988, 78)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df_balanced_2) > 20000:\n",
    "    df_model = df_balanced_2.sample(n=20000, random_state=1)\n",
    "else:\n",
    "    df_model = df_balanced_2.copy()\n",
    "\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode','Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model['Review_Month'] = df_model['Review_Month'].astype(str)\n",
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5494, 77), (5494,), (5494, 77), (5494,))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grid(model, params, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    f1 = make_scorer(f1_score, pos_label = 1)\n",
    "    H = make_scorer(H_score, greater_is_better=True) \n",
    "    clf = GridSearchCV(estimator = model, param_grid = params, n_jobs = -1, cv = 5, verbose = verbose)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(clf.predict(X_test), y_test):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(clf.predict(X_test), y_test, pos_label=1):.4f}',\n",
    "          '| Precision Test :', f'{precision_score(clf.predict(X_test), y_test, pos_label=1):.4f}', \n",
    "          '| H Test :', f'{H_score(clf.predict(X_test), y_test):.4f}')\n",
    "    \n",
    "    print('Accuracy Train:', f'{accuracy_score(clf.predict(X_train), y_train):.4f}', \n",
    "          '| F1 Train:', f'{f1_score(clf.predict(X_train), y_train, pos_label=1):.4f}',\n",
    "          '| Precision Train:', f'{precision_score(clf.predict(X_train), y_train, pos_label=1):.4f}', \n",
    "          '| H Train:', f'{H_score(clf.predict(X_train), y_train):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_score(X_train, y_train):\n",
    "    acc = accuracy_score(X_train, y_train)\n",
    "    f1 = f1_score(X_train, y_train, pos_label = 1)\n",
    "    return(2 / ((1/acc)+(1/f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian(space, X, y, modelo, nevals):\n",
    "    \n",
    "    H = make_scorer(H_score, greater_is_better=True) \n",
    "        \n",
    "    def objective(space):\n",
    "        \n",
    "        global best_score\n",
    "        \n",
    "        model = modelo(**space)   \n",
    "        kfold = KFold(n_splits=5, random_state=1985, shuffle=True)\n",
    "        score = -cross_val_score(model, X, y, cv=kfold, scoring='accuracy', verbose=False).mean()\n",
    "        if (score < best_score):\n",
    "            best_score = score\n",
    "        return score\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    best = fmin(\n",
    "      objective, \n",
    "      space = space,\n",
    "      algo = tpe.suggest, \n",
    "      max_evals = nevals,\n",
    "      trials = Trials())\n",
    "\n",
    "    print(\"Hyperopt search took %.2f seconds for 200 candidates\" % ((time.time() - start)))\n",
    "    print(\"Best score: %.4f \" % (-best_score))\n",
    "    print(\"Best space: \", space_eval(params, best))\n",
    "    return(space_eval(params, best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.5453 | F1 Test : 0.5461 | Precision Test : 0.5471 | H Test : 0.5457\n",
      "Accuracy Train: 0.6993 | F1 Train: 0.6994 | Precision Train: 0.6997 | H Train: 0.6994\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate_model(KNeighborsClassifier(n_neighbors=5), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:02<00:00,  4.85s/trial, best loss: -0.573714139862203]\n",
      "Hyperopt search took 242.51 seconds for 200 candidates\n",
      "Best score: 0.5737 \n",
      "Best space:  {'learning_rate': 0.05, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 0.32, 'min_samples_split': 0.01, 'n_estimators': 248, 'subsample': 1}\n",
      "Accuracy Test : 0.5817 | F1 Test : 0.5855 | Precision Test : 0.5908 | H Test : 0.5836\n",
      "Accuracy Train: 0.5914 | F1 Train: 0.5977 | Precision Train: 0.6072 | H Train: 0.5945\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, \n",
    "                                                          0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.50]), \n",
    "          'n_estimators':      hp.choice('n_estimators', range(1,400)),\n",
    "          'max_depth':         hp.choice('max_depth',range(1,20)),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train, y_train, GradientBoostingClassifier, 50)\n",
    "pred_gbt = evaluate_model(GradientBoostingClassifier(**gbt_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:31<00:00,  5.43s/trial, best loss: -0.572076950232949]\n",
      "Hyperopt search took 271.51 seconds for 200 candidates\n",
      "Best score: 0.5721 \n",
      "Best space:  {'bootstrap': True, 'max_depth': 18, 'max_features': 'sqrt', 'min_samples_leaf': 0.06999999999999999, 'min_samples_split': 0.09999999999999999, 'n_estimators': 50}\n",
      "Accuracy Test : 0.5763 | F1 Test : 0.5858 | Precision Test : 0.5992 | H Test : 0.5810\n",
      "Accuracy Train: 0.5896 | F1 Train: 0.5941 | Precision Train: 0.6007 | H Train: 0.5918\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap':         hp.choice('bootstrap',[True, False]),\n",
    "          'max_depth':         hp.choice('max_depth', range(1, 20)),\n",
    "          'max_features':      hp.choice('max_features',['auto', 'sqrt']),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'n_estimators':      hp.choice('n_estimators',range(1,400))}\n",
    "\n",
    "best_score = 1\n",
    "rf_params = bayesian(params, X_train, y_train, RandomForestClassifier, 50)\n",
    "pred_rf = evaluate_model(RandomForestClassifier(**rf_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [17:41<00:00, 21.23s/trial, best loss: -0.5808134899917295]\n",
      "Hyperopt search took 1061.86 seconds for 200 candidates\n",
      "Best score: 0.5808 \n",
      "Best space:  {'colsample_bytree': 0.49, 'gamma': 0.4, 'learning_rate': 0.05, 'max_depth': 2, 'min_child_weight': 0.61, 'n_estimators': 80}\n",
      "Accuracy Test : 0.5861 | F1 Test : 0.5999 | Precision Test : 0.6207 | H Test : 0.5929\n",
      "Accuracy Train: 0.6085 | F1 Train: 0.6194 | Precision Train: 0.6371 | H Train: 0.6139\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':    hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                                         0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', range(1,200))}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train, y_train, xgb.XGBClassifier, 50)\n",
    "pred_xgb = evaluate_model(xgb.XGBClassifier(**xgb_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:16<00:00,  3.05trial/s, best loss: -0.5866377945839155]\n",
      "Hyperopt search took 16.39 seconds for 200 candidates\n",
      "Best score: 0.5866 \n",
      "Best space:  {'C': 0.01, 'tol': 0.0001}\n",
      "Accuracy Test : 0.6008 | F1 Test : 0.5854 | Precision Test : 0.5635 | H Test : 0.5930\n",
      "Accuracy Train: 0.6043 | F1 Train: 0.5872 | Precision Train: 0.5628 | H Train: 0.5956\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]),\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, \n",
    "                                  0.05, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train, y_train, LogisticRegression, 50)\n",
    "pred_log = evaluate_model(LogisticRegression(**log_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:44<00:00,  3.37trial/s, best loss: -0.5689800795888298]\n",
      "Hyperopt search took 44.52 seconds for 200 candidates\n",
      "Best score: 0.5690 \n",
      "Best space:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 37, 'min_samples_leaf': 13}\n",
      "Accuracy Test : 0.5783 | F1 Test : 0.6476 | Precision Test : 0.7750 | H Test : 0.6110\n",
      "Accuracy Train: 0.5688 | F1 Train: 0.6391 | Precision Train: 0.7637 | H Train: 0.6019\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {\"max_depth\":        hp.choice('max_depth', range(1, 20)),\n",
    "          \"max_features\":     hp.choice('max_features', range(1, 50)),\n",
    "          \"min_samples_leaf\": hp.choice('min_samples_leaf', range(1, 50)),\n",
    "          \"criterion\":        hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best_score = 1\n",
    "tree_params = bayesian(params, X_train, y_train, DecisionTreeClassifier, 150)\n",
    "pred_tree = evaluate_model(DecisionTreeClassifier(**tree_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:56<00:00, 23.67s/trial, best loss: -0.562249503191343]\n",
      "Hyperopt search took 236.74 seconds for 200 candidates\n",
      "Best score: 0.5622 \n",
      "Best space:  {'C': 0.25, 'degree': 2, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.5701 | F1 Test : 0.5752 | Precision Test : 0.5821 | H Test : 0.5726\n",
      "Accuracy Train: 0.6176 | F1 Train: 0.6196 | Precision Train: 0.6229 | H Train: 0.6186\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train, y_train, SVC, 10)\n",
    "pred_svm = evaluate_model(SVC(**svm_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.64trial/s, best loss: -0.5666161156607016]\n",
      "Hyperopt search took 8.88 seconds for 200 candidates\n",
      "Best score: 0.5666 \n",
      "Best space:  {'alpha': 0.75, 'fit_prior': False}\n",
      "Accuracy Test : 0.5792 | F1 Test : 0.5779 | Precision Test : 0.5763 | H Test : 0.5786\n",
      "Accuracy Train: 0.5770 | F1 Train: 0.5748 | Precision Train: 0.5719 | H Train: 0.5759\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\":     hp.choice('alpha', [0.025, 0.05, 0.075, 0.1, 0.15, 0.20, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, \n",
    "                                           2, 2.5, 5, 10]), \n",
    "          \"fit_prior\": hp.choice('fit_prior', [True, False])}\n",
    "\n",
    "best_score = 1\n",
    "nb_params = bayesian(params, X_train, y_train, BernoulliNB, 50)\n",
    "pred_nb = evaluate_model(BernoulliNB(**nb_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113744</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79720</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        logistic  gbt  knn  svm  tree  xgb  nb  rf\n",
       "113744         1    1    1    1     1    1   1   1\n",
       "79720          0    1    1    1     1    0   1   1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:20<00:00,  6.41s/trial, best loss: -0.5936291240045506]\n",
      "Hyperopt search took 320.42 seconds for 200 candidates\n",
      "Best score: 0.5936 \n",
      "Best space:  {'learning_rate': 0.25, 'max_depth': 19, 'max_features': 'sqrt', 'min_samples_leaf': 0.03, 'min_samples_split': 0.89, 'n_estimators': 140, 'subsample': 1}\n",
      "Accuracy Test : 0.5569 | F1 Test : 0.5694 | Precision Test : 0.5781 | H Test : 0.5631\n",
      "Accuracy Train: 0.6337 | F1 Train: 0.6309 | Precision Train: 0.6283 | H Train: 0.6323\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, \n",
    "                                                          0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.50]), \n",
    "          'n_estimators':      hp.choice('n_estimators', range(1,400)),\n",
    "          'max_depth':         hp.choice('max_depth',range(1,20)),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train_2, y_train_2, GradientBoostingClassifier, 50)\n",
    "pred_gbt_stck = evaluate_model(GradientBoostingClassifier(**gbt_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [28:21<00:00, 34.02s/trial, best loss: -0.5902161547212741]\n",
      "Hyperopt search took 1701.42 seconds for 200 candidates\n",
      "Best score: 0.5902 \n",
      "Best space:  {'colsample_bytree': 0.89, 'gamma': 0.61, 'learning_rate': 0.075, 'max_depth': 2, 'min_child_weight': 0.89, 'n_estimators': 153}\n",
      "Accuracy Test : 0.5532 | F1 Test : 0.5659 | Precision Test : 0.5745 | H Test : 0.5595\n",
      "Accuracy Train: 0.6494 | F1 Train: 0.6492 | Precision Train: 0.6511 | H Train: 0.6493\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':    hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                                         0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', range(1,200))}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train_2, y_train_2, xgb.XGBClassifier, 50)\n",
    "pred_xgb_stck = evaluate_model(xgb.XGBClassifier(**xgb_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [04:35<00:00, 27.54s/trial, best loss: -0.65575]\n",
      "Hyperopt search took 275.40 seconds for 200 candidates\n",
      "Best score: 0.6558 \n",
      "Best space:  {'C': 0.075, 'degree': 2, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.6515 | F1 Test : 0.6720 | Precision Test : 0.7361 | H Test : 0.6616\n",
      "Accuracy Train: 0.6596 | F1 Train: 0.6850 | Precision Train: 0.7288 | H Train: 0.6721\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train_2, y_train_2, SVC, 10)\n",
    "pred_svm_stck = evaluate_model(SVC(**svm_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:21<00:00,  2.30trial/s, best loss: -0.595221843003413]\n",
      "Hyperopt search took 21.74 seconds for 200 candidates\n",
      "Best score: 0.5952 \n",
      "Best space:  {'C': 0.075, 'tol': 0.025}\n",
      "Accuracy Test : 0.5705 | F1 Test : 0.5564 | Precision Test : 0.5314 | H Test : 0.5634\n",
      "Accuracy Train: 0.6180 | F1 Train: 0.6011 | Precision Train: 0.5776 | H Train: 0.6094\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, \n",
    "                                0.075, 0.1]),\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.000075, 0.0001, 0.00025, 0.0005, 0.00075, \n",
    "                                  0.001, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train_2, y_train_2, LogisticRegression, 50)\n",
    "pred_log_stck = evaluate_model(LogisticRegression(**log_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:40<00:00,  3.68trial/s, best loss: -0.5856655290102389]\n",
      "Hyperopt search took 40.86 seconds for 200 candidates\n",
      "Best score: 0.5857 \n",
      "Best space:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 41, 'min_samples_leaf': 35}\n",
      "Accuracy Test : 0.5541 | F1 Test : 0.6293 | Precision Test : 0.7469 | H Test : 0.5894\n",
      "Accuracy Train: 0.5868 | F1 Train: 0.6506 | Precision Train: 0.7721 | H Train: 0.6171\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {\"max_depth\":        hp.choice('max_depth', range(1, 20)),\n",
    "          \"max_features\":     hp.choice('max_features', range(1, 50)),\n",
    "          \"min_samples_leaf\": hp.choice('min_samples_leaf', range(1, 50)),\n",
    "          \"criterion\":        hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best_score = 1\n",
    "tree_params = bayesian(params, X_train_2, y_train_2, DecisionTreeClassifier, 150)\n",
    "pred_tree_stck = evaluate_model(DecisionTreeClassifier(**tree_params), X_train_2, X_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>657</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>313</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       657   357\n",
       "Good      313   673"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pred_log_stck, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKWARD ELIMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=True):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          end='\\r', flush=True)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', f'{score:.4f}','                                                                       ')\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = xgb.XGBClassifier(**xgb_params, random_state=1)            \n",
    "    clf.fit(X_train, y_train)\n",
    "    score = accuracy_score(clf.predict(X_train), y_train)\n",
    "    return(variable, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.6760                                                                        \n",
      "Seed: 1 <- 0.6765                                                                        \n",
      "Seed: 2 <- 0.6757                                                                        \n",
      "Seed: 3 <- 0.6796                                                                        \n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "var_selec = []\n",
    "for seed in range(4):\n",
    "    varin, score = try_seed(seed, verbose=True)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        var_selec = varin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.6623634558093345\n",
      "Accuracy:  0.66\n",
      "Recall:    0.6388888888888888\n",
      "Precision: 0.6876288659793814\n",
      "H-Score  : 0.661179615806311\n"
     ]
    }
   ],
   "source": [
    "X_train_varin = X_train_2[var_selec]\n",
    "X_test_varin = X_test_2[var_selec] \n",
    "\n",
    "X_train_varin = X_train_2\n",
    "X_test_varin = X_test_2\n",
    "\n",
    "clf = xgb.XGBClassifier(**xgb_params, random_state=1)            \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "print(\"F1-Score: \", f1_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Accuracy: \", accuracy_score(clf.predict(X_test_varin), y_test_2))\n",
    "print(\"Recall:   \", recall_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Precision:\", precision_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"H-Score  :\", H_score(clf.predict(X_test_varin), y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>667</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>303</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       667   377\n",
       "Good      303   653"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(clf.predict(X_test_varin), y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIDENCE INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\r"
     ]
    }
   ],
   "source": [
    "pred_f1 = []\n",
    "pred_ac = []\n",
    "pred_H = []\n",
    "\n",
    "for i in range(1000):\n",
    "    sample = np.random.randint(0, len(X_test_varin), size=len(X_test_varin))\n",
    "    X_sample = X_test_varin.iloc[sample]\n",
    "    y_sample = y_test_2.iloc[sample]\n",
    "    print(i, end='\\r', flush=True)\n",
    "    pred_f1.append(f1_score(clf.predict(X_sample), y_sample, pos_label='Bad'))\n",
    "    pred_ac.append(accuracy_score(clf.predict(X_sample), y_sample))\n",
    "    pred_H.append(H_score(clf.predict(X_sample), y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  4.,  6., 13., 20., 27., 39., 57., 61., 61., 90., 88., 90.,\n",
       "        95., 88., 74., 56., 44., 29., 25., 10.,  7.,  6.,  4.,  3.]),\n",
       " array([0.62925852, 0.63200143, 0.63474434, 0.63748725, 0.64023017,\n",
       "        0.64297308, 0.64571599, 0.6484589 , 0.65120182, 0.65394473,\n",
       "        0.65668764, 0.65943055, 0.66217347, 0.66491638, 0.66765929,\n",
       "        0.6704022 , 0.67314511, 0.67588803, 0.67863094, 0.68137385,\n",
       "        0.68411676, 0.68685968, 0.68960259, 0.6923455 , 0.69508841,\n",
       "        0.69783133]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_ac, bins=25, alpha=0.4)\n",
    "plt.hist(pred_H, bins=25, alpha=0.4)\n",
    "plt.hist(pred_f1, bins=25, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            2.5%    50%  97.5%\n",
      "H-Score:  0.6417 0.6619 0.6822\n",
      "Accuracy: 0.6405 0.6605 0.6810\n",
      "F1-Score: 0.6402 0.6633 0.6858\n"
     ]
    }
   ],
   "source": [
    "print('            2.5%    50%  97.5%')\n",
    "print('H-Score: ',f'{np.percentile(pred_H, 2.5):.4f}',f'{np.percentile(pred_H, 50):.4f}',f'{np.percentile(pred_H, 97.5):.4f}')\n",
    "print('Accuracy:',f'{np.percentile(pred_ac,2.5):.4f}',f'{np.percentile(pred_ac,50):.4f}',f'{np.percentile(pred_ac,97.5):.4f}')\n",
    "print('F1-Score:',f'{np.percentile(pred_f1,2.5):.4f}',f'{np.percentile(pred_f1,50):.4f}',f'{np.percentile(pred_f1,97.5):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
