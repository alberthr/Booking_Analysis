{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, Balance_Nationality, Balance_Category, cut):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = cut\n",
    "            if len(nationality) < n:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75780, 78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_1 = balance_df(df, Balance_Nationality=False, Balance_Category=True, cut=10000)\n",
    "df_balanced_2 = balance_df(df_balanced_1, Balance_Nationality=True, Balance_Category=True, \n",
    "                         cut=int(np.median(df_balanced_1.Nationality_Recode.value_counts())*1.5))\n",
    "df_balanced_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "North America          11538\n",
       "Western Europe         11519\n",
       "UK & Ireland           11513\n",
       "Middle east            11477\n",
       "Eastern Europe          8829\n",
       "Asia & Pacific          7680\n",
       "Oceania                 7604\n",
       "Sub-Saharian Africa     2058\n",
       "South/Latin America     1610\n",
       "China                   1099\n",
       "Arab States              853\n",
       "Name: Nationality_Recode, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_2.Nationality_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 78)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df_balanced_2) > 20000:\n",
    "    df_model = df_balanced_2.sample(n=20000, random_state=1)\n",
    "else:\n",
    "    df_model = df_balanced_2.copy()\n",
    "\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode','Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model['Review_Month'] = df_model['Review_Month'].astype(str)\n",
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 76), (10000,), (10000, 76), (10000,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random(model, params, iterations, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    f1 = make_scorer(f1_score, pos_label = \"Bad\")\n",
    "    clf = RandomizedSearchCV(estimator = model, param_distributions = params, n_iter = iterations, scoring = f1, \n",
    "                             n_jobs = -1, cv = 5, random_state = 27, verbose = verbose)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grid(model, params, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    f1 = make_scorer(f1_score, pos_label = \"Bad\")\n",
    "    clf = GridSearchCV(estimator = model, param_grid = params, scoring = f1, n_jobs = -1, cv = 5, verbose = verbose)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(clf.predict(X_test), y_test):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}')\n",
    "    print('Accuracy Train:', f'{accuracy_score(clf.predict(X_train), y_train):.4f}', \n",
    "          '| F1 Train:', f'{f1_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.5991 | F1 Test : 0.5987\n",
      "Accuracy Train: 0.7382 | F1 Train: 0.7402\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate_model(KNeighborsClassifier(n_neighbors=5), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 1, 'n_estimators': 108, 'min_samples_split': 0.9272727272727272, 'min_samples_leaf': 0.11393939393939392, 'max_features': 'sqrt', 'max_depth': 4, 'learning_rate': 0.001} 0.6813671058566237\n",
      "Accuracy Test : 0.6388 | F1 Test : 0.6811\n",
      "Accuracy Train: 0.6469 | F1 Train: 0.6895\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {'learning_rate':  [0.001, 0.0025, 0.005 , 0.01, 0.025, 0.05, 0.1], \n",
    "          'n_estimators': range(100, 200),\n",
    "          'max_depth': [2, 3, 4, 5],\n",
    "          'min_samples_split': np.linspace(0.1, 1.0, 100, endpoint=True),\n",
    "          'min_samples_leaf': np.linspace(0.01, 0.5, 100, endpoint=True), \n",
    "          'subsample': [1], \n",
    "          'max_features': ['sqrt']}\n",
    "\n",
    "pred_gbt = evaluate_random(GradientBoostingClassifier(), params, iterations, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_gbt = evaluate_model(GradientBoostingClassifier(n_estimators = 165, \n",
    "#                                                      min_samples_split = 0.6272727272727272, \n",
    "#                                                      min_samples_leaf = 0.11888888888888888, \n",
    "#                                                      max_depth = 2, learning_rate = 0.001),\n",
    "#                           X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 104, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 6, 'bootstrap': False} 0.668140795949073\n",
      "Accuracy Test : 0.6484 | F1 Test : 0.6567\n",
      "Accuracy Train: 0.6829 | F1 Train: 0.6926\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': range(1, 10),\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_leaf': range(1, 10),\n",
    "          'min_samples_split': range(1, 10),\n",
    "          'n_estimators': range(100, 200)}\n",
    "\n",
    "pred_rf = evaluate_random(RandomForestClassifier(random_state = 1), params, iterations, \n",
    "                          X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_rf = evaluate_model(RandomForestClassifier(n_estimators = 153, min_samples_split = 5,  min_samples_leaf = 7,\n",
    "#                                                 max_features = 'auto', max_depth = 2, bootstrap = False, random_state=1), \n",
    "#                          X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'min_child_weight': 10, 'max_depth': 3, 'learning_rate': 0.001, 'gamma': 0.5, 'colsample_bytree': 1.0} 0.6727454475939748\n",
      "Accuracy Test : 0.6403 | F1 Test : 0.6684\n",
      "Accuracy Train: 0.6453 | F1 Train: 0.6741\n"
     ]
    }
   ],
   "source": [
    "iterations = 250\n",
    "params = {\"learning_rate\"    : [0.0001, 0.005, 0.001, 0.005, 0.01, 0.05, 0.10, 0.25, 0.50],\n",
    "          \"max_depth\"        : [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          \"min_child_weight\" : [1, 3, 5, 10, 25, 50, 100, 250],\n",
    "          \"gamma\"            : [0.01, 0.05, 0.1, 0.15, 0.25, 0.50, 0.75, 0.95],\n",
    "          \"colsample_bytree\" : [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2],\n",
    "          \"n_estimators\"     : [2, 3, 5, 7, 10, 15, 25, 50, 100]}\n",
    "\n",
    "pred_xgb = evaluate_random(xgb.XGBClassifier(), params, iterations, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_xgb = evaluate_model(xgb.XGBClassifier(n_estimators = 7, min_child_weight = 5, max_depth = 3, learning_rate = 0.005,\n",
    "#                                             gamma = 0.05, colsample_bytree = 1, random_state = 1), \n",
    "#                     X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'tol': 1e-05} 0.6667386209306692\n",
      "Accuracy Test : 0.6555 | F1 Test : 0.6566\n",
      "Accuracy Train: 0.6670 | F1 Train: 0.6719\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\": [0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1],\n",
    "          \"tol\": [0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]}\n",
    "\n",
    "pred_log = evaluate_grid(LogisticRegression(solver = 'lbfgs', max_iter = 1000, random_state = 1), \n",
    "                         params, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_log = evaluate_model(LogisticRegression(C = 0.1, tol = 0.00001, solver='lbfgs', max_iter=1000, random_state=1), \n",
    "#                           X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 2, 'max_features': 12, 'max_depth': 3, 'criterion': 'gini'} 0.6856733638524558\n",
      "Accuracy Test : 0.6328 | F1 Test : 0.6797\n",
      "Accuracy Train: 0.6402 | F1 Train: 0.6879\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "params = {\"max_depth\": range(1, 10),\n",
    "          \"max_features\": range(1, 20),\n",
    "          \"min_samples_leaf\": range(1, 20),\n",
    "          \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "pred_tree = evaluate_random(DecisionTreeClassifier(random_state = 1), params, iterations, \n",
    "                            X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.6424 | F1 Test : 0.6831\n",
      "Accuracy Train: 0.6491 | F1 Train: 0.6864\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate_model(DecisionTreeClassifier(min_samples_leaf = 4, max_features = 19, max_depth = 3, \n",
    "                                                  criterion = 'entropy', random_state = 1), \n",
    "                     X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'degree': 3, 'kernel': 'poly'} 0.7002858960634858\n",
      "Accuracy Test : 0.6313 | F1 Test : 0.6831\n",
      "Accuracy Train: 0.6394 | F1 Train: 0.6915\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": [2, 3, 4],\n",
    "          \"kernel\": ['poly'], \n",
    "          \"C\":      [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "pred_svm = evaluate_grid(SVC(random_state = 1), params, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_svm = evaluate_model(SVC(kernel = 'poly', degree = 2, C = 0.005, random_state = 1), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'fit_prior': True} 0.6416924258034667\n",
      "Accuracy Test : 0.6465 | F1 Test : 0.6391\n",
      "Accuracy Train: 0.6457 | F1 Train: 0.6417\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\": [0.1, 0.25, 0.5, 1, 2.5, 5, 10], \n",
    "          \"fit_prior\": [True, False]}\n",
    "\n",
    "pred_nb = evaluate_grid(BernoulliNB(), params, X_train, X_test, y_train, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_nb = evaluate_model(BernoulliNB(alpha=0.25, fit_prior=True), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333373</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127076</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic  gbt  knn  svm tree  xgb   nb   rf\n",
       "333373      Bad  Bad  Bad  Bad  Bad  Bad  Bad  Bad\n",
       "127076      Bad  Bad  Bad  Bad  Bad  Bad  Bad  Bad"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 1, 'n_estimators': 108, 'min_samples_split': 0.9272727272727272, 'min_samples_leaf': 0.11393939393939392, 'max_features': 'sqrt', 'max_depth': 4, 'learning_rate': 0.001} 0.6924567873416765\n",
      "Accuracy Test : 0.6310 | F1 Test : 0.6786\n",
      "Accuracy Train: 0.6420 | F1 Train: 0.6936\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {'learning_rate':  [0.001, 0.0025, 0.005 , 0.01, 0.025, 0.05, 0.1], \n",
    "          'n_estimators': range(100, 200),\n",
    "          'max_depth': [2, 3, 4, 5],\n",
    "          'min_samples_split': np.linspace(0.1, 1.0, 100, endpoint=True),\n",
    "          'min_samples_leaf': np.linspace(0.01, 0.5, 100, endpoint=True), \n",
    "          'subsample': [1], \n",
    "          'max_features': ['sqrt']}\n",
    "          \n",
    "pred_gbt_stck = evaluate_random(GradientBoostingClassifier(random_state = 1), params, iterations, \n",
    "                                X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'min_child_weight': 100, 'max_depth': 5, 'learning_rate': 0.0001, 'gamma': 0.01, 'colsample_bytree': 1.0} 0.6735781487721149\n",
      "Accuracy Test : 0.6520 | F1 Test : 0.6723\n",
      "Accuracy Train: 0.6545 | F1 Train: 0.6810\n"
     ]
    }
   ],
   "source": [
    "iterations = 250\n",
    "params = {\"learning_rate\"    : [0.0001, 0.005, 0.001, 0.005, 0.01, 0.05, 0.10, 0.25, 0.50],\n",
    "          \"max_depth\"        : [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "          \"min_child_weight\" : [1, 3, 5, 10, 25, 50, 100, 250],\n",
    "          \"gamma\"            : [0.01, 0.05, 0.1, 0.15, 0.25, 0.50, 0.75, 0.95],\n",
    "          \"colsample_bytree\" : [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2],\n",
    "          \"n_estimators\"     : [2, 3, 5, 7, 10, 15, 25, 50, 100]}\n",
    "\n",
    "pred_xgb_stck = evaluate_random(xgb.XGBClassifier(random_state = 1), params, iterations, \n",
    "                                X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.005, 'degree': 2, 'kernel': 'poly'} 0.6969144046054042\n",
      "Accuracy Test : 0.6085 | F1 Test : 0.6892\n",
      "Accuracy Train: 0.6172 | F1 Train: 0.7000\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": [2, 3, 4],\n",
    "          \"kernel\": ['poly'], \n",
    "          \"C\":      [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "pred_svm_stck = evaluate_grid(SVC(random_state = 1), params, X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 0.001, 'C': 0.05} 0.6654194503952885\n",
      "Accuracy Test : 0.6675 | F1 Test : 0.6677\n",
      "Accuracy Train: 0.6639 | F1 Train: 0.6722\n"
     ]
    }
   ],
   "source": [
    "iterations = 50\n",
    "params = {\"C\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "          \"tol\": [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "pred_log_stck = evaluate_random(LogisticRegression(solver = 'lbfgs', max_iter = 1000, random_state = 1), \n",
    "                                params, iterations, X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 16, 'max_features': 17, 'max_depth': 4, 'criterion': 'entropy'} 0.6705932885940881\n",
      "Accuracy Test : 0.6550 | F1 Test : 0.6611\n",
      "Accuracy Train: 0.6593 | F1 Train: 0.6746\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "params = {\"max_depth\": range(1, 10),\n",
    "          \"max_features\": range(1, 20),\n",
    "          \"min_samples_leaf\": range(1, 20),\n",
    "          \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "pred_tree_stck = evaluate_random(DecisionTreeClassifier(random_state = 1), params, iterations, \n",
    "                                 X_train_2, X_test_2, y_train_2, y_test_2, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKWARD ELIMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=True):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          '| Variable to remove:', max_feature, end='\\r', flush=True)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', f'{score:.4f}')\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = SVC(C = 0.005, degree = 2, kernel = 'poly', random_state=1)            \n",
    "    clf.fit(X_train, y_train)\n",
    "    score = f1_score(clf.predict(X_train), y_train, pos_label = 'Bad')\n",
    "    return(variable, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.7068: 0.7066 | New score: 0.7068 | Variable to remove: Length_Recode_Stayed 3 nights\n",
      "14 Original Score: 0.7068 | New score: 0.7069 | Variable to remove: Length_Recode_Stayed 9+ nights\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-004aa28182b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvar_selec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mvarin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mmax_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-bdfa77f6d7d0>\u001b[0m in \u001b[0;36mtry_seed\u001b[1;34m(seed, verbose)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mX_train_vartest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mX_test_vartest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_vartest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_vartest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mmax_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-2361adffd9c5>\u001b[0m in \u001b[0;36mcheck_model\u001b[1;34m(variable, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'poly'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Bad'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# max_score = 0\n",
    "# var_selec = []\n",
    "# for seed in range(4):\n",
    "#     varin, score = try_seed(seed, verbose=True)\n",
    "#     if score > max_score:\n",
    "#         max_score = score\n",
    "#         var_selec = varin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.6891623660182612\n",
      "Accuracy:  0.6085\n",
      "Recall:    0.5603615235635894\n",
      "Precision: 0.8948453608247423\n"
     ]
    }
   ],
   "source": [
    "# X_train_varin = X_train_2[varin]\n",
    "# X_test_varin = X_test_2[varin] \n",
    "\n",
    "X_train_varin = X_train_2\n",
    "X_test_varin = X_test_2\n",
    "\n",
    "clf = SVC(C = 0.005, degree = 2, kernel = 'poly', random_state=1, probability=True)  \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "print(\"F1-Score: \", f1_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Accuracy: \", accuracy_score(clf.predict(X_test_varin), y_test_2))\n",
    "print(\"Recall:   \", recall_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))\n",
    "print(\"Precision:\", precision_score(clf.predict(X_test_varin), y_test_2, pos_label='Bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>868</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>102</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       868   681\n",
       "Good      102   349"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(clf.predict(X_test_varin), y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIDENCE INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\r"
     ]
    }
   ],
   "source": [
    "predicciones = []\n",
    "\n",
    "for i in range(1000):\n",
    "    sample = np.random.randint(0, len(X_test_varin), size=len(X_test_varin))\n",
    "    X_sample = X_test_varin.iloc[sample]\n",
    "    y_sample = y_test_2.iloc[sample]\n",
    "    print(i, end='\\r', flush=True)\n",
    "    predicciones.append(f1_score(clf.predict(X_sample), y_sample, pos_label='Bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   0.,   2.,   1.,   7.,   8.,  23.,  35.,  43.,  67.,  77.,\n",
       "         94.,  92., 105.,  88., 102.,  85.,  59.,  43.,  33.,  10.,   9.,\n",
       "          9.,   4.,   2.]),\n",
       " array([0.65301003, 0.65573381, 0.65845759, 0.66118137, 0.66390515,\n",
       "        0.66662893, 0.66935271, 0.67207649, 0.67480027, 0.67752405,\n",
       "        0.68024783, 0.68297161, 0.68569539, 0.68841918, 0.69114296,\n",
       "        0.69386674, 0.69659052, 0.6993143 , 0.70203808, 0.70476186,\n",
       "        0.70748564, 0.71020942, 0.7129332 , 0.71565698, 0.71838076,\n",
       "        0.72110454]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicciones, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6698829115236158, 0.6896139350752177, 0.709732606293281)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(predicciones, 2.5), np.percentile(predicciones, 50), np.percentile(predicciones, 97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
