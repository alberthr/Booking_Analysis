{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open file and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"515k-hotel-reviews-data-in-europe.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United Kingdom    262301\n",
       "Spain              60149\n",
       "France             59928\n",
       "Netherlands        57214\n",
       "Austria            38939\n",
       "Italy              37207\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_country(adress):\n",
    "    country = adress.split()[-1]\n",
    "    if country == \"Kingdom\":\n",
    "        return(\"United Kingdom\")\n",
    "    else:\n",
    "        return(country)\n",
    "    \n",
    "df['Country'] = df.Hotel_Address.apply(lambda x: get_country(x))\n",
    "df.Country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London       262301\n",
       "Barcelona     60149\n",
       "Paris         59928\n",
       "Amsterdam     57214\n",
       "Vienna        38939\n",
       "Milan         37207\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_city(adress, country):\n",
    "    city = adress.split()[-2]\n",
    "    if country == \"United Kingdom\":\n",
    "        return(adress.split()[-5])\n",
    "    else:\n",
    "        return(city)\n",
    "\n",
    "df['City'] = df[['Hotel_Address','Country']].apply(lambda x: get_city(x[0], x[1]), axis=1)\n",
    "df.City.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping Hotel Prices\n",
    "There's a lot more of information missing which we think is important to get better insights. \n",
    "To get all this information the first thing i need is to get the exact address that directs me into the booking page containing information of each Hotel. \n",
    "This first step will be done through scrapping the links in Google.\n",
    "Once scrapped the final address in booking, another scrapping exercise will be needed in order to get the desired information for each Hotel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    Hotel 11 Cadogan Gardens London\n",
       "1                               Hotel 1K Hotel Paris\n",
       "2    Hotel 25hours Hotel beim MuseumsQuartier Vienna\n",
       "3                                    Hotel 41 London\n",
       "4    Hotel 45 Park Lane Dorchester Collection London\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_city = df[['Hotel_Name','City']].groupby(['Hotel_Name','City']).count().reset_index()\n",
    "scrap = hotel_city.apply(lambda x: ('Hotel ' + x[0] + ' ' + x[1]), axis=1)\n",
    "scrap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the adress i will use in Google. The idea is that i will pick the first adress coming from booking.com as the final address of the hotel in the sistem. Once i will gather all of the addresses i will try to scrap the prices in each one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_address = ['https://www.google.com/search?sxsrf=&q=booking.com+'+i.replace(\" \", \"+\") for i in scrap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.google.com/search?sxsrf=&q=booking.com+Hotel+11+Cadogan+Gardens+London',\n",
       " 'https://www.google.com/search?sxsrf=&q=booking.com+Hotel+1K+Hotel+Paris',\n",
       " 'https://www.google.com/search?sxsrf=&q=booking.com+Hotel+25hours+Hotel+beim+MuseumsQuartier+Vienna',\n",
       " 'https://www.google.com/search?sxsrf=&q=booking.com+Hotel+41+London',\n",
       " 'https://www.google.com/search?sxsrf=&q=booking.com+Hotel+45+Park+Lane+Dorchester+Collection+London']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_address[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once i've got all the addresses of a Google search i start scrapping the addresses in Booking.\n",
    "\n",
    "I also save the important information just in case i need to start over again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(hotel_city, open('./hotel_city.sav', 'wb'))\n",
    "pickle.dump(google_address, open('./google_address.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrapping of Booking addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://www.booking.com/hotel/gb/number-eleven.es.html\n",
      "1 https://www.booking.com/hotel/fr/1-k-hotel.es.html\n",
      "2 https://www.booking.com/hotel/at/25hours-wien.es.html\n",
      "3 https://www.booking.com/hotel/gb/41clubredcarnations.es.html\n",
      "4 https://www.booking.com/hotel/gb/parklane.es.html\n"
     ]
    }
   ],
   "source": [
    "bookingaddress = []\n",
    "\n",
    "for i, hotel in enumerate(google_address[:5]):\n",
    "    URL = hotel\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    bkng = []\n",
    "    for page in soup.find_all('a', href=True):\n",
    "        if page['href'][:37] == '/url?q=https://www.booking.com/hotel/':\n",
    "            bkng.append(page['href'][7:].split('&', 1)[0])\n",
    "    if bkng[0][-8:] != '.es.html':\n",
    "        bkng[0] = bkng[0][:-5]+'.es.html'\n",
    "        \n",
    "    bookingaddress.append(bkng[0])\n",
    "    print(i,bkng[0])\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrapping of other Booking information (sample of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.booking.com/hotel/gb/number-eleven.es.html\n"
     ]
    }
   ],
   "source": [
    "head = {\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\"}\n",
    "URL = bookingaddress[i]\n",
    "page = requests.get(URL, headers=head)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(bookingaddress[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Header of the page ¿?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup.select(\"[type='application/ld+json']\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the price from the Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricetag = json.loads(data.text)['priceRange']\n",
    "price = int(pricetag.split(\"€\",1)[1].split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the stars of the Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = soup.find(class_='star_track')['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the name of the Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = json.loads(data.text)['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the facilities from Booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities = {}\n",
    "raw = soup.find_all(class_='facilitiesChecklistSection')\n",
    "for i in raw:\n",
    "    dept = i.getText().split('\\n')\n",
    "    facilities_dept = [x for x in i.getText().split('\\n') if x]\n",
    "    dept = facilities_dept[0]\n",
    "    items = facilities_dept[1:]    \n",
    "    facilities[dept] = items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dictionary with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = {}\n",
    "hotels[name] = {'Price': price, 'Stars': stars, 'Facilities': facilities, 'Header': json.loads(data.text)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrapping of other Booking information (complete dataset for loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://www.booking.com/hotel/gb/number-eleven.es.html\n",
      "1 https://www.booking.com/hotel/fr/1-k-hotel.es.html\n",
      "2 https://www.booking.com/hotel/at/25hours-wien.es.html\n",
      "3 https://www.booking.com/hotel/gb/41clubredcarnations.es.html\n",
      "4 https://www.booking.com/hotel/gb/parklane.es.html\n",
      "5 https://www.booking.com/hotel/gb/88-studios.es.html\n",
      "6 https://www.booking.com/hotel/fr/9hotel-republique.es.html\n",
      "7 https://www.booking.com/hotel/fr/a-la-villa-madame.es.html\n",
      "8 https://www.booking.com/hotel/es/abac-barcelona.es.html\n",
      "9 https://www.booking.com/hotel/es/achotelsbarcelona.es.html\n",
      "10 https://www.booking.com/hotel/es/ac-marriott-diagonal-lilla.es.html\n",
      "11 https://www.booking.com/hotel/es/acirla.es.html\n",
      "12 https://www.booking.com/hotel/it/ac-milano.es.html\n",
      "13 https://www.booking.com/hotel/fr/ac-paris-porte-maillot-by-marriott.es.html\n",
      "14 https://www.booking.com/hotel/es/ac-sants.es.html\n"
     ]
    }
   ],
   "source": [
    "head = {\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\"}\n",
    "hotels = {}\n",
    "name_scrap = []\n",
    "\n",
    "for num, url in enumerate(bookingaddress):\n",
    "    \n",
    "    print(num, url)\n",
    "    \n",
    "    URL = url\n",
    "    page = requests.get(URL, headers=head)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Get Header\n",
    "    data = soup.select(\"[type='application/ld+json']\")[0]\n",
    "    \n",
    "    # Get Hotel Name\n",
    "    name = json.loads(data.text)['name']\n",
    "    name_scrap.append(name)\n",
    "    \n",
    "    # Get Price\n",
    "    pricetag = json.loads(data.text)['priceRange']\n",
    "    price = int(pricetag.split(\"€\",1)[1].split()[0])\n",
    "    \n",
    "    # Get Stars\n",
    "    stars = soup.find(class_='star_track')['title']\n",
    "    \n",
    "    # Get Facilities    \n",
    "    facilities = {}\n",
    "    raw = soup.find_all(class_='facilitiesChecklistSection')\n",
    "    for i in raw:\n",
    "        dept = i.getText().split('\\n')\n",
    "        facilities_dept = [x for x in i.getText().split('\\n') if x]\n",
    "        dept = facilities_dept[0]\n",
    "        items = facilities_dept[1:]    \n",
    "        facilities[dept] = items\n",
    "        \n",
    "    # Append Information to Dicctionary\n",
    "    hotels[name] = {'Price': price, 'Stars': stars, 'Facilities': facilities, 'Header': json.loads(data.text)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name_scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 'The Adria Hotel']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[i for i in hotels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in hotels:\n",
    "#    print(hotels[i]['Header']['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the process in only one For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city = pickle.load(open('./hotel_city.sav', 'rb'))\n",
    "google_address = pickle.load(open('./google_address.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\"}\n",
    "bookingaddress = []\n",
    "hotels = {}\n",
    "name_scraped = []\n",
    "address_scraped = []\n",
    "begin = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://www.booking.com/hotel/gb/number-eleven.es.html\n",
      "1 https://www.booking.com/hotel/fr/1-k-hotel.es.html\n",
      "2 https://www.booking.com/hotel/at/25hours-wien.es.html\n",
      "3 https://www.booking.com/hotel/gb/41clubredcarnations.es.html\n",
      "4 https://www.booking.com/hotel/gb/parklane.es.html\n",
      "5 https://www.booking.com/hotel/gb/88-studios.es.html\n",
      "6 https://www.booking.com/hotel/fr/9hotel-republique.es.html\n",
      "7 https://www.booking.com/hotel/fr/a-la-villa-madame.es.html\n",
      "8 https://www.booking.com/hotel/es/abac-barcelona.es.html\n",
      "9 https://www.booking.com/hotel/es/achotelsbarcelona.es.html\n",
      "10 https://www.booking.com/hotel/es/ac-marriott-diagonal-lilla.es.html\n",
      "11 https://www.booking.com/hotel/es/acirla.es.html\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-4ef55387cb7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'/url?q=https://www.booking.com/hotel/'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mbkng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'&'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mbkng\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'.es.html'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mbkng\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbkng\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.es.html'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i, hotel in enumerate(google_address[begin:]):\n",
    "    \n",
    "    # Get Booking.com Address from Google\n",
    "    URL = hotel\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    bkng = []\n",
    "    for page in soup.find_all('a', href=True):\n",
    "        if page['href'][:37] == '/url?q=https://www.booking.com/hotel/':\n",
    "            bkng.append(page['href'][7:].split('&', 1)[0])\n",
    "    if bkng[0][-8:] != '.es.html':\n",
    "        bkng[0] = bkng[0][:-5]+'.es.html'\n",
    "        \n",
    "    bookingaddress.append(bkng[0])\n",
    "    print(i+begin,bkng[0])\n",
    "    time.sleep(6)\n",
    "        \n",
    "    # Open Booking.com webpage\n",
    "    URL = bkng[0]\n",
    "    page = requests.get(URL, headers=head)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Get Header\n",
    "    if len(soup.select(\"[type='application/ld+json']\")) > 0:\n",
    "        data = soup.select(\"[type='application/ld+json']\")[0]\n",
    "        hotel_header = json.loads(data.text)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Get Hotel Name\n",
    "    name = json.loads(data.text)['name']\n",
    "    name_scraped.append(name)\n",
    "    address_scraped.append(hotel)\n",
    "    \n",
    "    # Get Price\n",
    "    pricetag = json.loads(data.text)['priceRange']\n",
    "    if price != None:\n",
    "        price = int(pricetag.split(\"€\",1)[1].split()[0])\n",
    "    else:\n",
    "        price = np.nan\n",
    "        \n",
    "    # Get Stars\n",
    "    if soup.find(class_='star_track') != None: \n",
    "        stars = soup.find(class_='star_track')['title']\n",
    "    else:\n",
    "        stars = np.nan\n",
    "    \n",
    "    # Get Facilities    \n",
    "    facilities = {}\n",
    "    raw = soup.find_all(class_='facilitiesChecklistSection')\n",
    "    for i in raw:\n",
    "        dept = i.getText().split('\\n')\n",
    "        facilities_dept = [x for x in i.getText().split('\\n') if x]\n",
    "        dept = facilities_dept[0]\n",
    "        items = facilities_dept[1:]    \n",
    "        facilities[dept] = items\n",
    "        \n",
    "    # Append Information to Dicctionary\n",
    "    hotels[name] = {'Price': price, 'Stars': stars, 'Facilities': facilities, 'Header': hotel_header}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(hotels, open('./hotels.sav', 'wb'))\n",
    "pickle.dump(bookingaddress, open('./bookingaddress.sav', 'wb'))\n",
    "pickle.dump(name_scrap, open('./name_scrap.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
