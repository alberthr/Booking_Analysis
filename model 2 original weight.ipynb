{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Date'] = df['Review_Date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Month'] = df.Review_Month.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good       0.477339\n",
       "Average    0.231924\n",
       "Bad        0.181281\n",
       "Worse      0.109456\n",
       "Name: Diff_Recode, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 categories\n",
    "\n",
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -2:\n",
    "        tmp.append('Worse')\n",
    "    elif i < -0.5:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.5:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.5:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()/len(df.Diff_Recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Better     215560\n",
       "Average    156602\n",
       "Bad        140308\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 categories\n",
    "\n",
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.6:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.6:\n",
    "        tmp.append('Better')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 categories\n",
    "\n",
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i >= -0.6:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.sample(10000, random_state=1)\n",
    "df_test['test'] = 1\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502470, 37)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.drop(df_test.index)\n",
    "df_train['test'] = 0\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Categories and UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities = list(df_train.Nationality_Recode.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207278, 37)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced1 = None\n",
    "\n",
    "for i in nationalities:\n",
    "    tmp = df_train[df_train.Nationality_Recode == i]\n",
    "    n = 30000\n",
    "    if len(tmp) < 30000:\n",
    "        n = len(tmp)\n",
    "    tmp = tmp.sample(n)\n",
    "    balanced1 = pd.concat([balanced1, tmp])\n",
    "balanced1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59215, ['Good', 'Bad'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minclass = np.min(balanced1.Diff_Recode.value_counts())\n",
    "classes = list(balanced1.Diff_Recode.value_counts().index)\n",
    "minclass, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118430, 37)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced2 = None\n",
    "\n",
    "for i in classes:\n",
    "    tmp = balanced1[balanced1.Diff_Recode == i].sample(minclass)\n",
    "    balanced2 = pd.concat([balanced2, tmp])\n",
    "balanced2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balanced2.sample(50000, random_state=1)\n",
    "df2 = pd.concat([df_balanced, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'Diff_Recode'\n",
    "x_col_dummy = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode']\n",
    "x_col_normal = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance', 'test', 'Close_Landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummy = df2[x_col_dummy]\n",
    "X_normal = df2[x_col_normal]\n",
    "y = df2[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_dummy = X_dummy.fillna('Not Available')\n",
    "X_dummy = pd.get_dummies(X_dummy, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512470, 36)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([y, X_normal, X_dummy], axis=1, sort=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 58), (50000, 58))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_final[df_final.test==1]\n",
    "df_train = df_final[df_final.test==0]\n",
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (50000, 56), (10000,), (10000, 56))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train[y_col]\n",
    "X_train = df_train.drop([y_col,'test'], axis=1)\n",
    "y_test = df_test[y_col]\n",
    "X_test = df_test.drop([y_col,'test'], axis=1)\n",
    "y_train.shape, X_train.shape, y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 56), (10000,), (50000, 56), (50000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-cba31a847c78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mkap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcohen_kappa_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for i in range(5,6):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    print('Neighbours:', i, '|',\n",
    "          'Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b8628b63dd30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcohen_kappa_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2163\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2164\u001b[0m         \"\"\"\n\u001b[1;32m-> 2165\u001b[1;33m         \u001b[0mraw_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2166\u001b[0m         \u001b[0mencoded_labels\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_prediction_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m         \"\"\"\n\u001b[1;32m-> 2120\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m         \u001b[0mraw_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate=0.01, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6183, 0.14880396364329207)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5455, 0.09102843263062732)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 3000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6276  |  Kappa: 0.1548  |  F1-Score: 0.4207  |  Precision: 0.4927  |  Recall: 0.367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(pred, y_test), ' | ',\n",
    "      'Kappa:',round(cohen_kappa_score(pred, y_test),4), ' | ',\n",
    "      'F1-Score:',round(f1_score(pred, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Precision:',round(precision_score(pred, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Recall:',round(recall_score(pred, y_test, pos_label='Bad'),4)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.334 | Kappa: 0.034 | F1-Score: 0.442 | Precision: 0.962 | Recall: 0.287 | Mean: 0.270 | Threshold: 0.35\n",
      "Accuracy: 0.351 | Kappa: 0.044 | F1-Score: 0.446 | Precision: 0.951 | Recall: 0.291 | Mean: 0.280 | Threshold: 0.36\n",
      "Accuracy: 0.372 | Kappa: 0.058 | F1-Score: 0.451 | Precision: 0.940 | Recall: 0.297 | Mean: 0.294 | Threshold: 0.37\n",
      "Accuracy: 0.390 | Kappa: 0.065 | F1-Score: 0.452 | Precision: 0.916 | Recall: 0.300 | Mean: 0.302 | Threshold: 0.38\n",
      "Accuracy: 0.412 | Kappa: 0.077 | F1-Score: 0.455 | Precision: 0.895 | Recall: 0.305 | Mean: 0.315 | Threshold: 0.39\n",
      "Accuracy: 0.431 | Kappa: 0.085 | F1-Score: 0.455 | Precision: 0.867 | Recall: 0.309 | Mean: 0.324 | Threshold: 0.40\n",
      "Accuracy: 0.455 | Kappa: 0.096 | F1-Score: 0.457 | Precision: 0.835 | Recall: 0.314 | Mean: 0.336 | Threshold: 0.41\n",
      "Accuracy: 0.476 | Kappa: 0.106 | F1-Score: 0.457 | Precision: 0.804 | Recall: 0.320 | Mean: 0.347 | Threshold: 0.42\n",
      "Accuracy: 0.498 | Kappa: 0.115 | F1-Score: 0.456 | Precision: 0.766 | Recall: 0.324 | Mean: 0.356 | Threshold: 0.43\n",
      "Accuracy: 0.517 | Kappa: 0.119 | F1-Score: 0.452 | Precision: 0.726 | Recall: 0.328 | Mean: 0.363 | Threshold: 0.44\n",
      "Accuracy: 0.534 | Kappa: 0.122 | F1-Score: 0.447 | Precision: 0.685 | Recall: 0.331 | Mean: 0.367 | Threshold: 0.45\n",
      "Accuracy: 0.553 | Kappa: 0.127 | F1-Score: 0.442 | Precision: 0.645 | Recall: 0.336 | Mean: 0.374 | Threshold: 0.46\n",
      "Accuracy: 0.577 | Kappa: 0.140 | F1-Score: 0.441 | Precision: 0.609 | Recall: 0.346 | Mean: 0.386 | Threshold: 0.47\n",
      "Accuracy: 0.596 | Kappa: 0.146 | F1-Score: 0.435 | Precision: 0.568 | Recall: 0.353 | Mean: 0.393 | Threshold: 0.48\n",
      "Accuracy: 0.612 | Kappa: 0.150 | F1-Score: 0.428 | Precision: 0.528 | Recall: 0.359 | Mean: 0.396 | Threshold: 0.49\n",
      "Accuracy: 0.628 | Kappa: 0.155 | F1-Score: 0.421 | Precision: 0.493 | Recall: 0.367 | Mean: 0.401 | Threshold: 0.50\n",
      "Accuracy: 0.641 | Kappa: 0.157 | F1-Score: 0.411 | Precision: 0.456 | Recall: 0.374 | Mean: 0.403 | Threshold: 0.51\n",
      "Accuracy: 0.652 | Kappa: 0.153 | F1-Score: 0.397 | Precision: 0.418 | Recall: 0.378 | Mean: 0.401 | Threshold: 0.52\n",
      "Accuracy: 0.664 | Kappa: 0.154 | F1-Score: 0.385 | Precision: 0.383 | Recall: 0.387 | Mean: 0.401 | Threshold: 0.53\n",
      "Accuracy: 0.674 | Kappa: 0.149 | F1-Score: 0.368 | Precision: 0.346 | Recall: 0.392 | Mean: 0.397 | Threshold: 0.54\n",
      "Accuracy: 0.683 | Kappa: 0.147 | F1-Score: 0.354 | Precision: 0.316 | Recall: 0.401 | Mean: 0.395 | Threshold: 0.55\n"
     ]
    }
   ],
   "source": [
    "mat = clf.predict_proba(X_test)\n",
    "\n",
    "for threshold in np.arange(0.35, 0.55, 0.01):\n",
    "    pred = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "predictors = X_train.to_numpy()\n",
    "df_target = [1 if i=='Good' else 0 for i in y_train]\n",
    "target = to_categorical(df_target)\n",
    "pred_data = X_test.to_numpy()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x29d51cafe10>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(predictors, target, epochs=20, validation_split=0.3, callbacks=[early_stopping_monitor], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5874 | Kappa: 0.0965 | F1: 0.3918\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(pred_data)[:,1])\n",
    "pred = ['Good' if round(i) else 'Bad' for i in predictions]\n",
    "print('Accuracy:',accuracy_score(pred, y_test), '|', \n",
    "      'Kappa:', round(cohen_kappa_score(pred,y_test),4), '|', \n",
    "      'F1:',round(f1_score(pred,y_test, pos_label='Bad'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.403 | Kappa: 0.057 | F1-Score: 0.442 | Precision: 0.862 | Recall: 0.297 | Mean: 0.301 | Threshold: 0.40\n",
      "Accuracy: 0.440 | Kappa: 0.068 | F1-Score: 0.439 | Precision: 0.798 | Recall: 0.303 | Mean: 0.315 | Threshold: 0.42\n",
      "Accuracy: 0.487 | Kappa: 0.089 | F1-Score: 0.439 | Precision: 0.730 | Recall: 0.314 | Mean: 0.338 | Threshold: 0.44\n",
      "Accuracy: 0.533 | Kappa: 0.104 | F1-Score: 0.432 | Precision: 0.647 | Recall: 0.324 | Mean: 0.356 | Threshold: 0.46\n",
      "Accuracy: 0.580 | Kappa: 0.124 | F1-Score: 0.424 | Precision: 0.565 | Recall: 0.340 | Mean: 0.376 | Threshold: 0.48\n"
     ]
    }
   ],
   "source": [
    "mat = model.predict(pred_data)\n",
    "\n",
    "for threshold in np.arange(0.4, 0.5, 0.02):\n",
    "    pred = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
