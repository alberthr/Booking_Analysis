{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff_Percentage']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff_Percentage.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.917609\n",
       "Bad     0.082391\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 0.7 else 'Good' for i in df.Diff_Percentage])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode','Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 67), (10000,), (10000, 67), (10000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.5750 | 0.1501\n",
      "Train: 0.7141 | 0.4281\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6332 | 0.2675\n",
      "Train: 0.6494 | 0.2981\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6171 | 0.2363\n",
      "Train: 0.6298 | 0.2583\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 200, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6318 | 0.2646\n",
      "Train: 0.6521 | 0.3036\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 20, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6370 | 0.2744\n",
      "Train: 0.6324 | 0.2644\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6139 | 0.2256\n",
      "Train: 0.6249 | 0.2511\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6281 | 0.2574\n",
      "Train: 0.6443 | 0.2878\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6062 | 0.2122\n",
      "Train: 0.6039 | 0.2078\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST logistic   knn   xgb   gbt    rf   svm  tree    nb\n",
       "0  Good      Bad   Bad  Good  Good   Bad   Bad  Good   Bad\n",
       "1   Bad      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "2  Good     Good  Good  Good  Good  Good  Good  Good  Good\n",
       "3   Bad     Good  Good  Good  Good   Bad  Good  Good   Bad\n",
       "4   Bad      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465506</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102127</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic   gbt  knn  svm  tree   xgb   nb   rf\n",
       "465506      Bad  Good  Bad  Bad  Good  Good  Bad  Bad\n",
       "102127      Bad   Bad  Bad  Bad   Bad   Bad  Bad  Bad"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Test : 0.6350 | 0.2717\n",
      "Train: 0.6505 | 0.3015\n",
      "----------------------\n",
      "XGB\n",
      "Test : 0.6360 | 0.2724\n",
      "Train: 0.6591 | 0.3185\n",
      "----------------------\n",
      "GBT\n",
      "Test : 0.6385 | 0.2773\n",
      "Train: 0.6406 | 0.2815\n",
      "----------------------\n",
      "Logistic\n",
      "Test : 0.6415 | 0.2829\n",
      "Train: 0.6454 | 0.2909\n",
      "----------------------\n",
      "SVM\n",
      "Test : 0.6375 | 0.2768\n",
      "Train: 0.6462 | 0.2931\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 200, max_depth = 5, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 20, max_depth=3, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)   \n",
    "    # clf = GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    return(variable, acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=False):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          '| Variable to remove:', max_feature)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', score)\n",
    "            return(varin)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.646\n",
      "Seed: 1 <- 0.647\n",
      "Seed: 2 <- 0.6455\n",
      "Seed: 3 <- 0.6425\n",
      "Seed: 4 <- 0.652\n"
     ]
    }
   ],
   "source": [
    "for seed in range(5):\n",
    "    try_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 Original Score: 0.6415 | New score: 0.6420 | Variable to remove: food_Neg_Hotel\n",
      "01 Original Score: 0.6420 | New score: 0.6425 | Variable to remove: food_Pos_Hotel\n",
      "02 Original Score: 0.6425 | New score: 0.6430 | Variable to remove: Whom_Solo traveler\n",
      "03 Original Score: 0.6430 | New score: 0.6440 | Variable to remove: value_Neg_Hotel\n",
      "04 Original Score: 0.6440 | New score: 0.6445 | Variable to remove: Nationality_Recode_UK & Ireland\n",
      "05 Original Score: 0.6445 | New score: 0.6460 | Variable to remove: location_Pos_Hotel\n",
      "06 Original Score: 0.6460 | New score: 0.6470 | Variable to remove: Room_Recode_Other (Standard)\n",
      "07 Original Score: 0.6470 | New score: 0.6475 | Variable to remove: Room_Recode_Studio\n",
      "08 Original Score: 0.6475 | New score: 0.6480 | Variable to remove: Dist_Center\n",
      "09 Original Score: 0.6480 | New score: 0.6485 | Variable to remove: Dist_Train\n",
      "10 Original Score: 0.6485 | New score: 0.6490 | Variable to remove: Length_Recode_Stayed 8 nights\n",
      "11 Original Score: 0.6490 | New score: 0.6495 | Variable to remove: min\n",
      "12 Original Score: 0.6495 | New score: 0.6500 | Variable to remove: Whom_Travelers with friends\n",
      "13 Original Score: 0.6500 | New score: 0.6505 | Variable to remove: count\n",
      "14 Original Score: 0.6505 | New score: 0.6510 | Variable to remove: Stars_hotel de 5 estrellas\n",
      "15 Original Score: 0.6510 | New score: 0.6520 | Variable to remove: Stars_hotel de 3 estrellas\n",
      "Seed: 4 <- 0.652\n"
     ]
    }
   ],
   "source": [
    "varin = try_seed(4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  9.,  23.,  36.,  76., 105., 132., 149., 170., 182., 168., 157.,\n",
       "        141., 135., 136., 119.,  91.,  79.,  62.,  23.,   7.]),\n",
       " array([0.0912537 , 0.13333018, 0.17540666, 0.21748315, 0.25955963,\n",
       "        0.30163611, 0.34371259, 0.38578907, 0.42786556, 0.46994204,\n",
       "        0.51201852, 0.554095  , 0.59617148, 0.63824797, 0.68032445,\n",
       "        0.72240093, 0.76447741, 0.8065539 , 0.84863038, 0.89070686,\n",
       "        0.93278334]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>633</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>334</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       633   362\n",
       "Good      334   671"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6520 <- Accuracy\n",
      "0.3039 <- Kappa\n",
      "0.6453 <- F1\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(prediction, y_test_2):.4f}', '<- Accuracy')\n",
    "print(f'{cohen_kappa_score(prediction, y_test_2):.4f}', '<- Kappa')\n",
    "print(f'{f1_score(prediction, y_test_2, pos_label=\"Bad\"):.4f}', '<- F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.40 | Accuracy: 0.6140 | Kappa: 0.2372 | F1: 0.6690 | Avg: 0.6415\n",
      "Threshold: 0.41 | Accuracy: 0.6185 | Kappa: 0.2453 | F1: 0.6684 | Avg: 0.6435\n",
      "Threshold: 0.42 | Accuracy: 0.6215 | Kappa: 0.2505 | F1: 0.6667 | Avg: 0.6441\n",
      "Threshold: 0.43 | Accuracy: 0.6240 | Kappa: 0.2547 | F1: 0.6640 | Avg: 0.6440\n",
      "Threshold: 0.44 | Accuracy: 0.6230 | Kappa: 0.2517 | F1: 0.6566 | Avg: 0.6398\n",
      "Threshold: 0.45 | Accuracy: 0.6250 | Kappa: 0.2547 | F1: 0.6528 | Avg: 0.6389\n",
      "Threshold: 0.46 | Accuracy: 0.6265 | Kappa: 0.2568 | F1: 0.6478 | Avg: 0.6372\n",
      "Threshold: 0.47 | Accuracy: 0.6355 | Kappa: 0.2738 | F1: 0.6500 | Avg: 0.6428\n",
      "Threshold: 0.48 | Accuracy: 0.6315 | Kappa: 0.2650 | F1: 0.6403 | Avg: 0.6359\n",
      "Threshold: 0.49 | Accuracy: 0.6395 | Kappa: 0.2799 | F1: 0.6400 | Avg: 0.6398\n",
      "Threshold: 0.50 | Accuracy: 0.6520 | Kappa: 0.3039 | F1: 0.6453 | Avg: 0.6486\n",
      "Threshold: 0.51 | Accuracy: 0.6425 | Kappa: 0.2840 | F1: 0.6286 | Avg: 0.6355\n",
      "Threshold: 0.52 | Accuracy: 0.6400 | Kappa: 0.2781 | F1: 0.6182 | Avg: 0.6291\n",
      "Threshold: 0.53 | Accuracy: 0.6365 | Kappa: 0.2702 | F1: 0.6068 | Avg: 0.6217\n",
      "Threshold: 0.54 | Accuracy: 0.6320 | Kappa: 0.2602 | F1: 0.5934 | Avg: 0.6127\n",
      "Threshold: 0.55 | Accuracy: 0.6310 | Kappa: 0.2569 | F1: 0.5807 | Avg: 0.6058\n",
      "Threshold: 0.56 | Accuracy: 0.6305 | Kappa: 0.2547 | F1: 0.5681 | Avg: 0.5993\n",
      "Threshold: 0.57 | Accuracy: 0.6280 | Kappa: 0.2488 | F1: 0.5566 | Avg: 0.5923\n",
      "Threshold: 0.58 | Accuracy: 0.6180 | Kappa: 0.2276 | F1: 0.5330 | Avg: 0.5755\n",
      "Threshold: 0.59 | Accuracy: 0.6160 | Kappa: 0.2225 | F1: 0.5194 | Avg: 0.5677\n"
     ]
    }
   ],
   "source": [
    "prob_bad = probability[:,0]\n",
    "for thr in np.arange(0.4, 0.6, 0.01):\n",
    "    classification = ['Bad' if i > thr else 'Good' for i in prob_bad]\n",
    "    accuracy = accuracy_score(classification, y_test_2)\n",
    "    kappa = cohen_kappa_score(classification, y_test_2)\n",
    "    f1 = f1_score(classification, y_test_2, pos_label='Bad')\n",
    "    avg =np.mean([accuracy, f1])\n",
    "    print('Threshold:', f'{thr:.2f}', '| Accuracy:', f'{accuracy:.4f}', '| Kappa:', f'{kappa:.4f}', '| F1:', f'{f1:.4f}', \n",
    "          '| Avg:', f'{avg:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
