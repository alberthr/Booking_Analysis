{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fix the date because when Pandas opens the file it reads it incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Date'] = df['Review_Date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))\n",
    "df['Review_Month'] = df.Review_Month.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff_Percentage']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff_Percentage.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.917609\n",
       "Bad     0.082391\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 0.70 else 'Good' for i in df.Diff_Percentage])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 74), (10000,), (10000, 74), (10000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.5717 | 0.1434\n",
      "Train: 0.7194 | 0.4388\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6302 | 0.2617\n",
      "Train: 0.6440 | 0.2872\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6154 | 0.2331\n",
      "Train: 0.6309 | 0.2604\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 200, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6335 | 0.2682\n",
      "Train: 0.6525 | 0.3043\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 20, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6407 | 0.2817\n",
      "Train: 0.6351 | 0.2699\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6139 | 0.2256\n",
      "Train: 0.6249 | 0.2511\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6250 | 0.2513\n",
      "Train: 0.6662 | 0.3316\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6069 | 0.2136\n",
      "Train: 0.6043 | 0.2086\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST logistic   knn   xgb   gbt    rf   svm  tree    nb\n",
       "0  Good      Bad   Bad  Good   Bad   Bad   Bad  Good   Bad\n",
       "1   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "2  Good     Good  Good  Good  Good  Good  Good  Good  Good\n",
       "3   Bad     Good  Good  Good  Good   Bad  Good  Good   Bad\n",
       "4   Bad      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465506</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102127</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic  gbt   knn  svm  tree   xgb   nb   rf\n",
       "465506      Bad  Bad   Bad  Bad  Good  Good  Bad  Bad\n",
       "102127      Bad  Bad  Good  Bad   Bad   Bad  Bad  Bad"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Test : 0.6390 | 0.2794\n",
      "Train: 0.6546 | 0.3097\n",
      "----------------------\n",
      "XGB\n",
      "Test : 0.6350 | 0.2701\n",
      "Train: 0.6644 | 0.3289\n",
      "----------------------\n",
      "GBT\n",
      "Test : 0.6440 | 0.2881\n",
      "Train: 0.6414 | 0.2830\n",
      "----------------------\n",
      "Logistic\n",
      "Test : 0.6360 | 0.2715\n",
      "Train: 0.6470 | 0.2940\n",
      "----------------------\n",
      "SVM\n",
      "Test : 0.6375 | 0.2762\n",
      "Train: 0.6671 | 0.3346\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 200, max_depth = 5, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 20, max_depth=3, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)   \n",
    "    # clf = GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    return(variable, acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Original Score: 0.636 | New score: 0.6365 | Variable to remove: Average_Score\n",
      "1 Original Score: 0.6365 | New score: 0.639 | Variable to remove: Dist_Airport\n",
      "2 Original Score: 0.639 | New score: 0.6395 | Variable to remove: gbt\n",
      "3 Original Score: 0.6395 | New score: 0.6425 | Variable to remove: food_Neg_Hotel\n",
      "4 Original Score: 0.6425 | New score: 0.6445 | Variable to remove: svm\n",
      "5 Original Score: 0.6445 | New score: 0.646 | Variable to remove: Review_Month_5\n",
      "6 Original Score: 0.646 | New score: 0.647 | Variable to remove: cleanliness_Neg_Hotel\n",
      "7 Original Score: 0.647 | New score: 0.6475 | Variable to remove: Room_Recode_Executive\n",
      "8 Original Score: 0.6475 | New score: 0.6485 | Variable to remove: Whom_Family with young children\n",
      "9 Original Score: 0.6485 | New score: 0.649 | Variable to remove: staff_Neg_Hotel\n",
      "10 Original Score: 0.649 | New score: 0.65 | Variable to remove: staff_Pos_Hotel\n",
      "11 Original Score: 0.65 | New score: 0.6505 | Variable to remove: location_Pos_Hotel\n",
      "12 Original Score: 0.6505 | New score: 0.6535 | Variable to remove: value_Pos_Hotel\n",
      "13 Original Score: 0.6535 | New score: 0.654 | Variable to remove: comfort_Pos_Hotel\n",
      "14 Original Score: 0.654 | New score: 0.6545 | Variable to remove: 25%\n",
      "15 Original Score: 0.6545 | New score: 0.655 | Variable to remove: count\n",
      "16 Original Score: 0.655 | New score: 0.656 | Variable to remove: Review_Month_12\n",
      "17 Original Score: 0.656 | New score: 0.6565 | Variable to remove: Nationality_Recode_China\n",
      "18 Original Score: 0.6565 | New score: 0.657 | Variable to remove: Room_Recode_Studio\n",
      "End of process\n"
     ]
    }
   ],
   "source": [
    "score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "varout = []\n",
    "varin = list(X_test_2.columns)\n",
    "\n",
    "for n in range(len(varin)):\n",
    "    max_score = score\n",
    "    max_feature = []\n",
    "    \n",
    "    random.seed(6) # 6 (0.6570)\n",
    "    for i in sample(varin, len(varin)):\n",
    "        var_test = varin.copy()\n",
    "        var_test.remove(i)\n",
    "        X_train_vartest = X_train_2[var_test]\n",
    "        X_test_vartest = X_test_2[var_test]\n",
    "        check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "        if check[1] > max_score:\n",
    "            max_feature = check[0]\n",
    "            max_score = check[1] \n",
    "            varin.remove(max_feature)   \n",
    "            varout.append(max_feature)\n",
    "            print(n, 'Original Score:', score, '| New score:', max_score, '| Variable to remove:', max_feature)\n",
    "            break\n",
    "    \n",
    "    if max_score > score:\n",
    "        score = max_score\n",
    "    else:\n",
    "        print('End of process')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 14.,  24.,  52.,  92., 128., 147., 146., 154., 151., 171., 146.,\n",
       "        137., 149., 145.,  99.,  90.,  89.,  45.,  14.,   7.]),\n",
       " array([0.10977279, 0.15127387, 0.19277495, 0.23427602, 0.2757771 ,\n",
       "        0.31727818, 0.35877926, 0.40028034, 0.44178141, 0.48328249,\n",
       "        0.52478357, 0.56628465, 0.60778572, 0.6492868 , 0.69078788,\n",
       "        0.73228896, 0.77379004, 0.81529111, 0.85679219, 0.89829327,\n",
       "        0.93979435]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQXUlEQVR4nO3df7DldV3H8ecrNjT8EeheHNzdutgsJTI2MjfCnArFRn44LH9oA5O5GuNODpmlqUvORFPDDGplOZnTjhDYGLqZyY5oRoRRTWAXFWRBYgOCK+heRegHE4q+++N+aa6Xs3vOPd9zf+xnn4+ZO+d8P9/P95z3fObu6372c77n+01VIUlqy/etdQGSpMkz3CWpQYa7JDXIcJekBhnuktSgDWtdAMDGjRtrenp6rcuQpEPKzTff/PWqmhq0b12E+/T0NLOzs2tdhiQdUpL8x4H2uSwjSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNWhffUJVW0vTOa3odf++lZ0+oEmn1OHOXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGDQ33JJcn2Z/ktiXtb0pyZ5K9Sd69qP2iJPu6fa9YiaIlSQc3yuUHrgD+GPjQEw1JXgpsA15YVY8lObZrPxE4D3gB8Fzg75KcUFXfmXThkqQDGzpzr6obgIeWNL8RuLSqHuv67O/atwEfqarHquoeYB9wygTrlSSNYNw19xOAn05yU5J/SPITXfsm4P5F/ea6tidJsiPJbJLZ+fn5McuQJA0ybrhvAI4BTgXeBuxOEiAD+tagF6iqXVU1U1UzU1NTY5YhSRpk3HCfAz5eCz4HfBfY2LVvWdRvM/BAvxIlScs1brh/AngZQJITgCOBrwN7gPOSPCXJ8cBW4HOTKFSSNLqhZ8skuQo4DdiYZA64GLgcuLw7PfJbwPaqKmBvkt3A7cDjwIWeKSNJq29ouFfV+QfY9ZoD9L8EuKRPUZKkfvyGqiQ1yHuoatX0uZep9zGVlseZuyQ1yHCXpAYZ7pLUINfcdUjos14vHY6cuUtSg5y5S+uUZxepD2fuktQgw12SGuSyzGHI/+5L7TPctSyH41kr/jHUochwlxrkHyS55i5JDTLcJalBQ8M9yeVJ9nc35li67zeSVJKN3XaSvC/JviS3Jjl5JYqWJB3cKDP3K4AzljYm2QL8HHDfouYzWbi13lZgB/CB/iVKkpZraLhX1Q3AQwN2vRd4O1CL2rYBH+punH0jcHSS4yZSqSRpZGOtuSc5B/hKVd2yZNcm4P5F23Nd26DX2JFkNsns/Pz8OGVIkg5g2eGe5CjgncBvDdo9oK0GtFFVu6pqpqpmpqamlluGJOkgxjnP/UeA44FbkgBsBj6f5BQWZupbFvXdDDzQt0hJ0vIse+ZeVV+qqmOrarqqplkI9JOr6qvAHuC13VkzpwKPVNWDky1ZkjTM0Jl7kquA04CNSeaAi6vqsgN0/xRwFrAPeBR4/YTqlA5Jh+PlGrQ+DA33qjp/yP7pRc8LuLB/WZKkPvyGqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNcgbZB+C/Eq7pGGcuUtSgwx3SWqQ4S5JDTLcJalBhrskNWhouCe5PMn+JLctantPki8nuTXJXyc5etG+i5LsS3JnklesVOGSpAMbZeZ+BXDGkrZrgZOq6oXAvwEXASQ5ETgPeEF3zJ8kOWJi1UqSRjI03KvqBuChJW1/W1WPd5s3snAjbIBtwEeq6rGquoeF2+2dMsF6JUkjmMSa+y8Bn+6ebwLuX7Rvrmt7kiQ7kswmmZ2fn59AGZKkJ/QK9yTvBB4HPvxE04BuNejYqtpVVTNVNTM1NdWnDEnSEmNffiDJduCVwOndjbFhYaa+ZVG3zcAD45cnSRrHWDP3JGcA7wDOqapHF+3aA5yX5ClJjge2Ap/rX6YkaTmGztyTXAWcBmxMMgdczMLZMU8Brk0CcGNV/XJV7U2yG7idheWaC6vqOytVvCRpsKHhXlXnD2i+7CD9LwEu6VOUJKkfv6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQ0HBPcnmS/UluW9T2rCTXJrmrezyma0+S9yXZl+TWJCevZPGSpMFGmblfAZyxpG0ncF1VbQWu67YBzmThvqlbgR3AByZTpiRpOYaGe1XdADy0pHkbcGX3/Erg3EXtH6oFNwJHJzluUsVKkkYz7pr7c6rqQYDu8diufRNw/6J+c13bkyTZkWQ2yez8/PyYZUiSBhl6g+xlyoC2GtSxqnYBuwBmZmYG9pG0+qZ3XtPr+HsvPXtClaiPcWfuX3tiuaV73N+1zwFbFvXbDDwwfnmSpHGMG+57gO3d8+3A1YvaX9udNXMq8MgTyzeSpNUzdFkmyVXAacDGJHPAxcClwO4kFwD3Aa/uun8KOAvYBzwKvH4FapYkDTE03Kvq/APsOn1A3wIu7FuUJKkfv6EqSQ0y3CWpQYa7JDVo0ue5a0R9zyWWpINx5i5JDTLcJalBLstImqg+S45eumByDHdJ64Z/GCbHZRlJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhrUK9yT/HqSvUluS3JVkqcmOT7JTUnuSvLRJEdOqlhJ0mjGDvckm4BfBWaq6iTgCOA84F3Ae6tqK/BN4IJJFCpJGl3fZZkNwA8k2QAcBTwIvAz4WLf/SuDcnu8hSVqmscO9qr4C/B4L91B9EHgEuBl4uKoe77rNAZsGHZ9kR5LZJLPz8/PjliFJGqDPsswxwDbgeOC5wNOAMwd0rUHHV9Wuqpqpqpmpqalxy5AkDdBnWeblwD1VNV9V3wY+DvwUcHS3TAOwGXigZ42SpGXqE+73AacmOSpJgNOB24HrgVd1fbYDV/crUZK0XH3W3G9i4YPTzwNf6l5rF/AO4C1J9gHPBi6bQJ2SpGXodT33qroYuHhJ893AKX1eV5LUj99QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUG9wj3J0Uk+luTLSe5I8uIkz0pybZK7usdjJlWsJGk0fWfufwT8TVX9GPDjwB3ATuC6qtoKXNdtS5JW0djhnuSZwM/Q3Uavqr5VVQ8D24Aru25XAuf2LVKStDx9Zu7PA+aBP0vyhSQfTPI04DlV9SBA93jsoIOT7Egym2R2fn6+RxmSpKX6hPsG4GTgA1X1IuB/WMYSTFXtqqqZqpqZmprqUYYkaak+4T4HzFXVTd32x1gI+68lOQ6ge9zfr0RJ0nKNHe5V9VXg/iQ/2jWdDtwO7AG2d23bgat7VShJWrYNPY9/E/DhJEcCdwOvZ+EPxu4kFwD3Aa/u+R6SpGXqFe5V9UVgZsCu0/u8riSpH7+hKkkNMtwlqUGGuyQ1yHCXpAb1PVvmsDa985q1LkGSBnLmLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgzzPXVIT+nzv5N5Lz55gJeuDM3dJapDhLkkN6h3uSY7obpD9yW77+CQ3JbkryUe7G3lIklbRJGbubwbuWLT9LuC9VbUV+CZwwQTeQ5K0DL3CPclm4Gzgg912gJexcLNsgCuBc/u8hyRp+frO3P8QeDvw3W772cDDVfV4tz0HbBp0YJIdSWaTzM7Pz/csQ5K02NjhnuSVwP6qunlx84CuNej4qtpVVTNVNTM1NTVuGZKkAfqc5/4S4JwkZwFPBZ7Jwkz+6CQbutn7ZuCB/mVKkpZj7Jl7VV1UVZuraho4D/j7qvoF4HrgVV237cDVvauUJC3LSpzn/g7gLUn2sbAGf9kKvIck6SAmcvmBqvos8Nnu+d3AKZN4XUnSePyGqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0EQu+Xsom955zVqXIEkT1+ceqluSXJ/kjiR7k7y5a39WkmuT3NU9HjO5ciVJo+izLPM48Naqej5wKnBhkhOBncB1VbUVuK7bliStoj73UH2wqj7fPf8v4A5gE7ANuLLrdiVwbt8iJUnLM5EPVJNMAy8CbgKeU1UPwsIfAODYSbyHJGl0vcM9ydOBvwJ+rar+cxnH7Ugym2R2fn6+bxmSpEV6hXuS72ch2D9cVR/vmr+W5Lhu/3HA/kHHVtWuqpqpqpmpqak+ZUiSluhztkyAy4A7quoPFu3aA2zvnm8Hrh6/PEnSOPqc5/4S4BeBLyX5Ytf2m8ClwO4kFwD3Aa/uV6IkabnGDveq+icgB9h9+rivK0nqz8sPSFKDDHdJatAhf20Zrw0jqa++OXLvpWdPqJLJceYuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDvnz3CVprfU5T36lzpF35i5JDTLcJalBhrskNchwl6QGGe6S1KAVC/ckZyS5M8m+JDtX6n0kSU+2IuGe5Ajg/cCZwInA+UlOXIn3kiQ92UrN3E8B9lXV3VX1LeAjwLYVei9J0hIr9SWmTcD9i7bngJ9c3CHJDmBHt/nfSe5coVpWy0bg62tdxDrnGA3nGI2mmXHKu3od/sMH2rFS4T7oxtn1PRtVu4BdK/T+qy7JbFXNrHUd65ljNJxjNBrHabiVWpaZA7Ys2t4MPLBC7yVJWmKlwv1fga1Jjk9yJHAesGeF3kuStMSKLMtU1eNJfgX4DHAEcHlV7V2J91pHmlliWkGO0XCO0WgcpyFSVcN7SZIOKX5DVZIaZLhLUoMM92UYdkmFJG9JcnuSW5Ncl+SA56C2bNRLTyR5VZJKctid0jbKGCX5+e73aW+Sv1jtGtfaCP/efijJ9Um+0P2bO2st6ly3qsqfEX5Y+GD434HnAUcCtwAnLunzUuCo7vkbgY+udd3rcZy6fs8AbgBuBGbWuu71NkbAVuALwDHd9rFrXfc6HKNdwBu75ycC96513evpx5n76IZeUqGqrq+qR7vNG1k4v/9wM+qlJ34XeDfwv6tZ3Doxyhi9AXh/VX0ToKr2r3KNa22UMSrgmd3zH8Tv0nwPw310gy6psOkg/S8APr2iFa1PQ8cpyYuALVX1ydUsbB0Z5XfpBOCEJP+c5MYkZ6xadevDKGP028BrkswBnwLetDqlHRq8Qfbohl5S4f87Jq8BZoCfXdGK1qeDjlOS7wPeC7xutQpah0b5XdrAwtLMaSz8D/Afk5xUVQ+vcG3rxShjdD5wRVX9fpIXA3/ejdF3V7689c+Z++hGuqRCkpcD7wTOqarHVqm29WTYOD0DOAn4bJJ7gVOBPYfZh6qj/C7NAVdX1ber6h7gThbC/nAxyhhdAOwGqKp/AZ7KwgXFhOG+HEMvqdAtN/wpC8F+uK2RPuGg41RVj1TVxqqarqppFj6bOKeqZtem3DUxyuU5PsHCB/Qk2cjCMs3dq1rl2hpljO4DTgdI8nwWwn1+Vatcxwz3EVXV48ATl1S4A9hdVXuT/E6Sc7pu7wGeDvxlki8mOeyupzPiOB3WRhyjzwDfSHI7cD3wtqr6xtpUvPpGHKO3Am9IcgtwFfC66k6dkZcfkKQmOXOXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalB/wc/oDj5JK8BxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>625</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>342</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       625   363\n",
       "Good      342   670"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6393861892583119"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(prediction, y_test_2, pos_label='Bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 4, max_depth=5, random_state=1))]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    prob_stck_2 = clf.predict_proba(X_test_2)\n",
    "\n",
    "    pred[i[0]] = pred_stck_2\n",
    "    prob[i[0]] = prob_stck_2[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.6390 | 0.2783\n"
     ]
    }
   ],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test_2):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test_2):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
