{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hotel = df[['Hotel_Address','City','Country']].groupby(['Hotel_Address','City']).count().reset_index().\\\n",
    "            sort_values('Country', ascending = False).iloc[[0],[0]].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Hotel_Address == top_hotel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4789, 69)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.524535\n",
       "Bad     0.475465\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, Balance_Nationality, Balance_Category, cut):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = cut\n",
    "            if len(nationality) < n:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4789, 78)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_1 = balance_df(df, Balance_Nationality=False, Balance_Category=False, cut=10000)\n",
    "df_balanced_2 = balance_df(df_balanced_1, Balance_Nationality=False, Balance_Category=False, \n",
    "                         cut=int(np.median(df_balanced_1.Nationality_Recode.value_counts())*1.5))\n",
    "df_balanced_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UK & Ireland           3966\n",
       "Western Europe          404\n",
       "Eastern Europe           98\n",
       "Asia & Pacific           77\n",
       "North America            73\n",
       "Oceania                  51\n",
       "Middle east              44\n",
       "Sub-Saharian Africa      40\n",
       "South/Latin America      14\n",
       "China                    11\n",
       "Arab States               8\n",
       "Name: Nationality_Recode, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_2.Nationality_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4789, 78)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df_balanced_2) > 20000:\n",
    "    df_model = df_balanced_2.sample(n=20000, random_state=1)\n",
    "else:\n",
    "    df_model = df_balanced_2.copy()\n",
    "\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode']\n",
    "x_numerical = ['Total_Number_of_Reviews_Reviewer_Has_Given']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model['Review_Month'] = df_model['Review_Month'].astype(str)\n",
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3832, 38), (3832,), (957, 38), (957,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grid(model, params, X_train, X_test, y_train, y_test, verbose = 1):\n",
    "    f1 = make_scorer(f1_score, pos_label = \"Bad\")\n",
    "    clf = GridSearchCV(estimator = model, param_grid = params, n_jobs = -1, cv = 5, verbose = verbose)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_, clf.best_score_)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(clf.predict(X_test), y_test):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Test :', f'{precision_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}', \n",
    "          '| H Test :', f'{H_score(clf.predict(X_test), y_test):.4f}')\n",
    "    \n",
    "    print('Accuracy Train:', f'{accuracy_score(clf.predict(X_train), y_train):.4f}', \n",
    "          '| F1 Train:', f'{f1_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Train:', f'{precision_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}', \n",
    "          '| H Train:', f'{H_score(clf.predict(X_train), y_train):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_score(X_train, y_train):\n",
    "    acc = accuracy_score(X_train, y_train)\n",
    "    f1 = f1_score(X_train, y_train, pos_label = \"Bad\")\n",
    "    return(2 / ((1/acc)+(1/f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian(space, X, y, modelo, nevals):\n",
    "    \n",
    "    #H = make_scorer(H_score, greater_is_better=True) \n",
    "        \n",
    "    def objective(space):\n",
    "        \n",
    "        global best_score\n",
    "        \n",
    "        model = modelo(**space)   \n",
    "        kfold = KFold(n_splits=5, random_state=1985, shuffle=True)\n",
    "        score = -cross_val_score(model, X, y, cv=kfold, scoring='accuracy', verbose=False).mean()\n",
    "        if (score < best_score):\n",
    "            best_score = score\n",
    "        return score\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    best = fmin(\n",
    "      objective, \n",
    "      space = space,\n",
    "      algo = tpe.suggest, \n",
    "      max_evals = nevals,\n",
    "      trials = Trials())\n",
    "\n",
    "    print(\"Hyperopt search took %.2f seconds for 200 candidates\" % ((time.time() - start)))\n",
    "    print(\"Best score: %.4f \" % (-best_score))\n",
    "    print(\"Best space: \", space_eval(params, best))\n",
    "    return(space_eval(params, best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.5253 | F1 Test : 0.4886 | Precision Test : 0.4769 | H Test : 0.5063\n",
      "Accuracy Train: 0.6980 | F1 Train: 0.6792 | Precision Train: 0.6725 | H Train: 0.6885\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate_model(KNeighborsClassifier(n_neighbors=5), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:50<00:00,  1.00s/trial, best loss: -0.5799738219895288]\n",
      "Hyperopt search took 50.59 seconds for 200 candidates\n",
      "Best score: 0.5800 \n",
      "Best space:  {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 0.17, 'min_samples_split': 0.78, 'n_estimators': 358, 'subsample': 1}\n",
      "Accuracy Test : 0.5785 | F1 Test : 0.4923 | Precision Test : 0.4297 | H Test : 0.5320\n",
      "Accuracy Train: 0.5799 | F1 Train: 0.4820 | Precision Train: 0.4110 | H Train: 0.5264\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, \n",
    "                                                          0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.50]), \n",
    "          'n_estimators':      hp.choice('n_estimators', range(1,400)),\n",
    "          'max_depth':         hp.choice('max_depth',range(1,20)),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train, y_train, GradientBoostingClassifier, 50)\n",
    "pred_gbt = evaluate_model(GradientBoostingClassifier(**gbt_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:15<00:00,  2.72s/trial, best loss: -0.5809609511343804]\n",
      "Hyperopt search took 136.05 seconds for 200 candidates\n",
      "Best score: 0.5810 \n",
      "Best space:  {'bootstrap': True, 'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 0.02, 'min_samples_split': 0.02, 'n_estimators': 388}\n",
      "Accuracy Test : 0.5759 | F1 Test : 0.5083 | Precision Test : 0.4610 | H Test : 0.5400\n",
      "Accuracy Train: 0.6123 | F1 Train: 0.5380 | Precision Train: 0.4747 | H Train: 0.5728\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap':         hp.choice('bootstrap',[True, False]),\n",
    "          'max_depth':         hp.choice('max_depth', range(1, 20)),\n",
    "          'max_features':      hp.choice('max_features',['auto', 'sqrt']),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'n_estimators':      hp.choice('n_estimators',range(1,400))}\n",
    "\n",
    "best_score = 1\n",
    "rf_params = bayesian(params, X_train, y_train, RandomForestClassifier, 50)\n",
    "pred_rf = evaluate_model(RandomForestClassifier(**rf_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:06<00:00,  1.33s/trial, best loss: -0.5987892670157068]\n",
      "Hyperopt search took 66.71 seconds for 200 candidates\n",
      "Best score: 0.5988 \n",
      "Best space:  {'colsample_bytree': 0.9, 'gamma': 0.77, 'learning_rate': 0.025, 'max_depth': 2, 'min_child_weight': 0.3, 'n_estimators': 81}\n",
      "Accuracy Test : 0.5723 | F1 Test : 0.4974 | Precision Test : 0.4451 | H Test : 0.5322\n",
      "Accuracy Train: 0.6165 | F1 Train: 0.5349 | Precision Train: 0.4637 | H Train: 0.5728\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':    hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                                         0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', range(1,200))}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train, y_train, xgb.XGBClassifier, 50)\n",
    "pred_xgb = evaluate_model(xgb.XGBClassifier(**xgb_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.22trial/s, best loss: -0.5851767015706807]\n",
      "Hyperopt search took 5.44 seconds for 200 candidates\n",
      "Best score: 0.5852 \n",
      "Best space:  {'C': 0.025, 'tol': 5e-05}\n",
      "Accuracy Test : 0.5801 | F1 Test : 0.4939 | Precision Test : 0.4308 | H Test : 0.5335\n",
      "Accuracy Train: 0.6040 | F1 Train: 0.5033 | Precision Train: 0.4220 | H Train: 0.5490\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]),\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, \n",
    "                                  0.05, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train, y_train, LogisticRegression, 50)\n",
    "pred_log = evaluate_model(LogisticRegression(**log_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:10<00:00, 14.43trial/s, best loss: -0.5924901832460733]\n",
      "Hyperopt search took 10.43 seconds for 200 candidates\n",
      "Best score: 0.5925 \n",
      "Best space:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 33, 'min_samples_leaf': 41}\n",
      "Accuracy Test : 0.5814 | F1 Test : 0.5391 | Precision Test : 0.5148 | H Test : 0.5595\n",
      "Accuracy Train: 0.5904 | F1 Train: 0.5344 | Precision Train: 0.4945 | H Train: 0.5610\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "params = {\"max_depth\":        hp.choice('max_depth', range(1, 20)),\n",
    "          \"max_features\":     hp.choice('max_features', range(1, 38)),\n",
    "          \"min_samples_leaf\": hp.choice('min_samples_leaf', range(1, 50)),\n",
    "          \"criterion\":        hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best_score = 1\n",
    "tree_params = bayesian(params, X_train, y_train, DecisionTreeClassifier, 150)\n",
    "pred_tree = evaluate_model(DecisionTreeClassifier(**tree_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.62trial/s, best loss: -0.5914594240837696]\n",
      "Hyperopt search took 11.48 seconds for 200 candidates\n",
      "Best score: 0.5915 \n",
      "Best space:  {'C': 0.25, 'degree': 2, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.5793 | F1 Test : 0.5278 | Precision Test : 0.4945 | H Test : 0.5524\n",
      "Accuracy Train: 0.6134 | F1 Train: 0.5521 | Precision Train: 0.5011 | H Train: 0.5811\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train, y_train, SVC, 30)\n",
    "pred_svm = evaluate_model(SVC(**svm_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.86trial/s, best loss: -0.5893433682373473]\n",
      "Hyperopt search took 4.62 seconds for 200 candidates\n",
      "Best score: 0.5893 \n",
      "Best space:  {'alpha': 0.75, 'fit_prior': True}\n",
      "Accuracy Test : 0.5712 | F1 Test : 0.5023 | Precision Test : 0.4550 | H Test : 0.5345\n",
      "Accuracy Train: 0.6176 | F1 Train: 0.5448 | Precision Train: 0.4813 | H Train: 0.5789\n"
     ]
    }
   ],
   "source": [
    "params = {\"alpha\":     hp.choice('alpha', [0.025, 0.05, 0.075, 0.1, 0.15, 0.20, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, \n",
    "                                           2, 2.5, 5, 10]), \n",
    "          \"fit_prior\": hp.choice('fit_prior', [True, False])}\n",
    "\n",
    "best_score = 1\n",
    "nb_params = bayesian(params, X_train, y_train, BernoulliNB, 50)\n",
    "pred_nb = evaluate_model(BernoulliNB(**nb_params), X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
