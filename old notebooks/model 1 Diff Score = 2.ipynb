{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.890544\n",
       "Bad     0.109456\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < -2 else 'Good' for i in df.Diff])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode','Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 67), (10000,), (10000, 67), (10000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.5482 | 0.0963\n",
      "Train: 0.7046 | 0.4091\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6140 | 0.2283\n",
      "Train: 0.6382 | 0.2765\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6090 | 0.2186\n",
      "Train: 0.6267 | 0.2539\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6062 | 0.2129\n",
      "Train: 0.6387 | 0.2777\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6144 | 0.2289\n",
      "Train: 0.6236 | 0.2470\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6096 | 0.2194\n",
      "Train: 0.6106 | 0.2213\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6102 | 0.2208\n",
      "Train: 0.6415 | 0.2832\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.5975 | 0.1951\n",
      "Train: 0.5904 | 0.1807\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST logistic   knn   xgb   gbt    rf   svm  tree    nb\n",
       "0  Good     Good   Bad  Good  Good   Bad  Good  Good  Good\n",
       "1  Good     Good  Good  Good  Good  Good  Good  Good  Good\n",
       "2  Good      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "3   Bad      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "4   Bad      Bad  Good   Bad   Bad  Good  Good   Bad  Good"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>483844</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49888</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic   gbt   knn   svm  tree   xgb    nb    rf\n",
       "483844     Good  Good   Bad  Good  Good  Good  Good   Bad\n",
       "49888      Good  Good  Good  Good  Good  Good  Good  Good"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Test : 0.6065 | 0.2146\n",
      "Train: 0.6266 | 0.2533\n",
      "----------------------\n",
      "XGB\n",
      "Test : 0.6115 | 0.2237\n",
      "Train: 0.6272 | 0.2545\n",
      "----------------------\n",
      "GBT\n",
      "Test : 0.6090 | 0.2187\n",
      "Train: 0.6224 | 0.2448\n",
      "----------------------\n",
      "Logistic\n",
      "Test : 0.6265 | 0.2528\n",
      "Train: 0.6219 | 0.2438\n",
      "----------------------\n",
      "SVM\n",
      "Test : 0.6110 | 0.2231\n",
      "Train: 0.6268 | 0.2535\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 90, max_depth = 4, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 2, max_depth=4, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    return(variable, acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=False):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          '| Variable to remove:', max_feature)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', score)\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.635\n",
      "Seed: 1 <- 0.6395\n",
      "Seed: 2 <- 0.637\n",
      "Seed: 3 <- 0.6445\n",
      "Seed: 4 <- 0.634\n",
      "Seed: 5 <- 0.6355\n",
      "Seed: 6 <- 0.6425\n",
      "Seed: 7 <- 0.6405\n",
      "Seed: 8 <- 0.644\n",
      "Seed: 9 <- 0.6375\n",
      "Seed: 10 <- 0.6385\n",
      "Seed: 11 <- 0.6405\n",
      "Seed: 12 <- 0.645\n",
      "Seed: 13 <- 0.6405\n",
      "Seed: 14 <- 0.64\n",
      "Seed: 15 <- 0.6375\n",
      "Seed: 16 <- 0.6415\n",
      "Seed: 17 <- 0.6385\n",
      "Seed: 18 <- 0.6345\n",
      "Seed: 19 <- 0.6345\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "var_selec = []\n",
    "for seed in range(20):\n",
    "    varin, score = try_seed(seed)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        var_selec = varin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,  27.,  38.,  64.,  91., 119., 129., 168., 167., 198., 164.,\n",
       "        183., 164., 134., 132.,  88.,  58.,  42.,  18.,  12.]),\n",
       " array([0.11944471, 0.15764404, 0.19584336, 0.23404269, 0.27224202,\n",
       "        0.31044135, 0.34864068, 0.38684   , 0.42503933, 0.46323866,\n",
       "        0.50143799, 0.53963732, 0.57783665, 0.61603597, 0.6542353 ,\n",
       "        0.69243463, 0.73063396, 0.76883329, 0.80703261, 0.84523194,\n",
       "        0.88343127]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>619</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>347</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       619   379\n",
       "Good      347   655"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 4, max_depth=5, random_state=1))]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    prob_stck_2 = clf.predict_proba(X_test_2)\n",
    "\n",
    "    pred[i[0]] = pred_stck_2\n",
    "    prob[i[0]] = prob_stck_2[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.6200 | 0.2406\n"
     ]
    }
   ],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test_2):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test_2):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
