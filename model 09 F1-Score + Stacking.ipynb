{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials, space_eval\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(y_test, clf.predict(X_test)):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(y_test, clf.predict(X_test), pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Test :', f'{precision_score(y_test, clf.predict(X_test), pos_label=\"Bad\"):.4f}', \n",
    "          '| Recall Test :', f'{recall_score(y_test, clf.predict(X_test), pos_label=\"Bad\"):.4f}', \n",
    "          '| H Test :', f'{H_score(y_test, clf.predict(X_test)):.4f}')\n",
    "    \n",
    "    print('Accuracy Test :', f'{accuracy_score(y_train, clf.predict(X_train)):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(y_train, clf.predict(X_train), pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Test :', f'{precision_score(y_train, clf.predict(X_train), pos_label=\"Bad\"):.4f}', \n",
    "          '| Recall Test :', f'{recall_score(y_train, clf.predict(X_train), pos_label=\"Bad\"):.4f}', \n",
    "          '| H Test :', f'{H_score(y_train, clf.predict(X_train)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_score(X_train, y_train):\n",
    "    acc = accuracy_score(y_train, X_train)\n",
    "    f1 = f1_score(y_train, X_train, pos_label = \"Bad\")\n",
    "    return(2 / ((1/(acc+0.0000001))+(1/(f1+0.0000001))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian(space, X, y, modelo, nevals):\n",
    "    \n",
    "    f1 = make_scorer(f1_score, pos_label = \"Bad\")\n",
    "    \n",
    "    def objective(space):        \n",
    "        global best_score\n",
    "        model = modelo(**space, random_state = 1)   \n",
    "        cv =  StratifiedKFold(n_splits = 5, random_state = 1)\n",
    "        score = -cross_val_score(model, X, y, cv = cv, scoring = f1, verbose = False).mean()\n",
    "        if (score < best_score):\n",
    "            best_score = score\n",
    "        return score\n",
    "\n",
    "    start = time.time()\n",
    "    rstate = np.random.RandomState(1)\n",
    "    best = fmin(objective, space = space, algo = tpe.suggest, max_evals = nevals,trials = Trials(), rstate = rstate)\n",
    "\n",
    "    print(\"Hyperopt search took %.2f seconds\" % ((time.time() - start)))\n",
    "    print(\"Best score: %.4f \" % (-best_score))\n",
    "    print(\"Best space: \", space_eval(params, best))\n",
    "    return(space_eval(params, best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pickle.load(open('./sav/df_balanced.sav', 'rb'))\n",
    "df_subset = pickle.load(open('./sav/df_subset.sav', 'rb'))\n",
    "df_stacking = df_balanced.drop(df_subset.index).sample(n=10000, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_subset['Category']\n",
    "X = df_subset[df_subset.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 38), (2000,), (8000, 38), (8000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_stacking['Category']\n",
    "X = df_stacking[df_stacking.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pickle.load(open('./sav/model_f1.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = [Counter([y.iloc[k] for k in x]).most_common(1)[0][0] for x in models[0].query(X, k = 100)[1]]\n",
    "pred_log = models[1].predict(X)\n",
    "pred_svm = models[2].predict(X)\n",
    "pred_svm_2 = models[3].predict(X)\n",
    "pred_tree = models[4].predict(X)\n",
    "pred_rf = models[5].predict(X)\n",
    "pred_gbt = models[6].predict(X)\n",
    "pred_xgb = models[7].predict(X)\n",
    "pred_cat = models[8].predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['logistic'] = pred_log\n",
    "X['gbt'] = pred_gbt\n",
    "X['knn'] = pred_knn\n",
    "X['svm'] = pred_svm\n",
    "X['svm_2'] = pred_svm_2\n",
    "X['tree'] = pred_tree\n",
    "X['xgb'] = pred_xgb\n",
    "X['rf'] = pred_rf\n",
    "X['cat'] = pred_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>svm_2</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rf</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231987</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178130</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266651</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428706</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408969</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic   gbt   knn   svm svm_2  tree   xgb    rf   cat\n",
       "231987      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "178130     Good  Good  Good  Good  Good  Good  Good  Good  Good\n",
       "266651      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "428706      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "408969      Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad   Bad"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:,-9:].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,-9:] = X.iloc[:,-9:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:46<00:00,  3.32s/trial, best loss: -0.699247423326867]\n",
      "Hyperopt search took 166.28 seconds\n",
      "Best score: 0.6992 \n",
      "Best space:  {'learning_rate': 0.00075, 'max_depth': 18, 'max_features': 'sqrt', 'min_samples_leaf': 0.15000000000000002, 'min_samples_split': 0.12, 'n_estimators': 82, 'subsample': 1}\n",
      "Accuracy Test : 0.5950 | F1 Test : 0.6980 | Precision Test : 0.5625 | Recall Test : 0.9194 | H Test : 0.6424\n",
      "Accuracy Test : 0.5964 | F1 Test : 0.6993 | Precision Test : 0.5633 | Recall Test : 0.9217 | H Test : 0.6437\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, \n",
    "                                                          0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.50, 0.75, 1]), \n",
    "          'n_estimators':      hp.choice('n_estimators', range(1,400)),\n",
    "          'max_depth':         hp.choice('max_depth',range(1,20)),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train, y_train, GradientBoostingClassifier, 50)\n",
    "pred_gbt_stck = evaluate_model(GradientBoostingClassifier(**gbt_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [21:20<00:00, 25.60s/trial, best loss: -0.6682564734072931]\n",
      "Hyperopt search took 1280.32 seconds\n",
      "Best score: 0.6683 \n",
      "Best space:  {'colsample_bytree': 0.89, 'gamma': 0.68, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 0.55, 'n_estimators': 6}\n",
      "Accuracy Test : 0.6535 | F1 Test : 0.6787 | Precision Test : 0.6427 | Recall Test : 0.7191 | H Test : 0.6659\n",
      "Accuracy Test : 0.6535 | F1 Test : 0.6759 | Precision Test : 0.6452 | Recall Test : 0.7098 | H Test : 0.6645\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':    hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                                         0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', range(1,200))}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train, y_train, xgb.XGBClassifier, 50)\n",
    "pred_xgb_stck = evaluate_model(xgb.XGBClassifier(**xgb_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:41<00:00, 34.10s/trial, best loss: -0.696183616500966]\n",
      "Hyperopt search took 341.05 seconds\n",
      "Best score: 0.6962 \n",
      "Best space:  {'C': 0.0005, 'degree': 4, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.5775 | F1 Test : 0.6988 | Precision Test : 0.5484 | Recall Test : 0.9627 | H Test : 0.6324\n",
      "Accuracy Test : 0.5741 | F1 Test : 0.6964 | Precision Test : 0.5466 | Recall Test : 0.9592 | H Test : 0.6294\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train, y_train, SVC, 10)\n",
    "pred_svm_stck = evaluate_model(SVC(**svm_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [07:52<00:00, 47.28s/trial, best loss: -0.6631869662235699]\n",
      "Hyperopt search took 472.79 seconds\n",
      "Best score: 0.6632 \n",
      "Best space:  {'C': 5, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Accuracy Test : 0.6495 | F1 Test : 0.6670 | Precision Test : 0.6458 | Recall Test : 0.6896 | H Test : 0.6581\n",
      "Accuracy Test : 0.6560 | F1 Test : 0.6698 | Precision Test : 0.6550 | Recall Test : 0.6852 | H Test : 0.6628\n"
     ]
    }
   ],
   "source": [
    "params = {'C':      hp.choice('C', [1, 2, 5, 10, 15, 20]), \n",
    "          'gamma':  hp.choice('gamma', [0.0001, 0.001, 0.01, 0.1]),\n",
    "          'kernel': hp.choice('kernel', ['rbf'])}\n",
    "\n",
    "best_score = 1\n",
    "svm_params_2 = bayesian(params, X_train, y_train, SVC, 10)\n",
    "pred_svm_2 = evaluate_model(SVC(**svm_params_2, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:36<00:00,  1.37trial/s, best loss: -0.6615181023165619]\n",
      "Hyperopt search took 36.47 seconds\n",
      "Best score: 0.6615 \n",
      "Best space:  {'C': 0.01, 'tol': 0.0025}\n",
      "Accuracy Test : 0.6495 | F1 Test : 0.6628 | Precision Test : 0.6494 | Recall Test : 0.6768 | H Test : 0.6561\n",
      "Accuracy Test : 0.6556 | F1 Test : 0.6644 | Precision Test : 0.6593 | Recall Test : 0.6695 | H Test : 0.6600\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]),\n",
    "          \"\"\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, \n",
    "                                  0.05, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train, y_train, LogisticRegression, 50)\n",
    "pred_log_stck = evaluate_model(LogisticRegression(**log_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:29<00:00,  6.59s/trial, best loss: -0.6747286789792464]\n",
      "Hyperopt search took 329.53 seconds\n",
      "Best score: 0.6747 \n",
      "Best space:  {'bootstrap': True, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 0.4, 'min_samples_split': 0.8200000000000001, 'n_estimators': 387}\n",
      "Accuracy Test : 0.5090 | F1 Test : 0.6746 | Precision Test : 0.5090 | Recall Test : 1.0000 | H Test : 0.5802\n",
      "Accuracy Test : 0.5091 | F1 Test : 0.6747 | Precision Test : 0.5091 | Recall Test : 1.0000 | H Test : 0.5803\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap':         hp.choice('bootstrap',[True, False]),\n",
    "          'max_depth':         hp.choice('max_depth', range(1, 20)),\n",
    "          'max_features':      hp.choice('max_features',['auto', 'sqrt']),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'n_estimators':      hp.choice('n_estimators',range(1,400))}\n",
    "\n",
    "best_score = 1\n",
    "rf_params = bayesian(params, X_train, y_train, RandomForestClassifier, 50)\n",
    "pred_rf_stck = evaluate_model(RandomForestClassifier(**rf_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [35:39<00:00, 213.98s/trial, best loss: -0.6633100343455033]\n",
      "Hyperopt search took 2139.89 seconds\n",
      "Best score: 0.6633 \n",
      "Best space:  {'cat_features': (5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45), 'iterations': 1050, 'l2_leaf_reg': 2, 'learning_rate': 0.0075, 'verbose': False}\n",
      "Accuracy Test : 0.6525 | F1 Test : 0.6692 | Precision Test : 0.6491 | Recall Test : 0.6906 | H Test : 0.6607\n",
      "Accuracy Test : 0.6835 | F1 Test : 0.6941 | Precision Test : 0.6832 | Recall Test : 0.7054 | H Test : 0.6888\n"
     ]
    }
   ],
   "source": [
    "cat_features = [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,\n",
    "                38,39,40,41,42,43,44,45]\n",
    "params = {'iterations':        hp.choice('iterations', range(100, 4000, 25)), \n",
    "          'learning_rate':     hp.choice('learning_rate', [0.001, 0.0025, 0.0075, 0.01, 0.025, 0.05, 0.1]),\n",
    "          'l2_leaf_reg':       hp.choice('l2_leaf_reg', range(1, 10)), \n",
    "          'cat_features':      hp.choice('cat_features', [cat_features]), \n",
    "          'verbose':           hp.choice('verbose', [False])}\n",
    "\n",
    "best_score = 1\n",
    "cat_params = bayesian(params, X_train, y_train, CatBoostClassifier, 10)\n",
    "pred_cat = evaluate_model(CatBoostClassifier(**cat_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.34trial/s, best loss: -0.6734143768052325]\n",
      "Hyperopt search took 15.05 seconds\n",
      "Best score: 0.6734 \n",
      "Best space:  {'criterion': 'gini', 'max_depth': 8, 'max_features': 1, 'min_samples_leaf': 131}\n",
      "Accuracy Test : 0.5430 | F1 Test : 0.4961 | Precision Test : 0.5653 | Recall Test : 0.4420 | H Test : 0.5185\n",
      "Accuracy Test : 0.5581 | F1 Test : 0.4988 | Precision Test : 0.5903 | Recall Test : 0.4319 | H Test : 0.5268\n"
     ]
    }
   ],
   "source": [
    "params = {\"max_depth\":        hp.choice('max_depth', range(1, 50)),\n",
    "          \"max_features\":     hp.choice('max_features', range(1, X_train.columns.size)),\n",
    "          \"min_samples_leaf\": hp.choice('min_samples_leaf', range(1, 200)),\n",
    "          \"criterion\":        hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best_score = 1\n",
    "tree_params = bayesian(params, X_train, y_train, DecisionTreeClassifier, 50)\n",
    "pred_tree = evaluate_model(DecisionTreeClassifier(**tree_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.5950 | F1 Test : 0.6980 | Precision Test : 0.5625 | Recall Test : 0.9194 | H Test : 0.6424\n",
      "Accuracy Test : 0.5964 | F1 Test : 0.6993 | Precision Test : 0.5633 | Recall Test : 0.9217 | H Test : 0.6437\n"
     ]
    }
   ],
   "source": [
    "gbt_params = {'learning_rate': 0.00075, 'max_depth': 18, 'max_features': 'sqrt', \n",
    "              'min_samples_leaf': 0.15000000000000002, 'min_samples_split': 0.12, 'n_estimators': 82, 'subsample': 1}\n",
    "pred_gbt_stck = evaluate_model(GradientBoostingClassifier(**gbt_params, random_state=22), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>936</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>82</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       936   728\n",
       "Good       82   254"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pred_gbt_stck, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (LogisticRegression(**log_params, max_iter = 1000).fit(X_train, y_train),\n",
    "          SVC(**svm_params).fit(X_train, y_train),\n",
    "          SVC(**svm_params_2).fit(X_train, y_train),\n",
    "          DecisionTreeClassifier(**tree_params).fit(X_train, y_train),\n",
    "          RandomForestClassifier(**rf_params).fit(X_train, y_train),\n",
    "          GradientBoostingClassifier(**gbt_params).fit(X_train, y_train),\n",
    "          xgb.XGBClassifier(**xgb_params).fit(X_train, y_train),\n",
    "          CatBoostClassifier(**cat_params).fit(X_train, y_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(models, open('./sav/model_f1stack.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
