{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.834777\n",
       "Bad     0.165223\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Standard Rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other (Standard)    305992\n",
       "Deluxe              151710\n",
       "Executive            19707\n",
       "Suite                14209\n",
       "Studio                4773\n",
       "Name: Room_Recode, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Room_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Room_Recode == 'Other (Standard)']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode',\n",
    "                 'Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 67), (10000,), (10000, 67), (10000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6069 | 0.2140\n",
      "Train: 0.7287 | 0.4572\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6540 | 0.3081\n",
      "Train: 0.6743 | 0.3486\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6464 | 0.2928\n",
      "Train: 0.6605 | 0.3216\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6507 | 0.3015\n",
      "Train: 0.6704 | 0.3406\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6554 | 0.3110\n",
      "Train: 0.6635 | 0.3262\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6416 | 0.2838\n",
      "Train: 0.6493 | 0.2962\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6522 | 0.3045\n",
      "Train: 0.6682 | 0.3363\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6461 | 0.2924\n",
      "Train: 0.6405 | 0.2805\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST logistic   knn   xgb   gbt    rf   svm  tree    nb\n",
       "0  Good      Bad   Bad   Bad   Bad   Bad   Bad  Good   Bad\n",
       "1   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad  Good\n",
       "2   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "3  Good     Good  Good  Good  Good   Bad  Good  Good   Bad\n",
       "4   Bad     Good  Good  Good  Good  Good  Good  Good  Good"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1)),\n",
    "           ('GBT', GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))\n",
    "          ]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_ens = clf.predict(X_train)\n",
    "    pred_ens = clf.predict(X_test)\n",
    "    prob_ens = clf.predict_proba(X_test)\n",
    "\n",
    "    pred[i[0]] = pred_ens\n",
    "    prob[i[0]] = prob_ens[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.6532 | 0.3065\n"
     ]
    }
   ],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test):.4f}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508691</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249556</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic  gbt   knn  svm  tree  xgb    nb   rf\n",
       "508691      Bad  Bad   Bad  Bad  Good  Bad   Bad  Bad\n",
       "249556      Bad  Bad  Good  Bad   Bad  Bad  Good  Bad"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Test : 0.6640 | 0.3283\n",
      "Train: 0.6667 | 0.3335\n",
      "----------------------\n",
      "XGB\n",
      "Test : 0.6630 | 0.3261\n",
      "Train: 0.6631 | 0.3264\n",
      "----------------------\n",
      "GBT\n",
      "Test : 0.6655 | 0.3315\n",
      "Train: 0.6549 | 0.3096\n",
      "----------------------\n",
      "Logistic\n",
      "Test : 0.6735 | 0.3474\n",
      "Train: 0.6526 | 0.3052\n",
      "----------------------\n",
      "SVM\n",
      "Test : 0.6655 | 0.3312\n",
      "Train: 0.6575 | 0.3151\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 2, max_depth=4, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    f1 = f1_score(prediccion, y_test, pos_label='Bad')\n",
    "    return(variable, acc_score, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=False):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          '| Variable to remove:', max_feature)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', score)\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 <- 0.6825\n",
      "Seed: 1 <- 0.68\n",
      "Seed: 2 <- 0.685\n",
      "Seed: 3 <- 0.6795\n",
      "Seed: 4 <- 0.6835\n",
      "Seed: 5 <- 0.6825\n",
      "Seed: 6 <- 0.6805\n",
      "Seed: 7 <- 0.677\n",
      "Seed: 8 <- 0.68\n",
      "Seed: 9 <- 0.6825\n",
      "Seed: 10 <- 0.6795\n",
      "Seed: 11 <- 0.683\n",
      "Seed: 12 <- 0.6825\n",
      "Seed: 13 <- 0.68\n",
      "Seed: 14 <- 0.685\n",
      "Seed: 15 <- 0.68\n",
      "Seed: 16 <- 0.679\n",
      "Seed: 17 <- 0.6825\n",
      "Seed: 18 <- 0.6875\n",
      "Seed: 19 <- 0.68\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "varin = []\n",
    "for seed in range(20):\n",
    "    vartest, score = try_seed(seed)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        varin = vartest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,  34.,  52.,  73., 103., 120., 139., 130., 146., 143., 156.,\n",
       "        122., 156., 149., 148., 111.,  92.,  77.,  36.,   9.]),\n",
       " array([0.03932777, 0.08248227, 0.12563677, 0.16879127, 0.21194577,\n",
       "        0.25510028, 0.29825478, 0.34140928, 0.38456378, 0.42771828,\n",
       "        0.47087278, 0.51402728, 0.55718179, 0.60033629, 0.64349079,\n",
       "        0.68664529, 0.72979979, 0.77295429, 0.81610879, 0.85926329,\n",
       "        0.9024178 ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQwUlEQVR4nO3df4xlZX3H8fdHtmDxR0F2MLgLHWwWK5o2kinFmrYotoIYlj+wWaJ1tcRNlVpbrAL1D5o2JqBtbY3GdiuUpbEIpVY2/qhFxNI2gh1EkB8StkBhBN1RhP4wRVe//WMO7TDcYe7cM3Nn99n3K5ncc57znLnffbLzmTPPPT9SVUiS2vK0tS5AkrTyDHdJapDhLkkNMtwlqUGGuyQ1aN1aFwCwfv36mpycXOsyJGmfctNNN32rqiYGbdsrwn1ycpLp6em1LkOS9ilJ/n2xbUtOyyS5JMnuJLctaH9bkruS3J7kvfPaz0+yq9v2qn6lS5JGMcyR+6XAB4HLHm9I8nJgM/BTVfVYksO79mOBLcCLgOcBn0tyTFX9YKULlyQtbskj96q6Hnh4QfNbgAur6rGuz+6ufTPwsap6rKruBXYBx69gvZKkIYx6tswxwM8nuTHJPyb5ma59A/DAvH4zXduTJNmWZDrJ9Ozs7IhlSJIGGTXc1wGHAicA7wSuTBIgA/oOvHlNVW2vqqmqmpqYGPhhryRpRKOG+wzw8ZrzJeCHwPqu/ch5/TYCD/YrUZK0XKOG+yeAVwAkOQY4EPgWsBPYkuSgJEcDm4AvrUShkqThLXm2TJLLgROB9UlmgAuAS4BLutMjvwdsrbl7B9+e5ErgDmAPcLZnykjS+GVvuJ/71NRUeRGTJC1PkpuqamrQtr3iClVpbzZ53qdG3ve+C0/d595XbfDGYZLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGeRGT1CAvgJLhLukJ+vxiAH857C2clpGkBhnuktQgp2W0T3AOWVoej9wlqUGGuyQ1yHCXpAY5567m9T21T9oXLXnknuSSJLu756Uu3PY7SSrJ+m49ST6QZFeSW5MctxpFS5Ke2jDTMpcCJy9sTHIk8EvA/fOaTwE2dV/bgA/3L1GStFxLhntVXQ88PGDT+4F3AfOfsL0ZuKzm3AAckuSIFalUkjS0kT5QTXIa8PWqumXBpg3AA/PWZ7q2Qd9jW5LpJNOzs7OjlCFJWsSyP1BNcjDwbuCXB20e0FYD2qiq7cB2gKmpqYF9tPfxYiJp3zDK2TI/ARwN3JIEYCPw5STHM3ekfuS8vhuBB/sWKUlanmVPy1TVV6vq8KqarKpJ5gL9uKr6BrATeEN31swJwKNV9dDKlixJWsowp0JeDnwReEGSmSRnPUX3TwP3ALuAvwDeuiJVSpKWZclpmao6c4ntk/OWCzi7f1mSpD68/YAkNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ3yYR0aGx+aIY2PR+6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgYR6zd0mS3Ulum9f2viRfS3Jrkr9Lcsi8becn2ZXkriSvWq3CJUmLG+b2A5cCHwQum9d2DXB+Ve1JchFwPnBukmOBLcCLgOcBn0tyTFX9YGXLlvYN3nJBa2XJI/equh54eEHbP1TVnm71BmBjt7wZ+FhVPVZV9zL3oOzjV7BeSdIQVmLO/deAz3TLG4AH5m2b6dokSWPU666QSd4N7AE++njTgG61yL7bgG0ARx11VJ8ytExOFUjtG/nIPclW4DXA66rq8QCfAY6c120j8OCg/atqe1VNVdXUxMTEqGVIkgYYKdyTnAycC5xWVd+dt2knsCXJQUmOBjYBX+pfpiRpOZaclklyOXAisD7JDHABc2fHHARckwTghqr69aq6PcmVwB3MTdec7ZkykjR+S4Z7VZ05oPnip+j/HuA9fYqSJPXjFaqS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQb1uPyBJC/W5vcV9F566gpXs3zxyl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgbz+wD+pzebek/cOSR+5JLkmyO8lt89qek+SaJHd3r4d27UnygSS7ktya5LjVLF6SNNgw0zKXAicvaDsPuLaqNgHXdusApwCbuq9twIdXpkxJ0nIsGe5VdT3w8ILmzcCObnkHcPq89stqzg3AIUmOWKliJUnDGfUD1edW1UMA3evhXfsG4IF5/Wa6tidJsi3JdJLp2dnZEcuQJA2y0mfLZEBbDepYVduraqqqpiYmJla4DEnav40a7t98fLqle93dtc8AR87rtxF4cPTyJEmjGDXcdwJbu+WtwNXz2t/QnTVzAvDo49M3kqTxWfI89ySXAycC65PMABcAFwJXJjkLuB94bdf908CrgV3Ad4E3rULNkqQlLBnuVXXmIptOGtC3gLP7FiVJ6sfbD0hSgwx3SWqQ4S5JDTLcJalBhrskNchb/kraa/S5nfV9F566gpXs+zxyl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGtQr3JP8dpLbk9yW5PIkT09ydJIbk9yd5IokB65UsZKk4Ywc7kk2AL8JTFXVi4EDgC3ARcD7q2oT8B3grJUoVJI0vL7TMuuAH02yDjgYeAh4BXBVt30HcHrP95AkLdPI4V5VXwf+ELifuVB/FLgJeKSq9nTdZoANfYuUJC1Pn2mZQ4HNwNHA84BnAKcM6FqL7L8tyXSS6dnZ2VHLkCQN0Gda5pXAvVU1W1XfBz4O/BxwSDdNA7AReHDQzlW1vaqmqmpqYmKiRxmSpIX6hPv9wAlJDk4S4CTgDuA64Iyuz1bg6n4lSpKWq8+c+43MfXD6ZeCr3ffaDpwLnJNkF3AYcPEK1ClJWoZez1CtqguACxY03wMc3+f7StJy+fzVJ/IKVUlqkOEuSQ0y3CWpQYa7JDWo1weqGl2fD38kaSkeuUtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDWoV7gnOSTJVUm+luTOJC9N8pwk1yS5u3s9dKWKlSQNp++R+58Cf19VPwn8NHAncB5wbVVtAq7t1iVJYzRyuCd5NvALwMUAVfW9qnoE2Azs6LrtAE7vW6QkaXn6HLk/H5gF/jLJzUk+kuQZwHOr6iGA7vXwQTsn2ZZkOsn07OxsjzIkSQv1Cfd1wHHAh6vqJcB/s4wpmKraXlVTVTU1MTHRowxJ0kJ9wn0GmKmqG7v1q5gL+28mOQKge93dr0RJ0nKNHO5V9Q3ggSQv6JpOAu4AdgJbu7atwNW9KpQkLVvfB2S/DfhokgOBe4A3MfcL48okZwH3A6/t+R6SpGXqFe5V9RVgasCmk/p8X0lSP16hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoL6nQu7XJs/71FqXIEkDeeQuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb1DvckByS5Ocknu/Wjk9yY5O4kV3TPV5UkjdFKHLm/Hbhz3vpFwPurahPwHeCsFXgPSdIy9Ar3JBuBU4GPdOsBXgFc1XXZAZze5z0kScvX98j9T4B3AT/s1g8DHqmqPd36DLBh0I5JtiWZTjI9OzvbswxJ0nwjh3uS1wC7q+qm+c0Dutag/atqe1VNVdXUxMTEqGVIkgbo8ySmlwGnJXk18HTg2cwdyR+SZF139L4ReLB/mZKk5Rj5yL2qzq+qjVU1CWwBPl9VrwOuA87oum0Fru5dpSRpWVbjPPdzgXOS7GJuDv7iVXgPSdJTWJEHZFfVF4AvdMv3AMevxPeVpHHo+7D7+y48dYUqWTleoSpJDTLcJalBKzItsy/r++eYJO2NPHKXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0aOdyTHJnkuiR3Jrk9ydu79uckuSbJ3d3roStXriRpGH2O3PcA76iqFwInAGcnORY4D7i2qjYB13brkqQxGjncq+qhqvpyt/yfwJ3ABmAzsKPrtgM4vW+RkqTlWZE59ySTwEuAG4HnVtVDMPcLADh8kX22JZlOMj07O7sSZUiSOr3DPckzgb8Ffquq/mPY/apqe1VNVdXUxMRE3zIkSfP0CvckP8JcsH+0qj7eNX8zyRHd9iOA3f1KlCQtV5+zZQJcDNxZVX88b9NOYGu3vBW4evTyJEmjWNdj35cBvwp8NclXurbfBS4ErkxyFnA/8Np+JUqSlmvkcK+qfwayyOaTRv2+kqT+vEJVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIa1Of2A5IkYPK8T428730XnrqClfw/j9wlqUGGuyQ1yHCXpAYZ7pLUIMNdkhq0z58t0+dTaklqlUfuktQgw12SGrRq4Z7k5CR3JdmV5LzVeh9J0pOtSrgnOQD4EHAKcCxwZpJjV+O9JElPtlpH7scDu6rqnqr6HvAxYPMqvZckaYHVOltmA/DAvPUZ4Gfnd0iyDdjWrf5XkruA9cC3VqmmfZnjsjjHZjDHZXF71djkol67//hiG1Yr3DOgrZ6wUrUd2P6EnZLpqppapZr2WY7L4hybwRyXxe0vY7Na0zIzwJHz1jcCD67Se0mSFlitcP9XYFOSo5McCGwBdq7Se0mSFliVaZmq2pPkN4DPAgcAl1TV7UPsun3pLvslx2Vxjs1gjsvi9ouxSVUt3UuStE/xClVJapDhLkkNGnu4L3VbgiQHJbmi235jkslx17hWhhibc5LckeTWJNcmWfQc15YMeyuLJGckqSTNn+b2uGHGJsmvdP9vbk/y1+OucS0M8bN0VJLrktzc/Ty9ei3qXFVVNbYv5j5c/Tfg+cCBwC3AsQv6vBX4s255C3DFOGtcq68hx+blwMHd8lv2h7EZZly6fs8CrgduAKbWuu69ZWyATcDNwKHd+uFrXfdeMi7bgbd0y8cC96113Sv9Ne4j92FuS7AZ2NEtXwWclGTQRVGtWXJsquq6qvput3oDc9cPtG7YW1n8AfBe4H/GWdwaG2Zs3gx8qKq+A1BVu8dc41oYZlwKeHa3/GM0eB3OuMN90G0JNizWp6r2AI8Ch42lurU1zNjMdxbwmVWtaO+w5LgkeQlwZFV9cpyF7QWG+T9zDHBMkn9JckOSk8dW3doZZlx+D3h9khng08DbxlPa+Iz7SUxL3pZgyD4tGvrfneT1wBTwi6ta0d7hKcclydOA9wNvHFdBe5Fh/s+sY25q5kTm/tL7pyQvrqpHVrm2tTTMuJwJXFpVf5TkpcBfdePyw9UvbzzGfeQ+zG0J/q9PknXM/cn08FiqW1tD3bIhySuBdwOnVdVjY6ptLS01Ls8CXgx8Icl9wAnAzv3kQ9Vhf56urqrvV9W9wF3MhX3LhhmXs4ArAarqi8DTmbuhWDPGHe7D3JZgJ7C1Wz4D+Hx1n3o0bsmx6aYf/py5YN8f5k5hiXGpqkeran1VTVbVJHOfRZxWVdNrU+5YDfPz9AnmPognyXrmpmnuGWuV4zfMuNwPnASQ5IXMhfvsWKtcZWMN924O/fHbEtwJXFlVtyf5/SSndd0uBg5Lsgs4B9gvnuI05Ni8D3gm8DdJvpKk+fv1DDku+6Uhx+azwLeT3AFcB7yzqr69NhWPx5Dj8g7gzUluAS4H3tjaQaS3H5CkBnmFqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDfpfyQxauyADcIgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>705</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>284</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       705   341\n",
       "Good      284   670"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875 <- Accuracy\n",
      "0.3753 <- Kappa\n",
      "0.6929 <- F1\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(prediction, y_test_2):.4f}', '<- Accuracy')\n",
    "print(f'{cohen_kappa_score(prediction, y_test_2):.4f}', '<- Kappa')\n",
    "print(f'{f1_score(prediction, y_test_2, pos_label=\"Bad\"):.4f}', '<- F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.40 | Accuracy: 0.6505 | Kappa: 0.3039 | F1: 0.7042 | Avg: 0.6773\n",
      "Threshold: 0.41 | Accuracy: 0.6520 | Kappa: 0.3065 | F1: 0.6997 | Avg: 0.6759\n",
      "Threshold: 0.42 | Accuracy: 0.6530 | Kappa: 0.3083 | F1: 0.6969 | Avg: 0.6750\n",
      "Threshold: 0.43 | Accuracy: 0.6545 | Kappa: 0.3110 | F1: 0.6938 | Avg: 0.6742\n",
      "Threshold: 0.44 | Accuracy: 0.6540 | Kappa: 0.3098 | F1: 0.6886 | Avg: 0.6713\n",
      "Threshold: 0.45 | Accuracy: 0.6610 | Kappa: 0.3235 | F1: 0.6896 | Avg: 0.6753\n",
      "Threshold: 0.46 | Accuracy: 0.6650 | Kappa: 0.3312 | F1: 0.6892 | Avg: 0.6771\n",
      "Threshold: 0.47 | Accuracy: 0.6720 | Kappa: 0.3450 | F1: 0.6920 | Avg: 0.6820\n",
      "Threshold: 0.48 | Accuracy: 0.6770 | Kappa: 0.3548 | F1: 0.6933 | Avg: 0.6851\n",
      "Threshold: 0.49 | Accuracy: 0.6805 | Kappa: 0.3616 | F1: 0.6912 | Avg: 0.6858\n",
      "Threshold: 0.50 | Accuracy: 0.6875 | Kappa: 0.3753 | F1: 0.6929 | Avg: 0.6902\n",
      "Threshold: 0.51 | Accuracy: 0.6855 | Kappa: 0.3710 | F1: 0.6847 | Avg: 0.6851\n",
      "Threshold: 0.52 | Accuracy: 0.6805 | Kappa: 0.3608 | F1: 0.6748 | Avg: 0.6777\n",
      "Threshold: 0.53 | Accuracy: 0.6755 | Kappa: 0.3506 | F1: 0.6636 | Avg: 0.6695\n",
      "Threshold: 0.54 | Accuracy: 0.6705 | Kappa: 0.3404 | F1: 0.6533 | Avg: 0.6619\n",
      "Threshold: 0.55 | Accuracy: 0.6655 | Kappa: 0.3301 | F1: 0.6417 | Avg: 0.6536\n",
      "Threshold: 0.56 | Accuracy: 0.6685 | Kappa: 0.3359 | F1: 0.6383 | Avg: 0.6534\n",
      "Threshold: 0.57 | Accuracy: 0.6630 | Kappa: 0.3246 | F1: 0.6247 | Avg: 0.6439\n",
      "Threshold: 0.58 | Accuracy: 0.6595 | Kappa: 0.3173 | F1: 0.6142 | Avg: 0.6368\n",
      "Threshold: 0.59 | Accuracy: 0.6570 | Kappa: 0.3121 | F1: 0.6053 | Avg: 0.6311\n"
     ]
    }
   ],
   "source": [
    "prob_bad = probability[:,0]\n",
    "for thr in np.arange(0.4, 0.6, 0.01):\n",
    "    classification = ['Bad' if i > thr else 'Good' for i in prob_bad]\n",
    "    accuracy = accuracy_score(classification, y_test_2)\n",
    "    kappa = cohen_kappa_score(classification, y_test_2)\n",
    "    f1 = f1_score(classification, y_test_2, pos_label='Bad')\n",
    "    avg =np.mean([accuracy, f1])\n",
    "    print('Threshold:', f'{thr:.2f}', '| Accuracy:', f'{accuracy:.4f}', '| Kappa:', f'{kappa:.4f}', '| F1:', f'{f1:.4f}', \n",
    "          '| Avg:', f'{avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
