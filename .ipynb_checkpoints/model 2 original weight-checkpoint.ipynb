{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Date'] = df['Review_Date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Month'] = df.Review_Month.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good       0.477339\n",
       "Average    0.231924\n",
       "Bad        0.181281\n",
       "Worse      0.109456\n",
       "Name: Diff_Recode, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 categories\n",
    "\n",
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -2:\n",
    "        tmp.append('Worse')\n",
    "    elif i < -0.5:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.5:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.5:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()/len(df.Diff_Recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Better     215560\n",
       "Average    156602\n",
       "Bad        140308\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 categories\n",
    "\n",
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.6:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.6:\n",
    "        tmp.append('Better')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 categories\n",
    "\n",
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i >= -0.6:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 36)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.sample(10000, random_state=1)\n",
    "df_test['test'] = 1\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502470, 36)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.drop(df_test.index)\n",
    "df_train['test'] = 0\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Categories and UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities = list(df_train.Nationality_Recode.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207278, 36)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced1 = None\n",
    "\n",
    "for i in nationalities:\n",
    "    tmp = df_train[df_train.Nationality_Recode == i]\n",
    "    n = 30000\n",
    "    if len(tmp) < 30000:\n",
    "        n = len(tmp)\n",
    "    tmp = tmp.sample(n)\n",
    "    balanced1 = pd.concat([balanced1, tmp])\n",
    "balanced1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59170, ['Good', 'Bad'])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minclass = np.min(balanced1.Diff_Recode.value_counts())\n",
    "classes = list(balanced1.Diff_Recode.value_counts().index)\n",
    "minclass, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118340, 36)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced2 = None\n",
    "\n",
    "for i in classes:\n",
    "    tmp = balanced1[balanced1.Diff_Recode == i].sample(minclass)\n",
    "    balanced2 = pd.concat([balanced2, tmp])\n",
    "balanced2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balanced2.sample(50000, random_state=1)\n",
    "df2 = pd.concat([df_balanced, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'Diff_Recode'\n",
    "x_col_dummy = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode']\n",
    "x_col_normal = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummy = df2[x_col_dummy]\n",
    "X_normal = df2[x_col_normal]\n",
    "y = df2[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_dummy = X_dummy.fillna('Not Available')\n",
    "X_dummy = pd.get_dummies(X_dummy, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512470, 35)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([y, X_normal, X_dummy], axis=1, sort=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 53), (50000, 53))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_final[df_final.test==1]\n",
    "df_train = df_final[df_final.test==0]\n",
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (50000, 51), (10000,), (10000, 51))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train[y_col]\n",
    "X_train = df_train.drop([y_col,'test'], axis=1)\n",
    "y_test = df_test[y_col]\n",
    "X_test = df_test.drop([y_col,'test'], axis=1)\n",
    "y_train.shape, X_train.shape, y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 51), (10000,), (50000, 51), (50000,))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours: 1 | Accuracy: 0.525 | Kappa: 0.028 | F1-Score: 0.366 | Precision: 0.499 | Recall: 0.289 |\n",
      "Neighbours: 2 | Accuracy: 0.417 | Kappa: 0.024 | F1-Score: 0.411 | Precision: 0.742 | Recall: 0.284 |\n",
      "Neighbours: 3 | Accuracy: 0.541 | Kappa: 0.043 | F1-Score: 0.371 | Precision: 0.493 | Recall: 0.297 |\n",
      "Neighbours: 4 | Accuracy: 0.463 | Kappa: 0.045 | F1-Score: 0.411 | Precision: 0.683 | Recall: 0.294 |\n",
      "Neighbours: 5 | Accuracy: 0.554 | Kappa: 0.067 | F1-Score: 0.385 | Precision: 0.509 | Recall: 0.310 |\n",
      "Neighbours: 6 | Accuracy: 0.483 | Kappa: 0.048 | F1-Score: 0.406 | Precision: 0.643 | Recall: 0.296 |\n",
      "Neighbours: 7 | Accuracy: 0.553 | Kappa: 0.059 | F1-Score: 0.379 | Precision: 0.497 | Recall: 0.306 |\n",
      "Neighbours: 8 | Accuracy: 0.499 | Kappa: 0.053 | F1-Score: 0.403 | Precision: 0.617 | Recall: 0.299 |\n",
      "Neighbours: 9 | Accuracy: 0.558 | Kappa: 0.064 | F1-Score: 0.379 | Precision: 0.492 | Recall: 0.309 |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    print('Neighbours:', i, '|',\n",
    "          'Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6119, 0.14570635226429862)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate=0.01, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6183, 0.14880396364329207)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5455, 0.09102843263062732)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 3000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6276  |  Kappa: 0.1548  |  F1-Score: 0.4207  |  Precision: 0.4927  |  Recall: 0.367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(pred, y_test), ' | ',\n",
    "      'Kappa:',round(cohen_kappa_score(pred, y_test),4), ' | ',\n",
    "      'F1-Score:',round(f1_score(pred, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Precision:',round(precision_score(pred, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Recall:',round(recall_score(pred, y_test, pos_label='Bad'),4)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.334 | Kappa: 0.034 | F1-Score: 0.442 | Precision: 0.962 | Recall: 0.287 | Mean: 0.270 | Threshold: 0.35\n",
      "Accuracy: 0.351 | Kappa: 0.044 | F1-Score: 0.446 | Precision: 0.951 | Recall: 0.291 | Mean: 0.280 | Threshold: 0.36\n",
      "Accuracy: 0.372 | Kappa: 0.058 | F1-Score: 0.451 | Precision: 0.940 | Recall: 0.297 | Mean: 0.294 | Threshold: 0.37\n",
      "Accuracy: 0.390 | Kappa: 0.065 | F1-Score: 0.452 | Precision: 0.916 | Recall: 0.300 | Mean: 0.302 | Threshold: 0.38\n",
      "Accuracy: 0.412 | Kappa: 0.077 | F1-Score: 0.455 | Precision: 0.895 | Recall: 0.305 | Mean: 0.315 | Threshold: 0.39\n",
      "Accuracy: 0.431 | Kappa: 0.085 | F1-Score: 0.455 | Precision: 0.867 | Recall: 0.309 | Mean: 0.324 | Threshold: 0.40\n",
      "Accuracy: 0.455 | Kappa: 0.096 | F1-Score: 0.457 | Precision: 0.835 | Recall: 0.314 | Mean: 0.336 | Threshold: 0.41\n",
      "Accuracy: 0.476 | Kappa: 0.106 | F1-Score: 0.457 | Precision: 0.804 | Recall: 0.320 | Mean: 0.347 | Threshold: 0.42\n",
      "Accuracy: 0.498 | Kappa: 0.115 | F1-Score: 0.456 | Precision: 0.766 | Recall: 0.324 | Mean: 0.356 | Threshold: 0.43\n",
      "Accuracy: 0.517 | Kappa: 0.119 | F1-Score: 0.452 | Precision: 0.726 | Recall: 0.328 | Mean: 0.363 | Threshold: 0.44\n",
      "Accuracy: 0.534 | Kappa: 0.122 | F1-Score: 0.447 | Precision: 0.685 | Recall: 0.331 | Mean: 0.367 | Threshold: 0.45\n",
      "Accuracy: 0.553 | Kappa: 0.127 | F1-Score: 0.442 | Precision: 0.645 | Recall: 0.336 | Mean: 0.374 | Threshold: 0.46\n",
      "Accuracy: 0.577 | Kappa: 0.140 | F1-Score: 0.441 | Precision: 0.609 | Recall: 0.346 | Mean: 0.386 | Threshold: 0.47\n",
      "Accuracy: 0.596 | Kappa: 0.146 | F1-Score: 0.435 | Precision: 0.568 | Recall: 0.353 | Mean: 0.393 | Threshold: 0.48\n",
      "Accuracy: 0.612 | Kappa: 0.150 | F1-Score: 0.428 | Precision: 0.528 | Recall: 0.359 | Mean: 0.396 | Threshold: 0.49\n",
      "Accuracy: 0.628 | Kappa: 0.155 | F1-Score: 0.421 | Precision: 0.493 | Recall: 0.367 | Mean: 0.401 | Threshold: 0.50\n",
      "Accuracy: 0.641 | Kappa: 0.157 | F1-Score: 0.411 | Precision: 0.456 | Recall: 0.374 | Mean: 0.403 | Threshold: 0.51\n",
      "Accuracy: 0.652 | Kappa: 0.153 | F1-Score: 0.397 | Precision: 0.418 | Recall: 0.378 | Mean: 0.401 | Threshold: 0.52\n",
      "Accuracy: 0.664 | Kappa: 0.154 | F1-Score: 0.385 | Precision: 0.383 | Recall: 0.387 | Mean: 0.401 | Threshold: 0.53\n",
      "Accuracy: 0.674 | Kappa: 0.149 | F1-Score: 0.368 | Precision: 0.346 | Recall: 0.392 | Mean: 0.397 | Threshold: 0.54\n",
      "Accuracy: 0.683 | Kappa: 0.147 | F1-Score: 0.354 | Precision: 0.316 | Recall: 0.401 | Mean: 0.395 | Threshold: 0.55\n"
     ]
    }
   ],
   "source": [
    "mat = clf.predict_proba(X_test)\n",
    "\n",
    "for threshold in np.arange(0.35, 0.55, 0.01):\n",
    "    pred = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "predictors = X_train.to_numpy()\n",
    "df_target = [1 if i=='Good' else 0 for i in y_train]\n",
    "target = to_categorical(df_target)\n",
    "pred_data = X_test.to_numpy()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x29d51cafe10>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(predictors, target, epochs=20, validation_split=0.3, callbacks=[early_stopping_monitor], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5874 | Kappa: 0.0965 | F1: 0.3918\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(pred_data)[:,1])\n",
    "pred = ['Good' if round(i) else 'Bad' for i in predictions]\n",
    "print('Accuracy:',accuracy_score(pred, y_test), '|', \n",
    "      'Kappa:', round(cohen_kappa_score(pred,y_test),4), '|', \n",
    "      'F1:',round(f1_score(pred,y_test, pos_label='Bad'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.403 | Kappa: 0.057 | F1-Score: 0.442 | Precision: 0.862 | Recall: 0.297 | Mean: 0.301 | Threshold: 0.40\n",
      "Accuracy: 0.440 | Kappa: 0.068 | F1-Score: 0.439 | Precision: 0.798 | Recall: 0.303 | Mean: 0.315 | Threshold: 0.42\n",
      "Accuracy: 0.487 | Kappa: 0.089 | F1-Score: 0.439 | Precision: 0.730 | Recall: 0.314 | Mean: 0.338 | Threshold: 0.44\n",
      "Accuracy: 0.533 | Kappa: 0.104 | F1-Score: 0.432 | Precision: 0.647 | Recall: 0.324 | Mean: 0.356 | Threshold: 0.46\n",
      "Accuracy: 0.580 | Kappa: 0.124 | F1-Score: 0.424 | Precision: 0.565 | Recall: 0.340 | Mean: 0.376 | Threshold: 0.48\n"
     ]
    }
   ],
   "source": [
    "mat = model.predict(pred_data)\n",
    "\n",
    "for threshold in np.arange(0.4, 0.5, 0.02):\n",
    "    pred = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
