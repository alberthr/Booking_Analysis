{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode',\n",
    "                 'Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 67), (10000,), (10000, 67), (10000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6069 | 0.2140\n",
      "Train: 0.7287 | 0.4572\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6540 | 0.3081\n",
      "Train: 0.6743 | 0.3486\n"
     ]
    }
   ],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6464 | 0.2928\n",
      "Train: 0.6605 | 0.3216\n"
     ]
    }
   ],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6507 | 0.3015\n",
      "Train: 0.6704 | 0.3406\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6554 | 0.3110\n",
      "Train: 0.6635 | 0.3262\n"
     ]
    }
   ],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6416 | 0.2838\n",
      "Train: 0.6493 | 0.2962\n"
     ]
    }
   ],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6522 | 0.3045\n",
      "Train: 0.6682 | 0.3363\n"
     ]
    }
   ],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.6461 | 0.2924\n",
      "Train: 0.6405 | 0.2805\n"
     ]
    }
   ],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEST</th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEST logistic   knn   xgb   gbt    rf   svm  tree    nb\n",
       "0  Good      Bad   Bad   Bad   Bad   Bad   Bad  Good   Bad\n",
       "1   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad  Good\n",
       "2   Bad      Bad  Good   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "3  Good     Good  Good  Good  Good   Bad  Good  Good   Bad\n",
       "4   Bad     Good  Good  Good  Good  Good  Good  Good  Good"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1)),\n",
    "           ('GBT', GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))\n",
    "          ]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_ens = clf.predict(X_train)\n",
    "    pred_ens = clf.predict(X_test)\n",
    "    prob_ens = clf.predict_proba(X_test)\n",
    "\n",
    "    pred[i[0]] = pred_ens\n",
    "    prob[i[0]] = prob_ens[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability : 0.6532 | 0.3065\n"
     ]
    }
   ],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test):.4f}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>nb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508691</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249556</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic  gbt   knn  svm  tree  xgb    nb   rf\n",
       "508691      Bad  Bad   Bad  Bad  Good  Bad   Bad  Bad\n",
       "249556      Bad  Bad  Good  Bad   Bad  Bad  Good  Bad"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Test : 0.6655 | 0.3312\n",
      "Train: 0.6576 | 0.3153\n",
      "----------------------\n",
      "XGB\n",
      "Test : 0.6630 | 0.3261\n",
      "Train: 0.6631 | 0.3264\n",
      "----------------------\n",
      "GBT\n",
      "Test : 0.6655 | 0.3315\n",
      "Train: 0.6549 | 0.3096\n",
      "----------------------\n",
      "Logistic\n",
      "Test : 0.6735 | 0.3474\n",
      "Train: 0.6526 | 0.3052\n",
      "----------------------\n",
      "SVM\n",
      "Test : 0.6655 | 0.3312\n",
      "Train: 0.6575 | 0.3151\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 2, max_depth=4, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    f1 = f1_score(prediccion, y_test, pos_label='Bad')\n",
    "    return(variable, acc_score, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 Original Score: 0.6735 | New score: 0.6740 | Variable to remove: Nationality_Recode_Oceania\n",
      "01 Original Score: 0.6740 | New score: 0.6745 | Variable to remove: cleanliness_Pos_Hotel\n",
      "02 Original Score: 0.6745 | New score: 0.6750 | Variable to remove: Dist_Train\n",
      "03 Original Score: 0.6750 | New score: 0.6760 | Variable to remove: facilities_Neg_Hotel\n",
      "04 Original Score: 0.6760 | New score: 0.6765 | Variable to remove: Review_Month\n",
      "05 Original Score: 0.6765 | New score: 0.6770 | Variable to remove: Length_Recode_Stayed 6 nights\n",
      "06 Original Score: 0.6770 | New score: 0.6780 | Variable to remove: comfort_Pos_Hotel\n",
      "07 Original Score: 0.6780 | New score: 0.6790 | Variable to remove: cleanliness_Neg_Hotel\n",
      "08 Original Score: 0.6790 | New score: 0.6795 | Variable to remove: xgb\n",
      "09 Original Score: 0.6795 | New score: 0.6800 | Variable to remove: food_Pos_Hotel\n",
      "10 Original Score: 0.6800 | New score: 0.6805 | Variable to remove: Length_Recode_Stayed 8 nights\n",
      "11 Original Score: 0.6805 | New score: 0.6815 | Variable to remove: min\n",
      "12 Original Score: 0.6815 | New score: 0.6825 | Variable to remove: tree\n",
      "13 Original Score: 0.6825 | New score: 0.6835 | Variable to remove: mean\n",
      "14 Original Score: 0.6835 | New score: 0.6850 | Variable to remove: Nationality_Recode_South/Latin America\n",
      "End of process\n"
     ]
    }
   ],
   "source": [
    "score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]   # 1=Accuracy | 2=F1\n",
    "varout = []\n",
    "varin = list(X_test_2.columns)\n",
    "\n",
    "for n in range(len(varin)):\n",
    "    max_score = score\n",
    "    max_feature = []\n",
    "    \n",
    "    # random.seed(6) # 6 (0.6805)  # <- No Stars\n",
    "    random.seed(2) # 2 (0.6850)    # <- With Stars\n",
    "    for i in sample(varin, len(varin)):\n",
    "        var_test = varin.copy()\n",
    "        var_test.remove(i)\n",
    "        X_train_vartest = X_train_2[var_test]\n",
    "        X_test_vartest = X_test_2[var_test]\n",
    "        check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "        if check[1] > max_score:      # 1=Accuracy | 2=F1\n",
    "            max_feature = check[0]\n",
    "            max_score = check[1]      # 1=Accuracy | 2=F1\n",
    "            varin.remove(max_feature)   \n",
    "            varout.append(max_feature)\n",
    "            print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                  '| Variable to remove:', max_feature)\n",
    "            break\n",
    "    \n",
    "    if max_score > score:\n",
    "        score = max_score\n",
    "    else:\n",
    "        print('End of process')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12.,  40.,  52.,  76., 106., 121., 148., 149., 162., 121., 140.,\n",
       "        151., 142., 153., 111., 101.,  92.,  66.,  42.,  15.]),\n",
       " array([0.05212747, 0.09500608, 0.1378847 , 0.18076331, 0.22364192,\n",
       "        0.26652053, 0.30939914, 0.35227775, 0.39515636, 0.43803497,\n",
       "        0.48091358, 0.52379219, 0.5666708 , 0.60954941, 0.65242802,\n",
       "        0.69530663, 0.73818524, 0.78106385, 0.82394246, 0.86682107,\n",
       "        0.90969968]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQXElEQVR4nO3df7DldV3H8edLNjT8EeBeHNyFLjaLiYyNzo0wp1KpkV/D8gc2MKmr7biTkVmagjkTTQ0zq1ZkkzltQmBjIJEJk5oRQVQj2AV/8UNiA4Ir6F5U6AcTiL7743yx2+Ve7rnne869u599PmZ2zvl+vp9zz5vP3H3th8/5ns83VYUkqS1PW+8CJEnjZ7hLUoMMd0lqkOEuSQ0y3CWpQRvWuwCAjRs31vT09HqXIUn7lJtuuunBqppa6txeEe7T09PMzs6udxmStE9J8u/LnXNZRpIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgFcM9yUVJ9iS5ZVH7W5PckeTWJO9b0P7uJLu7c6+ZRNGSpKc2zDdULwb+EPjIEw1JXgVsBV5SVY8mOaxrPwY4E3gx8Hzg75IcXVXfGXfh2r9Mn/vJkV97z85TxliJtG9YceZeVdcD31zU/BZgZ1U92vXZ07VvBS6rqker6m5gN3DcGOuVJA1h1DX3o4GfSHJjkn9I8qNd+ybgvgX95rq2J0myI8lsktn5+fkRy5AkLWXUcN8AHAIcD7wTuDxJgCzRd8mbtFbVrqqaqaqZqaklNzWTJI1o1HCfAz5eA58Dvgts7NqPWNBvM3B/vxIlSas1arh/Ang1QJKjgQOBB4GrgDOTPD3JUcAW4HPjKFSSNLwVr5ZJcinwSmBjkjngPOAi4KLu8sjHgG1VVcCtSS4HbgMeB872ShlJWnsrhntVnbXMqdct0/984Pw+RUmS+vEbqpLUIMNdkhpkuEtSg/aKG2RLGi+3a5Azd0lqkOEuSQ1yWUaaIJdHtF6cuUtSg5y5a830mcVKWh1n7pLUIGfuWhVn39K+wZm7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatAwt9m7CDgV2FNVxy4692vA+4GpqnowSYAPACcDjwBvrKqbx1+21D4vO1Ufw8zcLwZOXNyY5AjgZ4B7FzSfxOCm2FuAHcCH+pcoSVqtFcO9qq4HvrnEqQuAdwG1oG0r8JEauAE4OMnhY6lUkjS0kb6hmuQ04KtV9cXBSsz3bALuW3A817U9sMTP2MFgds+RRx45ShnSmnB5RPuiVX+gmuQg4D3Abyx1eom2WqKNqtpVVTNVNTM1NbXaMiRJT2GUmfsPAUcBT8zaNwM3JzmOwUz9iAV9NwP39y1SkrQ6q565V9WXq+qwqpquqmkGgf6yqvoacBXwhgwcDzxcVU9akpEkTdaK4Z7kUuCzwAuTzCXZ/hTdPwXcBewG/gT4xbFUKUlalRWXZarqrBXOTy94XsDZ/cuSJPXhN1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0a5k5MFyXZk+SWBW3vT/KVJF9K8ldJDl5w7t1Jdie5I8lrJlW4JGl5w8zcLwZOXNR2NXBsVb0E+Ffg3QBJjgHOBF7cveaPkhwwtmolSUMZ5jZ71yeZXtT2twsObwDO6J5vBS6rqkeBu5PsBo5jcA9W7SWmz/3kepewpva3/14JxrPm/vPAp7vnm4D7Fpyb69qeJMmOJLNJZufn58dQhiTpCb3CPcl7gMeBjz7RtES3Wuq1VbWrqmaqamZqaqpPGZKkRVZclllOkm3AqcAJVfVEgM8BRyzothm4f/TyJEmjGGnmnuRE4BzgtKp6ZMGpq4Azkzw9yVHAFuBz/cuUJK3GijP3JJcCrwQ2JpkDzmNwdczTgauTANxQVb9QVbcmuRy4jcFyzdlV9Z1JFS9JWtowV8uctUTzhU/R/3zg/D5FSZL68RuqktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUEjf0NVUpv6brR2z85TxlSJ+nDmLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIK+W2Qd52zhJK3HmLkkNMtwlqUGGuyQ1yHCXpAatGO5JLkqyJ8ktC9oOTXJ1kju7x0O69iT5gyS7k3wpycsmWbwkaWnDzNwvBk5c1HYucE1VbQGu6Y4BTmJwU+wtwA7gQ+MpU5K0GsPcQ/X6JNOLmrcyuGk2wCXAdcA5XftHqqqAG5IcnOTwqnpgXAVL2rv1uVTXTcfGZ9Q19+c9Edjd42Fd+ybgvgX95rq2J0myI8lsktn5+fkRy5AkLWXcH6hmibZaqmNV7aqqmaqamZqaGnMZkrR/GzXcv57kcIDucU/XPgccsaDfZuD+0cuTJI1i1HC/CtjWPd8GXLmg/Q3dVTPHAw+73i5Ja2/FD1STXMrgw9ONSeaA84CdwOVJtgP3Aq/tun8KOBnYDTwCvGkCNUuSVjDM1TJnLXPqhCX6FnB236IkSf34DVVJapDhLkkNMtwlqUGGuyQ1yDsxSdpruHXB+Dhzl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGtQr3JP8apJbk9yS5NIkz0hyVJIbk9yZ5GNJDhxXsZKk4Ywc7kk2Ab8MzFTVscABwJnAe4ELqmoL8C1g+zgKlSQNr++yzAbg+5NsAA4CHgBeDVzRnb8EOL3ne0iSVmnkcK+qrwK/w+AG2Q8ADwM3AQ9V1eNdtzlgU98iJUmr02dZ5hBgK3AU8HzgmcBJS3StZV6/I8lsktn5+flRy5AkLaHPssxPA3dX1XxVfRv4OPDjwMHdMg3AZuD+pV5cVbuqaqaqZqampnqUIUlarE+43wscn+SgJAFOAG4DrgXO6PpsA67sV6IkabX6rLnfyOCD05uBL3c/axdwDvD2JLuB5wIXjqFOSdIq9LqHalWdB5y3qPku4Lg+P1eS1I83yF4nfW4ELEkrcfsBSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQe4tI6kJffZrumfnKWOsZO/gzF2SGmS4S1KDDHdJapDhLkkN6hXuSQ5OckWSryS5PcnLkxya5Ookd3aPh4yrWEnScPrO3D8A/E1V/TDwI8DtwLnANVW1BbimO5YkraGRwz3Jc4CfpLsBdlU9VlUPAVuBS7pulwCn9y1SkrQ6fWbuLwDmgT9N8vkkH07yTOB5VfUAQPd42FIvTrIjyWyS2fn5+R5lSJIW6xPuG4CXAR+qqpcC/80qlmCqaldVzVTVzNTUVI8yJEmL9Qn3OWCuqm7sjq9gEPZfT3I4QPe4p1+JkqTVGjncq+prwH1JXtg1nQDcBlwFbOvatgFX9qpQkrRqffeWeSvw0SQHAncBb2LwD8blSbYD9wKv7fkekqRV6hXuVfUFYGaJUyf0+bmSpH78hqokNchwl6QGGe6S1CDDXZIa5J2Yeuhz5xdJmiRn7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUO+Nw5IcAMwCX62qU5McBVwGHArcDLy+qh7r+z6SNCl9NwG8Z+cpY6pkfMYxc38bcPuC4/cCF1TVFuBbwPYxvIckaRV6hXuSzcApwIe74wCvBq7oulwCnN7nPSRJq9d3Web3gXcBz+6Onws8VFWPd8dzwKalXphkB7AD4Mgjj+xZxujck11Si0aeuSc5FdhTVTctbF6iay31+qraVVUzVTUzNTU1ahmSpCX0mbm/AjgtycnAM4DnMJjJH5xkQzd73wzc379MSdJqjDxzr6p3V9XmqpoGzgT+vqp+DrgWOKPrtg24sneVkqRVmcR17ucAb0+ym8Ea/IUTeA9J0lMYyw2yq+o64Lru+V3AceP4uZKk0fgNVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg/rcIPuIJNcmuT3JrUne1rUfmuTqJHd2j4eMr1xJ0jD6zNwfB95RVS8CjgfOTnIMcC5wTVVtAa7pjiVJa6jPDbIfqKqbu+f/CdwObAK2Apd03S4BTu9bpCRpdcay5p5kGngpcCPwvKp6AAb/AACHLfOaHUlmk8zOz8+PowxJUqd3uCd5FvCXwK9U1X8M+7qq2lVVM1U1MzU11bcMSdICvcI9yfcxCPaPVtXHu+avJzm8O384sKdfiZKk1epztUyAC4Hbq+r3Fpy6CtjWPd8GXDl6eZKkUWzo8dpXAK8HvpzkC13brwM7gcuTbAfuBV7br0RJ0mqNHO5V9U9Aljl9wqg/V5LUn99QlaQG9VmWkSQB0+d+cuTX3rPzlDFW8n+cuUtSgwx3SWrQPr8s0+d/hySpVc7cJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgiYV7khOT3JFkd5JzJ/U+kqQnm0i4JzkA+CBwEnAMcFaSYybxXpKkJ5vUzP04YHdV3VVVjwGXAVsn9F6SpEUmtZ/7JuC+BcdzwI8t7JBkB7CjO/yvJHdMqJZ90UbgwfUuYi/l2CzPsVneXjs2eW+vl//gcicmFe5Zoq3+30HVLmDXhN5/n5Zktqpm1ruOvZFjszzHZnn749hMallmDjhiwfFm4P4JvZckaZFJhfu/AFuSHJXkQOBM4KoJvZckaZGJLMtU1eNJfgn4DHAAcFFV3TqJ92qUy1XLc2yW59gsb78bm1TVyr0kSfsUv6EqSQ0y3CWpQYb7Olppi4Ykb09yW5IvJbkmybLXtLZm2O0rkpyRpJLsN5e5DTM2SX62+925Ncmfr3WN62WIv1NHJrk2yee7v1cnr0eda6Kq/LMOfxh80PxvwAuAA4EvAscs6vMq4KDu+VuAj6133XvL2HT9ng1cD9wAzKx33XvL2ABbgM8Dh3THh6133XvR2OwC3tI9Pwa4Z73rntQfZ+7rZ8UtGqrq2qp6pDu8gcH3BfYHw25f8dvA+4D/Wcvi1tkwY/Nm4INV9S2AqtqzxjWul2HGpoDndM9/gIa/f2O4r5+ltmjY9BT9twOfnmhFe48VxybJS4Ejquqv17KwvcAwvzdHA0cn+eckNyQ5cc2qW1/DjM1vAq9LMgd8Cnjr2pS29ia1/YBWtuIWDd/rmLwOmAF+aqIV7T2ecmySPA24AHjjWhW0Fxnm92YDg6WZVzL4v71/THJsVT004drW2zBjcxZwcVX9bpKXA3/Wjc13J1/e2nLmvn6G2qIhyU8D7wFOq6pH16i29bbS2DwbOBa4Lsk9wPHAVfvJh6rD/N7MAVdW1ber6m7gDgZh37phxmY7cDlAVX0WeAaDTcWaY7ivnxW3aOiWHv6YQbDvL+umsMLYVNXDVbWxqqaraprB5xGnVdXs+pS7pobZ2uMTDD6MJ8lGBss0d61pletjmLG5FzgBIMmLGIT7/JpWuUYM93VSVY8DT2zRcDtweVXdmuS3kpzWdXs/8CzgL5J8Icl+sT/PkGOzXxpybD4DfCPJbcC1wDur6hvrU/HaGXJs3gG8OckXgUuBN1Z36Uxr3H5AkhrkzF2SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb9L2LAOI1+OOXtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>706</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>283</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       706   347\n",
       "Good      283   664"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6825 <- Accuracy\n",
      "0.3654 <- Kappa\n",
      "0.6904 <- F1\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(prediction, y_test_2):.4f}', '<- Accuracy')\n",
    "print(f'{cohen_kappa_score(prediction, y_test_2):.4f}', '<- Kappa')\n",
    "print(f'{f1_score(prediction, y_test_2, pos_label=\"Bad\"):.4f}', '<- F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.40 | Accuracy: 0.6460 | Kappa: 0.2950 | F1: 0.7015 | Avg: 0.6738\n",
      "Threshold: 0.41 | Accuracy: 0.6440 | Kappa: 0.2908 | F1: 0.6968 | Avg: 0.6704\n",
      "Threshold: 0.42 | Accuracy: 0.6510 | Kappa: 0.3045 | F1: 0.6981 | Avg: 0.6745\n",
      "Threshold: 0.43 | Accuracy: 0.6545 | Kappa: 0.3112 | F1: 0.6973 | Avg: 0.6759\n",
      "Threshold: 0.44 | Accuracy: 0.6605 | Kappa: 0.3229 | F1: 0.6967 | Avg: 0.6786\n",
      "Threshold: 0.45 | Accuracy: 0.6610 | Kappa: 0.3236 | F1: 0.6929 | Avg: 0.6770\n",
      "Threshold: 0.46 | Accuracy: 0.6635 | Kappa: 0.3284 | F1: 0.6909 | Avg: 0.6772\n",
      "Threshold: 0.47 | Accuracy: 0.6625 | Kappa: 0.3261 | F1: 0.6847 | Avg: 0.6736\n",
      "Threshold: 0.48 | Accuracy: 0.6670 | Kappa: 0.3349 | F1: 0.6841 | Avg: 0.6755\n",
      "Threshold: 0.49 | Accuracy: 0.6715 | Kappa: 0.3437 | F1: 0.6846 | Avg: 0.6780\n",
      "Threshold: 0.50 | Accuracy: 0.6850 | Kappa: 0.3704 | F1: 0.6915 | Avg: 0.6882\n",
      "Threshold: 0.51 | Accuracy: 0.6775 | Kappa: 0.3551 | F1: 0.6786 | Avg: 0.6781\n",
      "Threshold: 0.52 | Accuracy: 0.6735 | Kappa: 0.3469 | F1: 0.6687 | Avg: 0.6711\n",
      "Threshold: 0.53 | Accuracy: 0.6745 | Kappa: 0.3487 | F1: 0.6653 | Avg: 0.6699\n",
      "Threshold: 0.54 | Accuracy: 0.6690 | Kappa: 0.3375 | F1: 0.6545 | Avg: 0.6617\n",
      "Threshold: 0.55 | Accuracy: 0.6665 | Kappa: 0.3323 | F1: 0.6473 | Avg: 0.6569\n",
      "Threshold: 0.56 | Accuracy: 0.6675 | Kappa: 0.3341 | F1: 0.6427 | Avg: 0.6551\n",
      "Threshold: 0.57 | Accuracy: 0.6650 | Kappa: 0.3287 | F1: 0.6315 | Avg: 0.6482\n",
      "Threshold: 0.58 | Accuracy: 0.6650 | Kappa: 0.3284 | F1: 0.6223 | Avg: 0.6437\n",
      "Threshold: 0.59 | Accuracy: 0.6615 | Kappa: 0.3212 | F1: 0.6129 | Avg: 0.6372\n"
     ]
    }
   ],
   "source": [
    "prob_bad = probability[:,0]\n",
    "for thr in np.arange(0.4, 0.6, 0.01):\n",
    "    classification = ['Bad' if i > thr else 'Good' for i in prob_bad]\n",
    "    accuracy = accuracy_score(classification, y_test_2)\n",
    "    kappa = cohen_kappa_score(classification, y_test_2)\n",
    "    f1 = f1_score(classification, y_test_2, pos_label='Bad')\n",
    "    avg =np.mean([accuracy, f1])\n",
    "    print('Threshold:', f'{thr:.2f}', '| Accuracy:', f'{accuracy:.4f}', '| Kappa:', f'{kappa:.4f}', '| F1:', f'{f1:.4f}', \n",
    "          '| Avg:', f'{avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
