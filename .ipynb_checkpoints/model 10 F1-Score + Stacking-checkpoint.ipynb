{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials, space_eval\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(clf.predict(X_test), y_test):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Test :', f'{precision_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}', \n",
    "          '| Recall Test :', f'{recall_score(clf.predict(X_test), y_test, pos_label=\"Bad\"):.4f}', \n",
    "          '| H Test :', f'{H_score(clf.predict(X_test), y_test):.4f}')\n",
    "    \n",
    "    print('Accuracy Train:', f'{accuracy_score(clf.predict(X_train), y_train):.4f}', \n",
    "          '| F1 Train:', f'{f1_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Train:', f'{precision_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}', \n",
    "          '| Recall Train:', f'{recall_score(clf.predict(X_train), y_train, pos_label=\"Bad\"):.4f}', \n",
    "          '| H Train:', f'{H_score(clf.predict(X_train), y_train):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_score(X_train, y_train):\n",
    "    acc = accuracy_score(X_train, y_train)\n",
    "    f1 = f1_score(X_train, y_train, pos_label = \"Bad\")\n",
    "    return(2 / ((1/(acc+0.00001))+(1/(f1+0.00001))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian(space, X, y, modelo, nevals):\n",
    "    \n",
    "    f1 = make_scorer(f1_score, pos_label = \"Bad\")\n",
    "    \n",
    "    def objective(space):        \n",
    "        global best_score\n",
    "        model = modelo(**space, random_state = 1)   \n",
    "        cv =  StratifiedKFold(n_splits = 5, random_state = 1)\n",
    "        score = -cross_val_score(model, X, y, cv = cv, scoring = f1, verbose = False).mean()\n",
    "        if (score < best_score):\n",
    "            best_score = score\n",
    "        return score\n",
    "\n",
    "    start = time.time()\n",
    "    rstate = np.random.RandomState(1)\n",
    "    best = fmin(objective, space = space, algo = tpe.suggest, max_evals = nevals,trials = Trials(), rstate = rstate)\n",
    "\n",
    "    print(\"Hyperopt search took %.2f seconds\" % ((time.time() - start)))\n",
    "    print(\"Best score: %.4f \" % (-best_score))\n",
    "    print(\"Best space: \", space_eval(params, best))\n",
    "    return(space_eval(params, best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.read_csv('./data/df_balanced.gz')\n",
    "df_model = df_balanced.sample(n=10000, random_state=1)\n",
    "df_stacking = df_balanced.drop(df_model.index).sample(n=10000, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month','City','Pet','Purpose','Whom','Room_Recode','Nationality_Recode','Length_Recode','Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Close_Landmarks', 'Dist_Center', \n",
    "               'Dist_Train', 'Dist_Airport','food_Neg_Hotel','staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
    "               'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel','cleanliness_Neg_Hotel', \n",
    "               'food_Pos_Hotel', 'staff_Pos_Hotel','location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
    "               'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel','count', 'mean', 'std', 'min', '25%', \n",
    "               '50%', '75%', 'max']\n",
    "\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_stacking[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stacking['Review_Month'] = df_stacking['Review_Month'].astype(str)\n",
    "X_categorical = pd.get_dummies(df_stacking[x_categorical], prefix_sep='_', drop_first=False)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_stacking[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'mean','std', 'max', 'Review_Month_1', \n",
    "       'Review_Month_10', 'Review_Month_2','Review_Month_3', 'Review_Month_4', 'Review_Month_7', 'Review_Month_8',\n",
    "       'Review_Month_9', 'City_Amsterdam', 'City_London', 'Pet_With a pet','Purpose_Leisure trip', \n",
    "       'Whom_Family with older children','Whom_Family with young children', 'Whom_Travelers with friends',\n",
    "       'Room_Recode_Deluxe', 'Room_Recode_Other (Standard)','Room_Recode_Studio', 'Nationality_Recode_Arab States',\n",
    "       'Nationality_Recode_Asia & Pacific','Nationality_Recode_Eastern Europe', 'Nationality_Recode_Middle east',\n",
    "       'Nationality_Recode_North America', 'Nationality_Recode_Oceania','Nationality_Recode_UK & Ireland', \n",
    "       'Nationality_Recode_Western Europe','Length_Recode_Stayed 2 nights', 'Length_Recode_Stayed 5 nights',\n",
    "       'Length_Recode_Stayed 6 nights', 'Length_Recode_Stayed 7 nights','Length_Recode_Stayed 8 nights', 'Stars_Pension',\n",
    "       'Stars_hotel de 3 estrellas']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pickle.load(open('./sav/model_f1.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = [Counter([y.iloc[k] for k in x]).most_common(1)[0][0] for x in models[0].query(X, k = 114)[1]]\n",
    "pred_log = models[1].predict(X)\n",
    "pred_svm = models[2].predict(X)\n",
    "pred_tree = models[3].predict(X)\n",
    "pred_rf = models[4].predict(X)\n",
    "pred_gbt = models[5].predict(X)\n",
    "pred_xgb = models[6].predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['logistic'] = pred_log\n",
    "X['gbt'] = pred_gbt\n",
    "X['knn'] = pred_knn\n",
    "X['svm'] = pred_svm\n",
    "X['tree'] = pred_tree\n",
    "X['xgb'] = pred_xgb\n",
    "X['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>gbt</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "      <th>tree</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231987</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178130</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logistic   gbt   knn   svm  tree   xgb    rf\n",
       "231987      Bad   Bad   Bad   Bad   Bad   Bad   Bad\n",
       "178130     Good  Good  Good  Good  Good  Good  Good"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:,-7:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,-7:] = X.iloc[:,-7:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [02:48<00:00,  3.37s/trial, best loss: -0.6999080416837604]\n",
      "Hyperopt search took 168.80 seconds\n",
      "Best score: 0.6999 \n",
      "Best space:  {'learning_rate': 0.001, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_leaf': 0.11, 'min_samples_split': 0.12, 'n_estimators': 69, 'subsample': 1}\n",
      "Accuracy Test : 0.6085 | F1 Test : 0.6983 | Precision Test : 0.8900 | Recall Test : 0.5745 | H Test : 0.6503\n",
      "Accuracy Train: 0.6132 | F1 Train: 0.7011 | Precision Train: 0.8907 | Recall Train: 0.5780 | H Train: 0.6542\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, \n",
    "                                                          0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.50, 0.75, 1]), \n",
    "          'n_estimators':      hp.choice('n_estimators', range(1,400)),\n",
    "          'max_depth':         hp.choice('max_depth',range(1,20)),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train, y_train, GradientBoostingClassifier, 50)\n",
    "pred_gbt_stck = evaluate_model(GradientBoostingClassifier(**gbt_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 50/50 [08:18<00:00,  9.97s/trial, best loss: -0.669229118889345]\n",
      "Hyperopt search took 498.75 seconds\n",
      "Best score: 0.6692 \n",
      "Best space:  {'colsample_bytree': 0.37, 'gamma': 0.37, 'learning_rate': 0.0075, 'max_depth': 8, 'min_child_weight': 0.72, 'n_estimators': 10}\n",
      "Accuracy Test : 0.6515 | F1 Test : 0.6833 | Precision Test : 0.7387 | Recall Test : 0.6357 | H Test : 0.6670\n",
      "Accuracy Train: 0.6721 | F1 Train: 0.6981 | Precision Train: 0.7444 | Recall Train: 0.6571 | H Train: 0.6849\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':    hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                                         0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', range(1,200))}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train, y_train, xgb.XGBClassifier, 50)\n",
    "pred_xgb_stck = evaluate_model(xgb.XGBClassifier(**xgb_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 10/10 [03:58<00:00, 23.80s/trial, best loss: -0.6935612049703657]\n",
      "Hyperopt search took 238.02 seconds\n",
      "Best score: 0.6936 \n",
      "Best space:  {'C': 0.0005, 'degree': 4, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.5695 | F1 Test : 0.6982 | Precision Test : 0.9784 | Recall Test : 0.5428 | H Test : 0.6273\n",
      "Accuracy Train: 0.5670 | F1 Train: 0.6953 | Precision Train: 0.9705 | Recall Train: 0.5417 | H Train: 0.6247\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train, y_train, SVC, 10)\n",
    "pred_svm_stck = evaluate_model(SVC(**svm_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 50/50 [00:24<00:00,  2.07trial/s, best loss: -0.662091903074624]\n",
      "Hyperopt search took 24.22 seconds\n",
      "Best score: 0.6621 \n",
      "Best space:  {'C': 0.01, 'tol': 0.025}\n",
      "Accuracy Test : 0.6515 | F1 Test : 0.6644 | Precision Test : 0.6778 | Recall Test : 0.6516 | H Test : 0.6579\n",
      "Accuracy Train: 0.6560 | F1 Train: 0.6640 | Precision Train: 0.6676 | Recall Train: 0.6604 | H Train: 0.6600\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]),\n",
    "          \"\"\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, \n",
    "                                  0.05, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train, y_train, LogisticRegression, 50)\n",
    "pred_log_stck = evaluate_model(LogisticRegression(**log_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [02:45<00:00,  3.31s/trial, best loss: -0.6747286789792464]\n",
      "Hyperopt search took 165.69 seconds\n",
      "Best score: 0.6747 \n",
      "Best space:  {'bootstrap': True, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 0.4, 'min_samples_split': 0.8200000000000001, 'n_estimators': 387}\n",
      "Accuracy Test : 0.5090 | F1 Test : 0.6746 | Precision Test : 1.0000 | Recall Test : 0.5090 | H Test : 0.5802\n",
      "Accuracy Train: 0.5091 | F1 Train: 0.6747 | Precision Train: 1.0000 | Recall Train: 0.5091 | H Train: 0.5804\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap':         hp.choice('bootstrap',[True, False]),\n",
    "          'max_depth':         hp.choice('max_depth', range(1, 20)),\n",
    "          'max_features':      hp.choice('max_features',['auto', 'sqrt']),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'n_estimators':      hp.choice('n_estimators',range(1,400))}\n",
    "\n",
    "best_score = 1\n",
    "rf_params = bayesian(params, X_train, y_train, RandomForestClassifier, 50)\n",
    "pred_rf_stck = evaluate_model(RandomForestClassifier(**rf_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.5695 | F1 Test : 0.6982 | Precision Test : 0.9784 | Recall Test : 0.5428 | H Test : 0.6273\n",
      "Accuracy Train: 0.5670 | F1 Train: 0.6953 | Precision Train: 0.9705 | Recall Train: 0.5417 | H Train: 0.6247\n"
     ]
    }
   ],
   "source": [
    "svm_params = {'C': 0.0005, 'degree': 4, 'kernel': 'poly'}\n",
    "pred_svm_stck = evaluate_model(SVC(**svm_params), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>996</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>22</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       996   839\n",
       "Good       22   143"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pred_svm_stck, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
