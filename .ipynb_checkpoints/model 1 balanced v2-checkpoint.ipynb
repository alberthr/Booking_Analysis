{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fix the date because when Pandas opens the file it reads it inconrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Date'] = df['Review_Date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Month'] = df.Review_Month.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create from 4 up to 2 categories.\n",
    "We can check the results for the models in this different categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good       244622\n",
       "Average    118854\n",
       "Bad         92901\n",
       "Worse       56093\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -2:\n",
    "        tmp.append('Worse')\n",
    "    elif i < -0.5:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.5:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.5:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Better     215560\n",
       "Average    156602\n",
       "Bad        140308\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.6:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.6:\n",
    "        tmp.append('Better')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    372162\n",
       "Bad     140308\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i >= -0.6:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Categories and UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities = list(df.Nationality_Recode.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced1 = None\n",
    "\n",
    "for i in nationalities:\n",
    "    tmp = df[df.Nationality_Recode == i]\n",
    "    n = 30000\n",
    "    if len(tmp) < 30000:\n",
    "        n = len(tmp)\n",
    "    tmp = tmp.sample(n)\n",
    "    balanced1 = pd.concat([balanced1, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59685, ['Good', 'Bad'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minclass = np.min(balanced1.Diff_Recode.value_counts())\n",
    "classes = list(balanced1.Diff_Recode.value_counts().index)\n",
    "minclass, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced2 = None\n",
    "\n",
    "for i in classes:\n",
    "    tmp = balanced1[balanced1.Diff_Recode == i].sample(minclass)\n",
    "    balanced2 = pd.concat([balanced2, tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = balanced2.sample(n=50000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'Diff_Recode'\n",
    "x_col = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode',\n",
    "         'Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[x_col]\n",
    "y = df2[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode',\n",
       "       'Nationality_Recode', 'Length_Recode', 'Average_Score',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.fillna('Not Available')\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal = X[['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_dummy = pd.get_dummies(X[['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode',\n",
    "       'Nationality_Recode', 'Length_Recode']], prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_normal, X_dummy], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 50), (10000,), (40000, 50), (40000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours: 6 | Accuracy: 0.537 | Kappa: 0.076 | F1-Score: 0.595 | Precision: 0.688 | Recall: 0.524 |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "for i in range(6,7):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_knn = clf.predict(X_train)\n",
    "    pred_knn = clf.predict(X_test)\n",
    "    acc = accuracy_score(pred_knn, y_test)\n",
    "    kap = cohen_kappa_score(pred_knn, y_test)\n",
    "    f1s = f1_score(pred_knn, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred_knn, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred_knn, y_test, pos_label='Bad')\n",
    "    print('Neighbours:', i, '|',\n",
    "          'Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5849, 0.169320930767192)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate=0.01, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "train_gbt = clf.predict(X_train)\n",
    "pred_gbt = clf.predict(X_test)\n",
    "accuracy_score(pred_gbt, y_test), cohen_kappa_score(pred_gbt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5895, 0.17924287844740983)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
    "clf.fit(X_train, y_train)\n",
    "train_rf = clf.predict(X_train)\n",
    "pred_rf = clf.predict(X_test)\n",
    "accuracy_score(pred_rf, y_test), cohen_kappa_score(pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.505 | Kappa: 0.020 | F1-Score: 0.665 | Precision: 0.993 | Recall: 0.500 | Mean: 0.397 | Threshold: 0.30\n",
      "Accuracy: 0.524 | Kappa: 0.057 | F1-Score: 0.669 | Precision: 0.972 | Recall: 0.510 | Mean: 0.416 | Threshold: 0.35\n",
      "Accuracy: 0.540 | Kappa: 0.087 | F1-Score: 0.664 | Precision: 0.920 | Recall: 0.520 | Mean: 0.430 | Threshold: 0.40\n",
      "Accuracy: 0.567 | Kappa: 0.138 | F1-Score: 0.652 | Precision: 0.820 | Recall: 0.541 | Mean: 0.452 | Threshold: 0.45\n",
      "Accuracy: 0.590 | Kappa: 0.180 | F1-Score: 0.595 | Precision: 0.610 | Recall: 0.581 | Mean: 0.455 | Threshold: 0.50\n",
      "Accuracy: 0.570 | Kappa: 0.136 | F1-Score: 0.438 | Precision: 0.339 | Recall: 0.620 | Mean: 0.382 | Threshold: 0.55\n"
     ]
    }
   ],
   "source": [
    "mat = clf.predict_proba(X_test)\n",
    "\n",
    "for threshold in np.arange(0.30, 0.55, 0.05):\n",
    "    pred_rf = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred_rf, y_test)\n",
    "    kap = cohen_kappa_score(pred_rf, y_test)\n",
    "    f1s = f1_score(pred_rf, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred_rf, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred_rf, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5496, 0.0993167285519797)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 3000)\n",
    "clf.fit(X_train, y_train)\n",
    "train_xgb = clf.predict(X_train)\n",
    "pred_xgb = clf.predict(X_test)\n",
    "accuracy_score(pred_xgb, y_test), cohen_kappa_score(pred_xgb, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59  |  Kappa: 0.1797  |  F1-Score: 0.5814  |  Precision: 0.5756  |  Recall: 0.5873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "train_log = clf.predict(X_train)\n",
    "pred_log = clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(pred_log, y_test), ' | ',\n",
    "      'Kappa:',round(cohen_kappa_score(pred_log, y_test),4), ' | ',\n",
    "      'F1-Score:',round(f1_score(pred_log, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Precision:',round(precision_score(pred_log, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Recall:',round(recall_score(pred_log, y_test, pos_label='Bad'),4)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.507 | Kappa: 0.024 | F1-Score: 0.665 | Precision: 0.987 | Recall: 0.501 | Mean: 0.398 | Threshold: 0.30\n",
      "Accuracy: 0.533 | Kappa: 0.074 | F1-Score: 0.668 | Precision: 0.951 | Recall: 0.515 | Mean: 0.425 | Threshold: 0.35\n",
      "Accuracy: 0.558 | Kappa: 0.121 | F1-Score: 0.657 | Precision: 0.858 | Recall: 0.533 | Mean: 0.445 | Threshold: 0.40\n",
      "Accuracy: 0.585 | Kappa: 0.171 | F1-Score: 0.634 | Precision: 0.726 | Recall: 0.562 | Mean: 0.463 | Threshold: 0.45\n",
      "Accuracy: 0.590 | Kappa: 0.180 | F1-Score: 0.581 | Precision: 0.576 | Recall: 0.587 | Mean: 0.450 | Threshold: 0.50\n",
      "Accuracy: 0.580 | Kappa: 0.156 | F1-Score: 0.489 | Precision: 0.407 | Recall: 0.613 | Mean: 0.408 | Threshold: 0.55\n"
     ]
    }
   ],
   "source": [
    "mat = clf.predict_proba(X_test)\n",
    "\n",
    "for threshold in np.arange(0.30, 0.55, 0.05):\n",
    "    pred_log = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred_log, y_test)\n",
    "    kap = cohen_kappa_score(pred_log, y_test)\n",
    "    f1s = f1_score(pred_log, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred_log, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred_log, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "predictors = X_train.to_numpy()\n",
    "df_target = [1 if i=='Good' else 0 for i in y_train]\n",
    "target = to_categorical(df_target)\n",
    "pred_data = X_test.to_numpy()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15990dbb4e0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(predictors, target, epochs=20, validation_split=0.3, callbacks=[early_stopping_monitor], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5605 | Kappa: 0.1246 | F1: 0.6296\n"
     ]
    }
   ],
   "source": [
    "predictions_test = list(model.predict(pred_data)[:,1])\n",
    "predictions_train = list(model.predict(predictors)[:,1])\n",
    "pred_net = ['Good' if round(i) else 'Bad' for i in predictions_test]\n",
    "train_net = ['Good' if round(i) else 'Bad' for i in predictions_train]\n",
    "print('Accuracy:',accuracy_score(pred_net, y_test), '|', \n",
    "      'Kappa:', round(cohen_kappa_score(pred_net,y_test),4), '|', \n",
    "      'F1:',round(f1_score(pred_net, y_test, pos_label='Bad'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>nnet</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  logistic   knn  xgb   gbt nnet   rf\n",
       "0      Bad  Good  Bad   Bad  Bad  Bad\n",
       "1      Bad   Bad  Bad  Good  Bad  Bad\n",
       "2      Bad   Bad  Bad  Good  Bad  Bad\n",
       "3      Bad  Good  Bad   Bad  Bad  Bad\n",
       "4      Bad   Bad  Bad   Bad  Bad  Bad"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(pred_log, pred_knn, pred_xgb, pred_gbt, pred_net, pred_rf)), \n",
    "                         columns=['logistic','knn','xgb','gbt','nnet','rf']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>knn</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gbt</th>\n",
       "      <th>nnet</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  logistic   knn   xgb   gbt  nnet    rf\n",
       "0     Good  Good  Good  Good  Good  Good\n",
       "1     Good   Bad   Bad  Good   Bad  Good\n",
       "2     Good  Good  Good  Good  Good  Good\n",
       "3     Good  Good  Good  Good  Good  Good\n",
       "4      Bad   Bad   Bad   Bad   Bad   Bad"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_train = pd.DataFrame(list(zip(train_log, train_knn, train_xgb, train_gbt, train_net, train_rf)), \n",
    "                         columns=['logistic','knn','xgb','gbt','nnet','rf']) \n",
    "df_models_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5849, 0.169320930767192)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate=0.01, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_gbt = clf.predict(X_test)\n",
    "accuracy_score(pred_gbt, y_test), cohen_kappa_score(pred_gbt, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5496, 0.0993167285519797)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
    "clf.fit(X_train_2, y_train)\n",
    "train_rf = clf.predict(X_train_2)\n",
    "pred_rf = clf.predict(X_test_2)\n",
    "accuracy_score(pred_rf, y_test), cohen_kappa_score(pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5496  |  Kappa: 0.0993  |  F1-Score: 0.5499  |  Precision: 0.5562  |  Recall: 0.5437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train_2, y_train)\n",
    "train_log = clf.predict(X_train_2)\n",
    "pred_log = clf.predict(X_test_2)\n",
    "print('Accuracy:', accuracy_score(pred_log, y_test), ' | ',\n",
    "      'Kappa:',round(cohen_kappa_score(pred_log, y_test),4), ' | ',\n",
    "      'F1-Score:',round(f1_score(pred_log, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Precision:',round(precision_score(pred_log, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Recall:',round(recall_score(pred_log, y_test, pos_label='Bad'),4)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
