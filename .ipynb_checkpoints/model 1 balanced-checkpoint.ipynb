{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fix the date because when Pandas opens the file it reads it inconrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Date'] = df['Review_Date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Month'] = df.Review_Month.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create from 4 up to 2 categories.\n",
    "We can check the results for the models in this different categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good       244622\n",
       "Average    118854\n",
       "Bad         92901\n",
       "Worse       56093\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -2:\n",
    "        tmp.append('Worse')\n",
    "    elif i < -0.5:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.5:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.5:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Better     215560\n",
       "Average    156602\n",
       "Bad        140308\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i < 0.6:\n",
    "        tmp.append('Average')\n",
    "    elif i >= 0.6:\n",
    "        tmp.append('Better')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    372162\n",
       "Bad     140308\n",
       "Name: Diff_Recode, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df.Diff:\n",
    "    if i < -0.6:\n",
    "        tmp.append('Bad')\n",
    "    elif i >= -0.6:\n",
    "        tmp.append('Good')\n",
    "\n",
    "df['Diff_Recode'] = tmp\n",
    "df.Diff_Recode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Categories and UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities = list(df.Nationality_Recode.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced1 = None\n",
    "\n",
    "for i in nationalities:\n",
    "    tmp = df[df.Nationality_Recode == i]\n",
    "    n = 30000\n",
    "    if len(tmp) < 30000:\n",
    "        n = len(tmp)\n",
    "    tmp = tmp.sample(n)\n",
    "    balanced1 = pd.concat([balanced1, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59691, ['Good', 'Bad'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minclass = np.min(balanced1.Diff_Recode.value_counts())\n",
    "classes = list(balanced1.Diff_Recode.value_counts().index)\n",
    "minclass, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced2 = None\n",
    "\n",
    "for i in classes:\n",
    "    tmp = balanced1[balanced1.Diff_Recode == i].sample(minclass)\n",
    "    balanced2 = pd.concat([balanced2, tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = balanced2.sample(n=50000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'Diff_Recode'\n",
    "x_col = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode',\n",
    "         'Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[x_col]\n",
    "y = df2[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode',\n",
       "       'Nationality_Recode', 'Length_Recode', 'Average_Score',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.fillna('Not Available')\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal = X[['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given', 'Distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_dummy = pd.get_dummies(X[['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode',\n",
    "       'Nationality_Recode', 'Length_Recode']], prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_normal, X_dummy], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 50), (10000,), (40000, 50), (40000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours: 1 | Accuracy: 0.522 | Kappa: 0.045 | F1-Score: 0.520 | Precision: 0.517 | Recall: 0.524 |\n",
      "Neighbours: 2 | Accuracy: 0.515 | Kappa: 0.029 | F1-Score: 0.611 | Precision: 0.761 | Recall: 0.511 |\n",
      "Neighbours: 3 | Accuracy: 0.523 | Kappa: 0.047 | F1-Score: 0.522 | Precision: 0.519 | Recall: 0.525 |\n",
      "Neighbours: 4 | Accuracy: 0.527 | Kappa: 0.054 | F1-Score: 0.597 | Precision: 0.700 | Recall: 0.521 |\n",
      "Neighbours: 5 | Accuracy: 0.532 | Kappa: 0.065 | F1-Score: 0.531 | Precision: 0.527 | Recall: 0.534 |\n",
      "Neighbours: 6 | Accuracy: 0.524 | Kappa: 0.048 | F1-Score: 0.581 | Precision: 0.658 | Recall: 0.520 |\n",
      "Neighbours: 7 | Accuracy: 0.532 | Kappa: 0.064 | F1-Score: 0.529 | Precision: 0.524 | Recall: 0.534 |\n",
      "Neighbours: 8 | Accuracy: 0.536 | Kappa: 0.072 | F1-Score: 0.582 | Precision: 0.644 | Recall: 0.531 |\n",
      "Neighbours: 9 | Accuracy: 0.536 | Kappa: 0.072 | F1-Score: 0.530 | Precision: 0.523 | Recall: 0.538 |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    print('Neighbours:', i, '|',\n",
    "          'Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5857, 0.17144255471039005)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate=0.01, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5851, 0.17022588895226465)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.508 | Kappa: 0.015 | F1-Score: 0.670 | Precision: 0.996 | Recall: 0.505 | Mean: 0.398 | Threshold: 0.30\n",
      "Accuracy: 0.509 | Kappa: 0.017 | F1-Score: 0.670 | Precision: 0.992 | Recall: 0.505 | Mean: 0.399 | Threshold: 0.31\n",
      "Accuracy: 0.512 | Kappa: 0.023 | F1-Score: 0.671 | Precision: 0.990 | Recall: 0.507 | Mean: 0.402 | Threshold: 0.32\n",
      "Accuracy: 0.515 | Kappa: 0.028 | F1-Score: 0.671 | Precision: 0.986 | Recall: 0.508 | Mean: 0.405 | Threshold: 0.33\n",
      "Accuracy: 0.518 | Kappa: 0.034 | F1-Score: 0.671 | Precision: 0.982 | Recall: 0.510 | Mean: 0.408 | Threshold: 0.34\n",
      "Accuracy: 0.521 | Kappa: 0.040 | F1-Score: 0.672 | Precision: 0.977 | Recall: 0.512 | Mean: 0.411 | Threshold: 0.35\n",
      "Accuracy: 0.525 | Kappa: 0.048 | F1-Score: 0.672 | Precision: 0.973 | Recall: 0.514 | Mean: 0.415 | Threshold: 0.36\n",
      "Accuracy: 0.529 | Kappa: 0.056 | F1-Score: 0.673 | Precision: 0.967 | Recall: 0.516 | Mean: 0.419 | Threshold: 0.37\n",
      "Accuracy: 0.534 | Kappa: 0.066 | F1-Score: 0.673 | Precision: 0.959 | Recall: 0.519 | Mean: 0.424 | Threshold: 0.38\n",
      "Accuracy: 0.542 | Kappa: 0.082 | F1-Score: 0.675 | Precision: 0.950 | Recall: 0.524 | Mean: 0.433 | Threshold: 0.39\n",
      "Accuracy: 0.547 | Kappa: 0.093 | F1-Score: 0.674 | Precision: 0.933 | Recall: 0.527 | Mean: 0.438 | Threshold: 0.40\n",
      "Accuracy: 0.552 | Kappa: 0.103 | F1-Score: 0.672 | Precision: 0.913 | Recall: 0.531 | Mean: 0.442 | Threshold: 0.41\n",
      "Accuracy: 0.558 | Kappa: 0.114 | F1-Score: 0.669 | Precision: 0.890 | Recall: 0.535 | Mean: 0.447 | Threshold: 0.42\n",
      "Accuracy: 0.564 | Kappa: 0.127 | F1-Score: 0.666 | Precision: 0.866 | Recall: 0.541 | Mean: 0.452 | Threshold: 0.43\n",
      "Accuracy: 0.568 | Kappa: 0.135 | F1-Score: 0.661 | Precision: 0.841 | Recall: 0.545 | Mean: 0.455 | Threshold: 0.44\n",
      "Accuracy: 0.574 | Kappa: 0.147 | F1-Score: 0.657 | Precision: 0.813 | Recall: 0.551 | Mean: 0.459 | Threshold: 0.45\n",
      "Accuracy: 0.576 | Kappa: 0.152 | F1-Score: 0.647 | Precision: 0.775 | Recall: 0.555 | Mean: 0.458 | Threshold: 0.46\n",
      "Accuracy: 0.581 | Kappa: 0.162 | F1-Score: 0.636 | Precision: 0.731 | Recall: 0.563 | Mean: 0.460 | Threshold: 0.47\n",
      "Accuracy: 0.583 | Kappa: 0.165 | F1-Score: 0.622 | Precision: 0.685 | Recall: 0.569 | Mean: 0.456 | Threshold: 0.48\n",
      "Accuracy: 0.584 | Kappa: 0.168 | F1-Score: 0.605 | Precision: 0.635 | Recall: 0.577 | Mean: 0.452 | Threshold: 0.49\n",
      "Accuracy: 0.585 | Kappa: 0.170 | F1-Score: 0.583 | Precision: 0.578 | Recall: 0.587 | Mean: 0.446 | Threshold: 0.50\n",
      "Accuracy: 0.584 | Kappa: 0.167 | F1-Score: 0.554 | Precision: 0.515 | Recall: 0.598 | Mean: 0.435 | Threshold: 0.51\n",
      "Accuracy: 0.578 | Kappa: 0.157 | F1-Score: 0.519 | Precision: 0.454 | Recall: 0.605 | Mean: 0.418 | Threshold: 0.52\n",
      "Accuracy: 0.573 | Kappa: 0.148 | F1-Score: 0.486 | Precision: 0.402 | Recall: 0.614 | Mean: 0.402 | Threshold: 0.53\n",
      "Accuracy: 0.567 | Kappa: 0.136 | F1-Score: 0.448 | Precision: 0.350 | Recall: 0.621 | Mean: 0.384 | Threshold: 0.54\n",
      "Accuracy: 0.559 | Kappa: 0.119 | F1-Score: 0.411 | Precision: 0.306 | Recall: 0.622 | Mean: 0.363 | Threshold: 0.55\n"
     ]
    }
   ],
   "source": [
    "mat = clf.predict_proba(X_test)\n",
    "\n",
    "for threshold in np.arange(0.30, 0.55, 0.01):\n",
    "    pred = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5455, 0.09102843263062732)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 3000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test), cohen_kappa_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5852  |  Kappa: 0.1705  |  F1-Score: 0.5721  |  Precision: 0.5533  |  Recall: 0.5923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(pred, y_test), ' | ',\n",
    "      'Kappa:',round(cohen_kappa_score(pred, y_test),4), ' | ',\n",
    "      'F1-Score:',round(f1_score(pred, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Precision:',round(precision_score(pred, y_test, pos_label='Bad'),4), ' | ',\n",
    "      'Recall:',round(recall_score(pred, y_test, pos_label='Bad'),4)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.513 | Kappa: 0.024 | F1-Score: 0.671 | Precision: 0.990 | Recall: 0.507 | Mean: 0.403 | Threshold: 0.300\n",
      "Accuracy: 0.516 | Kappa: 0.029 | F1-Score: 0.671 | Precision: 0.984 | Recall: 0.509 | Mean: 0.405 | Threshold: 0.310\n",
      "Accuracy: 0.520 | Kappa: 0.038 | F1-Score: 0.672 | Precision: 0.979 | Recall: 0.511 | Mean: 0.410 | Threshold: 0.320\n",
      "Accuracy: 0.526 | Kappa: 0.050 | F1-Score: 0.673 | Precision: 0.974 | Recall: 0.514 | Mean: 0.417 | Threshold: 0.330\n",
      "Accuracy: 0.531 | Kappa: 0.060 | F1-Score: 0.674 | Precision: 0.966 | Recall: 0.517 | Mean: 0.421 | Threshold: 0.340\n",
      "Accuracy: 0.537 | Kappa: 0.073 | F1-Score: 0.675 | Precision: 0.957 | Recall: 0.521 | Mean: 0.428 | Threshold: 0.350\n",
      "Accuracy: 0.543 | Kappa: 0.085 | F1-Score: 0.674 | Precision: 0.944 | Recall: 0.525 | Mean: 0.434 | Threshold: 0.360\n",
      "Accuracy: 0.549 | Kappa: 0.096 | F1-Score: 0.674 | Precision: 0.930 | Recall: 0.528 | Mean: 0.440 | Threshold: 0.370\n",
      "Accuracy: 0.554 | Kappa: 0.106 | F1-Score: 0.671 | Precision: 0.910 | Recall: 0.532 | Mean: 0.444 | Threshold: 0.380\n",
      "Accuracy: 0.562 | Kappa: 0.123 | F1-Score: 0.671 | Precision: 0.890 | Recall: 0.538 | Mean: 0.452 | Threshold: 0.390\n",
      "Accuracy: 0.565 | Kappa: 0.128 | F1-Score: 0.666 | Precision: 0.867 | Recall: 0.541 | Mean: 0.453 | Threshold: 0.400\n",
      "Accuracy: 0.568 | Kappa: 0.135 | F1-Score: 0.661 | Precision: 0.841 | Recall: 0.545 | Mean: 0.455 | Threshold: 0.410\n",
      "Accuracy: 0.573 | Kappa: 0.146 | F1-Score: 0.657 | Precision: 0.814 | Recall: 0.550 | Mean: 0.459 | Threshold: 0.420\n",
      "Accuracy: 0.577 | Kappa: 0.154 | F1-Score: 0.650 | Precision: 0.784 | Recall: 0.555 | Mean: 0.460 | Threshold: 0.430\n",
      "Accuracy: 0.580 | Kappa: 0.158 | F1-Score: 0.643 | Precision: 0.755 | Recall: 0.560 | Mean: 0.460 | Threshold: 0.440\n",
      "Accuracy: 0.581 | Kappa: 0.161 | F1-Score: 0.634 | Precision: 0.723 | Recall: 0.564 | Mean: 0.459 | Threshold: 0.450\n",
      "Accuracy: 0.584 | Kappa: 0.168 | F1-Score: 0.625 | Precision: 0.692 | Recall: 0.570 | Mean: 0.459 | Threshold: 0.460\n",
      "Accuracy: 0.584 | Kappa: 0.167 | F1-Score: 0.613 | Precision: 0.657 | Recall: 0.574 | Mean: 0.455 | Threshold: 0.470\n",
      "Accuracy: 0.587 | Kappa: 0.173 | F1-Score: 0.603 | Precision: 0.626 | Recall: 0.582 | Mean: 0.454 | Threshold: 0.480\n",
      "Accuracy: 0.587 | Kappa: 0.175 | F1-Score: 0.589 | Precision: 0.591 | Recall: 0.588 | Mean: 0.451 | Threshold: 0.490\n",
      "Accuracy: 0.585 | Kappa: 0.171 | F1-Score: 0.572 | Precision: 0.553 | Recall: 0.592 | Mean: 0.443 | Threshold: 0.500\n",
      "Accuracy: 0.583 | Kappa: 0.167 | F1-Score: 0.556 | Precision: 0.520 | Recall: 0.597 | Mean: 0.435 | Threshold: 0.510\n",
      "Accuracy: 0.579 | Kappa: 0.158 | F1-Score: 0.533 | Precision: 0.479 | Recall: 0.600 | Mean: 0.423 | Threshold: 0.520\n",
      "Accuracy: 0.578 | Kappa: 0.156 | F1-Score: 0.515 | Precision: 0.447 | Recall: 0.607 | Mean: 0.416 | Threshold: 0.530\n",
      "Accuracy: 0.574 | Kappa: 0.149 | F1-Score: 0.493 | Precision: 0.413 | Recall: 0.611 | Mean: 0.405 | Threshold: 0.540\n",
      "Accuracy: 0.570 | Kappa: 0.141 | F1-Score: 0.470 | Precision: 0.380 | Recall: 0.615 | Mean: 0.394 | Threshold: 0.550\n"
     ]
    }
   ],
   "source": [
    "mat = clf.predict_proba(X_test)\n",
    "\n",
    "for threshold in np.arange(0.30, 0.55, 0.01):\n",
    "    pred = np.array(['Bad' if i > threshold else 'Good' for i in mat[:,0]])\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    kap = cohen_kappa_score(pred, y_test)\n",
    "    f1s = f1_score(pred, y_test, pos_label='Bad')\n",
    "    pre = precision_score(pred, y_test, pos_label='Bad')\n",
    "    rec = recall_score(pred, y_test, pos_label='Bad')\n",
    "    mea = (acc + kap + f1s) / 3\n",
    "    print('Accuracy:', f'{acc:.3f}', '|',\n",
    "          'Kappa:', f'{kap:.3f}', '|',\n",
    "          'F1-Score:', f'{f1s:.3f}', '|',\n",
    "          'Precision:', f'{pre:.3f}', '|',\n",
    "          'Recall:', f'{rec:.3f}', '|',\n",
    "          'Mean:', f'{mea:.3f}', '|',\n",
    "          'Threshold:', f'{threshold:.2f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "predictors = X_train.to_numpy()\n",
    "df_target = [1 if i=='Good' else 0 for i in y_train]\n",
    "target = to_categorical(df_target)\n",
    "pred_data = X_test.to_numpy()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b3ba85cf28>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(predictors, target, epochs=20, validation_split=0.3, callbacks=[early_stopping_monitor], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5667 | Kappa: 0.1338 | F1: 0.5254\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(pred_data)[:,1])\n",
    "pred = ['Good' if round(i) else 'Bad' for i in predictions]\n",
    "print('Accuracy:',accuracy_score(pred, y_test), '|', \n",
    "      'Kappa:', round(cohen_kappa_score(pred,y_test),4), '|', \n",
    "      'F1:',round(f1_score(pred,y_test, pos_label='Bad'),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
