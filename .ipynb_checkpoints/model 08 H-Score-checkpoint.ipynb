{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pickle.load(open('./sav/df_subset.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_subset['Category']\n",
    "X = df_subset[df_subset.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 38), (2000,), (8000, 38), (8000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials, space_eval\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    print_result(clf, X_train, X_test, y_train, y_test)\n",
    "    return(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(clf, X_train, X_test, y_train, y_test):\n",
    "    print('Accuracy Test :', f'{accuracy_score(y_test, clf.predict(X_test)):.4f}', \n",
    "          '| F1 Test :', f'{f1_score(y_test, clf.predict(X_test), pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Test :', f'{precision_score(y_test, clf.predict(X_test), pos_label=\"Bad\"):.4f}', \n",
    "          '| Recall Test :', f'{recall_score(y_test, clf.predict(X_test), pos_label=\"Bad\"):.4f}', \n",
    "          '| H Test :', f'{H_score(y_test, clf.predict(X_test)):.4f}')\n",
    "    \n",
    "    print('Accuracy Train:', f'{accuracy_score(y_test, clf.predict(X_train)):.4f}', \n",
    "          '| F1 Train:', f'{f1_score(y_test, clf.predict(X_train), pos_label=\"Bad\"):.4f}',\n",
    "          '| Precision Train:', f'{precision_score(y_test, clf.predict(X_train), pos_label=\"Bad\"):.4f}', \n",
    "          '| Recall Train:', f'{recall_score(y_test, clf.predict(X_train), pos_label=\"Bad\"):.4f}', \n",
    "          '| H Train:', f'{H_score(y_test, clf.predict(X_train)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_score(X_train, y_train):\n",
    "    acc = accuracy_score(y_train, X_train)\n",
    "    f1 = f1_score(y_train, X_train, pos_label = \"Bad\")\n",
    "    return(2 / ((1/(acc+0.0000001))+(1/(f1+0.0000001))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian(space, X, y, modelo, nevals):\n",
    "    \n",
    "    f1 = make_scorer(f1_score, pos_label = \"Bad\")\n",
    "    H = make_scorer(H_score, greater_is_better=True) \n",
    "    \n",
    "    def objective(space):        \n",
    "        global best_score\n",
    "        model = modelo(**space, random_state = 1)   \n",
    "        cv =  StratifiedKFold(n_splits = 5, random_state = 1)\n",
    "        score = -cross_val_score(model, X, y, cv = cv, scoring = H, verbose = False).mean()\n",
    "        if (score < best_score):\n",
    "            best_score = score\n",
    "        return score\n",
    "\n",
    "    start = time.time()\n",
    "    rstate = np.random.RandomState(1)\n",
    "    best = fmin(objective, space = space,algo = tpe.suggest, max_evals = nevals, trials = Trials(), rstate = rstate)\n",
    "\n",
    "    print(\"Hyperopt search took %.2f seconds\" % ((time.time() - start)))\n",
    "    print(\"Best score: %.4f \" % (-best_score))\n",
    "    print(\"Best space: \", space_eval(params, best))\n",
    "    return(space_eval(params, best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (KDTree Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = KDTree(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_dist, nearest_ind = tree.query(X_test, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = [Counter([y_train.iloc[k] for k in x]).most_common(1)[0][0] for x in nearest_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.6710 | F1 Test : 0.6670 | Precision Test : 0.6590 | Recall Test : 0.6752 | H Test : 0.6690\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Test :', f'{accuracy_score(y_test, pred_knn):.4f}', \n",
    "      '| F1 Test :', f'{f1_score(y_test, pred_knn, pos_label=\"Bad\"):.4f}',\n",
    "      '| Precision Test :', f'{precision_score(y_test, pred_knn, pos_label=\"Bad\"):.4f}', \n",
    "      '| Recall Test :', f'{recall_score(y_test, pred_knn, pos_label=\"Bad\"):.4f}', \n",
    "      '| H Test :', f'{H_score(pred_knn, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [03:45<00:00,  4.51s/trial, best loss: -0.6627245836659625]\n",
      "Hyperopt search took 225.76 seconds\n",
      "Best score: 0.6627 \n",
      "Best space:  {'learning_rate': 0.025, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_leaf': 0.06999999999999999, 'min_samples_split': 0.01, 'n_estimators': 145, 'subsample': 1}\n",
      "Accuracy Test : 0.6660 | F1 Test : 0.6636 | Precision Test : 0.6590 | Recall Test : 0.6684 | H Test : 0.6648\n",
      "Accuracy Train: 0.6691 | F1 Train: 0.6708 | Precision Train: 0.6746 | Recall Train: 0.6671 | H Train: 0.6700\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':     hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, \n",
    "                                                          0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.50, 0.75, 1]), \n",
    "          'n_estimators':      hp.choice('n_estimators', range(1,400)),\n",
    "          'max_depth':         hp.choice('max_depth',range(1,20)),\n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 10, endpoint=True)),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'subsample':         hp.choice('subsample',[1]), \n",
    "          'max_features':      hp.choice('max_features',['sqrt'])}\n",
    "\n",
    "best_score = 1\n",
    "gbt_params = bayesian(params, X_train, y_train, GradientBoostingClassifier, 50)\n",
    "pred_gbt = evaluate_model(GradientBoostingClassifier(**gbt_params, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [03:47<00:00,  4.55s/trial, best loss: -0.658991712956131]\n",
      "Hyperopt search took 227.84 seconds\n",
      "Best score: 0.6590 \n",
      "Best space:  {'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 0.01, 'min_samples_split': 0.12, 'n_estimators': 145}\n",
      "Accuracy Test : 0.6635 | F1 Test : 0.6735 | Precision Test : 0.6940 | Recall Test : 0.6541 | H Test : 0.6684\n",
      "Accuracy Train: 0.6607 | F1 Train: 0.6731 | Precision Train: 0.6988 | Recall Train: 0.6492 | H Train: 0.6669\n"
     ]
    }
   ],
   "source": [
    "params = {'bootstrap':         hp.choice('bootstrap',[True, False]),\n",
    "          'max_depth':         hp.choice('max_depth', range(1, 20)),\n",
    "          'max_features':      hp.choice('max_features',['auto', 'sqrt']),\n",
    "          'min_samples_leaf':  hp.choice('min_samples_leaf',np.linspace(0.01, 0.5, 50, endpoint=True)), \n",
    "          'min_samples_split': hp.choice('min_samples_split',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'n_estimators':      hp.choice('n_estimators',range(1,400))}\n",
    "\n",
    "best_score = 1\n",
    "rf_params = bayesian(params, X_train, y_train, RandomForestClassifier, 50)\n",
    "pred_rf = evaluate_model(RandomForestClassifier(**rf_params, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [12:20<00:00, 14.82s/trial, best loss: -0.665396566636388]\n",
      "Hyperopt search took 741.12 seconds\n",
      "Best score: 0.6654 \n",
      "Best space:  {'colsample_bytree': 0.25, 'gamma': 0.75, 'learning_rate': 0.5, 'max_depth': 1, 'min_child_weight': 0.3, 'n_estimators': 137}\n",
      "Accuracy Test : 0.6635 | F1 Test : 0.6650 | Precision Test : 0.6680 | Recall Test : 0.6620 | H Test : 0.6643\n",
      "Accuracy Train: 0.6680 | F1 Train: 0.6720 | Precision Train: 0.6806 | Recall Train: 0.6637 | H Train: 0.6700\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate':    hp.choice('learning_rate',[0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                                         0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75]), \n",
    "          'max_depth':        hp.choice('max_depth',range(1,20)),\n",
    "          'min_child_weight': hp.choice('min_child_weight',np.linspace(0.01, 1.0, 100, endpoint=True)),\n",
    "          'gamma':            hp.choice('gamma',np.linspace(0.01, 1.0, 100, endpoint=True)), \n",
    "          'colsample_bytree': hp.choice('colsample_bytree',np.linspace(0.0, 1, 101, endpoint=True)), \n",
    "          'n_estimators':     hp.choice('n_estimators', range(1,200))}\n",
    "\n",
    "best_score = 1\n",
    "xgb_params = bayesian(params, X_train, y_train, xgb.XGBClassifier, 50)\n",
    "pred_xgb = evaluate_model(xgb.XGBClassifier(**xgb_params, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:36<00:00,  1.36trial/s, best loss: -0.6646897632806852]\n",
      "Hyperopt search took 36.83 seconds\n",
      "Best score: 0.6647 \n",
      "Best space:  {'C': 0.1, 'tol': 0.1}\n",
      "Accuracy Test : 0.6660 | F1 Test : 0.6599 | Precision Test : 0.6480 | Recall Test : 0.6722 | H Test : 0.6629\n",
      "Accuracy Train: 0.6719 | F1 Train: 0.6706 | Precision Train: 0.6683 | Recall Train: 0.6729 | H Train: 0.6712\n"
     ]
    }
   ],
   "source": [
    "params = {\"C\":   hp.choice('C',[0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1]),\n",
    "          \"\"\n",
    "          \"tol\": hp.choice('tol',[0.00001, 0.000025, 0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, \n",
    "                                  0.05, 0.1])}\n",
    "\n",
    "best_score = 1\n",
    "log_params = bayesian(params, X_train, y_train, LogisticRegression, 50)\n",
    "pred_log = evaluate_model(LogisticRegression(**log_params, max_iter = 1000, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:26<00:00,  1.89trial/s, best loss: -0.6572164935775167]\n",
      "Hyperopt search took 26.63 seconds\n",
      "Best score: 0.6572 \n",
      "Best space:  {'criterion': 'entropy', 'max_depth': 3, 'max_features': 35, 'min_samples_leaf': 135}\n",
      "Accuracy Test : 0.6505 | F1 Test : 0.6881 | Precision Test : 0.7710 | Recall Test : 0.6213 | H Test : 0.6688\n",
      "Accuracy Train: 0.6441 | F1 Train: 0.6831 | Precision Train: 0.7674 | Recall Train: 0.6154 | H Train: 0.6630\n"
     ]
    }
   ],
   "source": [
    "params = {\"max_depth\":        hp.choice('max_depth', range(1, 50)),\n",
    "          \"max_features\":     hp.choice('max_features', range(1, 50)),\n",
    "          \"min_samples_leaf\": hp.choice('min_samples_leaf', range(1, 200)),\n",
    "          \"criterion\":        hp.choice('criterion', [\"gini\", \"entropy\"])}\n",
    "\n",
    "best_score = 1\n",
    "tree_params = bayesian(params, X_train, y_train, DecisionTreeClassifier, 50)\n",
    "pred_tree = evaluate_model(DecisionTreeClassifier(**tree_params, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:36<00:00, 33.63s/trial, best loss: -0.6667940792078737]\n",
      "Hyperopt search took 336.28 seconds\n",
      "Best score: 0.6668 \n",
      "Best space:  {'C': 0.1, 'degree': 2, 'kernel': 'poly'}\n",
      "Accuracy Test : 0.6670 | F1 Test : 0.6804 | Precision Test : 0.7090 | Recall Test : 0.6541 | H Test : 0.6736\n",
      "Accuracy Train: 0.6705 | F1 Train: 0.6875 | Precision Train: 0.7251 | Recall Train: 0.6535 | H Train: 0.6789\n"
     ]
    }
   ],
   "source": [
    "params = {\"degree\": hp.choice('degree', [2, 3, 4]),\n",
    "          \"kernel\": hp.choice('kernel', ['poly']), \n",
    "          \"C\":      hp.choice('C', [0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075, \n",
    "                                    0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75])}\n",
    "best_score = 1\n",
    "svm_params = bayesian(params, X_train, y_train, SVC, 10)\n",
    "pred_svm = evaluate_model(SVC(**svm_params, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [05:41<00:00, 34.13s/trial, best loss: -0.668593050789209]\n",
      "Hyperopt search took 341.30 seconds\n",
      "Best score: 0.6686 \n",
      "Best space:  {'C': 15, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Accuracy Test : 0.6685 | F1 Test : 0.6690 | Precision Test : 0.6700 | Recall Test : 0.6680 | H Test : 0.6687\n",
      "Accuracy Train: 0.6705 | F1 Train: 0.6738 | Precision Train: 0.6811 | Recall Train: 0.6667 | H Train: 0.6722\n"
     ]
    }
   ],
   "source": [
    "params = {'C':      hp.choice('C', [1, 2, 5, 10, 15, 20]), \n",
    "          'gamma':  hp.choice('gamma', [0.0001, 0.001, 0.01, 0.1]),\n",
    "          'kernel': hp.choice('kernel', ['rbf'])}\n",
    "\n",
    "best_score = 1\n",
    "svm_params_2 = bayesian(params, X_train, y_train, SVC, 10)\n",
    "pred_svm_2 = evaluate_model(SVC(**svm_params_2, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [19:07<00:00, 114.80s/trial, best loss: -0.6662835992495494]\n",
      "Hyperopt search took 1148.08 seconds\n",
      "Best score: 0.6663 \n",
      "Best space:  {'cat_features': (5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37), 'iterations': 1825, 'l2_leaf_reg': 5, 'learning_rate': 0.01, 'verbose': False}\n",
      "Accuracy Test : 0.6685 | F1 Test : 0.6643 | Precision Test : 0.6560 | Recall Test : 0.6728 | H Test : 0.6664\n",
      "Accuracy Train: 0.7405 | F1 Train: 0.7428 | Precision Train: 0.7496 | Recall Train: 0.7360 | H Train: 0.7416\n"
     ]
    }
   ],
   "source": [
    "cat_features = [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37]\n",
    "params = {'iterations':        hp.choice('iterations', range(100, 4000, 25)), \n",
    "          'learning_rate':     hp.choice('learning_rate', [0.001, 0.0025, 0.0075, 0.01, 0.025, 0.05, 0.1]),\n",
    "          'l2_leaf_reg':       hp.choice('l2_leaf_reg', range(1, 10)), \n",
    "          'cat_features':      hp.choice('cat_features', [cat_features]), \n",
    "          'verbose':           hp.choice('verbose', [False])}\n",
    "\n",
    "best_score = 1\n",
    "cat_params = bayesian(params, X_train, y_train, CatBoostClassifier, 10)\n",
    "pred_cat = evaluate_model(CatBoostClassifier(**cat_params, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test : 0.6685 | F1 Test : 0.6690 | Precision Test : 0.6700 | Recall Test : 0.6680 | H Test : 0.6687\n",
      "Accuracy Train: 0.6705 | F1 Train: 0.6738 | Precision Train: 0.6811 | Recall Train: 0.6667 | H Train: 0.6722\n"
     ]
    }
   ],
   "source": [
    "svm_params_2 = {'C': 15, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "pred_svm = evaluate_model(SVC(**svm_params_2, random_state=3), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>670</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>330</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category  Bad  Good\n",
       "row_0              \n",
       "Bad       670   333\n",
       "Good      330   667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pred_svm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (tree,\n",
    "          LogisticRegression(**log_params, max_iter = 1000).fit(X_train, y_train),\n",
    "          SVC(**svm_params).fit(X_train, y_train),\n",
    "          SVC(**svm_params_2).fit(X_train, y_train),\n",
    "          DecisionTreeClassifier(**tree_params).fit(X_train, y_train),\n",
    "          RandomForestClassifier(**rf_params).fit(X_train, y_train),\n",
    "          GradientBoostingClassifier(**gbt_params).fit(X_train, y_train),\n",
    "          xgb.XGBClassifier(**xgb_params).fit(X_train, y_train),\n",
    "          CatBoostClassifier(**cat_params).fit(X_train, y_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(models, open('./sav/model_H.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
