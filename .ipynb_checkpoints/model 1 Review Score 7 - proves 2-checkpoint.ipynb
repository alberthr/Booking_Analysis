{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df_features.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the rows without a distance to city center (because in the origin hotel don't have latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Dist_Center'])\n",
    "# df = df.dropna(subset=['Reservation_ADR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predicted Category for final models (2 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hotels = df[['Hotel_Address','Diff']].groupby('Hotel_Address').describe()\n",
    "diff_hotels = diff_hotels.Diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, diff_hotels, on='Hotel_Address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    0.831582\n",
       "Bad     0.168418\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = np.array(['Bad' if i < 7 else 'Good' for i in df.Reviewer_Score])\n",
    "df.loc[:, 'Category'] = category\n",
    "df.Category.value_counts() / len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score',\n",
       "       'days_since_review', 'lat', 'lng', 'Diff', 'Diff_Percentage',\n",
       "       'Review_Month', 'Review_Year', 'Country', 'City', 'Pet', 'Purpose',\n",
       "       'Whom', 'Room', 'Length', 'Device', 'Room_Recode', 'Nationality_Recode',\n",
       "       'Length_Recode', 'Close_Landmarks', 'Dist_Center', 'Dist_Airport',\n",
       "       'Dist_Train', 'Price', 'Stars', 'Length_N', 'Reservation_ADR',\n",
       "       'food_Neg', 'staff_Neg', 'location_Neg', 'value_Neg', 'comfort_Neg',\n",
       "       'room_Neg', 'facilities_Neg', 'cleanliness_Neg', 'food_Pos',\n",
       "       'staff_Pos', 'location_Pos', 'value_Pos', 'comfort_Pos', 'room_Pos',\n",
       "       'facilities_Pos', 'cleanliness_Pos', 'food_Neg_Hotel',\n",
       "       'staff_Neg_Hotel', 'location_Neg_Hotel', 'value_Neg_Hotel',\n",
       "       'comfort_Neg_Hotel', 'room_Neg_Hotel', 'facilities_Neg_Hotel',\n",
       "       'cleanliness_Neg_Hotel', 'food_Pos_Hotel', 'staff_Pos_Hotel',\n",
       "       'location_Pos_Hotel', 'value_Pos_Hotel', 'comfort_Pos_Hotel',\n",
       "       'room_Pos_Hotel', 'facilities_Pos_Hotel', 'cleanliness_Pos_Hotel',\n",
       "       'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Nationalities and / or Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(Balance_Nationality, Balance_Category):\n",
    "    df_balance_country = df.copy()\n",
    "    if Balance_Nationality:\n",
    "        df_balance_country = None\n",
    "        for i in list(df.Nationality_Recode.value_counts().index):\n",
    "            nationality = df[df.Nationality_Recode == i]\n",
    "            n = 20000\n",
    "            if len(nationality) < 20000:\n",
    "                n = len(nationality)\n",
    "            nationality = nationality.sample(n, random_state=1)\n",
    "            df_balance_country = pd.concat([df_balance_country, nationality])\n",
    "    \n",
    "    df_balance_class = df_balance_country.copy()\n",
    "    if Balance_Category:\n",
    "        df_balance_class = None\n",
    "        minclass = np.min(df_balance_country.Category.value_counts())\n",
    "        classes = list(df_balance_country.Category.value_counts().index)\n",
    "        for i in classes:\n",
    "            selected_class = df_balance_country[df_balance_country.Category == i].sample(minclass, random_state=1)\n",
    "            df_balance_class = pd.concat([df_balance_class, selected_class])\n",
    "    \n",
    "    return(df_balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balance_df(Balance_Nationality=True, Balance_Category=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_balanced.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_categorical = ['Review_Month', 'City', 'Pet', 'Purpose', 'Whom', 'Room_Recode', 'Nationality_Recode', 'Length_Recode',\n",
    "                 'Stars']\n",
    "x_numerical = ['Average_Score', 'Total_Number_of_Reviews_Reviewer_Has_Given']\n",
    "x_col = x_categorical + x_numerical\n",
    "y_col = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = df_model[x_numerical]\n",
    "X_numerical_std = X_numerical.apply(lambda x: ((x-np.mean(x)) / np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(df_model[x_categorical], prefix_sep='_', drop_first=True)\n",
    "X_categorical = X_categorical.fillna('Not Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_numerical_std, X_categorical], axis=1, sort=False)\n",
    "y = df_model[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 39), (10000,), (10000, 39), (10000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train = clf.predict(X_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print('Test :', f'{accuracy_score(pred, y_test):.4f}', '|', f'{cohen_kappa_score(pred, y_test):.4f}')\n",
    "    print('Train:', f'{accuracy_score(train, y_train):.4f}', '|', f'{cohen_kappa_score(train, y_train):.4f}')\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : 0.5921 | 0.1844\n",
      "Train: 0.7386 | 0.4770\n"
     ]
    }
   ],
   "source": [
    "pred_knn = evaluate(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gbt = evaluate(GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_rf = evaluate(RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = evaluate(xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_log = evaluate(LogisticRegression(solver='lbfgs', max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tree = evaluate(DecisionTreeClassifier(max_depth=4, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = evaluate(SVC(C=0.5, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb = evaluate(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_models_test = pd.DataFrame(list(zip(y_test, pred_log, pred_knn, pred_xgb, pred_gbt, pred_rf, \n",
    "                                       pred_svm, pred_tree, pred_nb)), \n",
    "                         columns=['TEST','logistic','knn','xgb','gbt','rf','svm', 'tree', 'nb']) \n",
    "df_models_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [('Logistic', LogisticRegression(solver='lbfgs', max_iter=1500, random_state=1)), \n",
    "           ('Random Forest', RandomForestClassifier(n_estimators = 70, max_depth = 5, random_state=1)),\n",
    "           ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 7, max_depth=4, random_state=1)),\n",
    "           ('GBT', GradientBoostingClassifier(learning_rate=0.04, max_depth=3, random_state=1))\n",
    "          ]\n",
    "\n",
    "pred = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "prob = pd.DataFrame(columns=['Logistic','Random Forest','XGB','GBT'])\n",
    "\n",
    "for i in modelos:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_ens = clf.predict(X_train)\n",
    "    pred_ens = clf.predict(X_test)\n",
    "    prob_ens = clf.predict_proba(X_test)\n",
    "\n",
    "    pred[i[0]] = pred_ens\n",
    "    prob[i[0]] = prob_ens[:,0]\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_final = prob.apply(lambda x: np.mean(x), axis=1)\n",
    "prob_final = ['Good' if i < 0.5 else 'Bad' for i in prob_final]\n",
    "print('Probability :',  \n",
    "      f'{accuracy_score(prob_final, y_test):.4f}', '|', \n",
    "      f'{cohen_kappa_score(prob_final, y_test):.4f}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using Random Forest adding the predicions of other models to the original dataset.\n",
    "I had to split the test set in 2 to create the new train/test set, otherwise i fall into overfitting because my original training set is biased vs the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I append the predictions of the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_test.copy()\n",
    "y_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['logistic'] = pred_log\n",
    "X_2['gbt'] = pred_gbt\n",
    "X_2['knn'] = pred_knn\n",
    "X_2['svm'] = pred_svm\n",
    "X_2['tree'] = pred_tree\n",
    "X_2['xgb'] = pred_xgb\n",
    "X_2['nb'] = pred_nb\n",
    "X_2['rf'] = pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.iloc[:,-8:] = X_2.iloc[:,-8:].apply(lambda x: [1 if i=='Good' else 0 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [('Random Forest', RandomForestClassifier(n_estimators = 75, max_depth = 5, random_state=1)), \n",
    "          ('XGB', xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 2, max_depth=4, random_state=1)),\n",
    "          ('GBT', GradientBoostingClassifier(learning_rate=0.005, max_depth=3, random_state=1)),\n",
    "          ('Logistic', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)),\n",
    "          ('SVM', SVC(C=0.5, random_state=1))\n",
    "         ]\n",
    "\n",
    "for i in models:\n",
    "    clf = i[1]\n",
    "    clf.fit(X_train_2, y_train_2)\n",
    "    train_stck_2 = clf.predict(X_train_2)\n",
    "    pred_stck_2 = clf.predict(X_test_2)\n",
    "    print(i[0])\n",
    "    print('Test :',f'{accuracy_score(pred_stck_2, y_test_2):.4f}', '|',f'{cohen_kappa_score(pred_stck_2, y_test_2):.4f}')\n",
    "    print('Train:',f'{accuracy_score(train_stck_2, y_train_2):.4f}', '|',f'{cohen_kappa_score(train_stck_2, y_train_2):.4f}')\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reserva = 0.58\n",
    "Distancia = 0.61\n",
    "Avg.Score = 0.64\n",
    "Hotel = 0.65\n",
    "Describe = 0.65\n",
    "\n",
    "Hotel + Describe = 0.65x\n",
    "Hotel + Distancia = 0.65\n",
    "Hotel + Avg.Score = 0.65\n",
    "Hotel + Reserva = 0.66\n",
    "\n",
    "Describe + Reserva  = 0.66\n",
    "Describe + Distancia = 0.65\n",
    "Describe + Avg.Score = 0.66\n",
    "\n",
    "Avg.Score + Reserva = 0.67\n",
    "Avg.Score + Distancia = 0.64x\n",
    "\n",
    "Describe + Reserva + Hotel = 0.67\n",
    "Avg.Score + Reserva + Hotel = 0.66x\n",
    "Avg.Score + Reserva + Describe = 0.66\n",
    "Avg.Score + Distancia + Hotel = 0.66\n",
    "Reserva + Describe + Distancia  = 0.65x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(variable, X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)    \n",
    "    clf.fit(X_train, y_train)\n",
    "    prediccion = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(prediccion, y_test)\n",
    "    f1 = f1_score(prediccion, y_test, pos_label='Bad')\n",
    "    return(variable, acc_score, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def try_seed(seed, verbose=False):\n",
    "    score = check_model('', X_train_2, X_test_2, y_train_2, y_test_2)[1]\n",
    "    varout = []\n",
    "    varin = list(X_test_2.columns)\n",
    "\n",
    "    for n in range(len(varin)):\n",
    "        max_score = score\n",
    "        max_feature = []\n",
    "        random.seed(seed)\n",
    "        \n",
    "        for i in sample(varin, len(varin)):\n",
    "            var_test = varin.copy()\n",
    "            var_test.remove(i)\n",
    "            X_train_vartest = X_train_2[var_test]\n",
    "            X_test_vartest = X_test_2[var_test]\n",
    "            check = check_model(i, X_train_vartest, X_test_vartest, y_train_2, y_test_2)\n",
    "            if check[1] > max_score:\n",
    "                max_feature = check[0]\n",
    "                max_score = check[1] \n",
    "                varin.remove(max_feature)   \n",
    "                varout.append(max_feature)\n",
    "                if verbose:\n",
    "                    print('{0:0=2d}'.format(n), 'Original Score:', f'{score:.4f}', '| New score:', f'{max_score:.4f}', \n",
    "                          '| Variable to remove:', max_feature)\n",
    "                break\n",
    "\n",
    "        if max_score > score:\n",
    "            score = max_score\n",
    "        else:\n",
    "            print('Seed:',seed, '<-', score)\n",
    "            return(varin, score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "varin = []\n",
    "for seed in range(20):\n",
    "    vartest, score = try_seed(seed)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        varin = vartest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(varin), len(X_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_varin = X_train_2[varin]\n",
    "X_test_varin = X_test_2[varin]\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=1)  \n",
    "clf.fit(X_train_varin, y_train_2)\n",
    "prediction = clf.predict(X_test_varin)\n",
    "probability = clf.predict_proba(X_test_varin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(probability[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(prediction, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{accuracy_score(prediction, y_test_2):.4f}', '<- Accuracy')\n",
    "print(f'{cohen_kappa_score(prediction, y_test_2):.4f}', '<- Kappa')\n",
    "print(f'{f1_score(prediction, y_test_2, pos_label=\"Bad\"):.4f}', '<- F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bad = probability[:,0]\n",
    "for thr in np.arange(0.4, 0.6, 0.01):\n",
    "    classification = ['Bad' if i > thr else 'Good' for i in prob_bad]\n",
    "    accuracy = accuracy_score(classification, y_test_2)\n",
    "    kappa = cohen_kappa_score(classification, y_test_2)\n",
    "    f1 = f1_score(classification, y_test_2, pos_label='Bad')\n",
    "    avg =np.mean([accuracy, f1])\n",
    "    print('Threshold:', f'{thr:.2f}', '| Accuracy:', f'{accuracy:.4f}', '| Kappa:', f'{kappa:.4f}', '| F1:', f'{f1:.4f}', \n",
    "          '| Avg:', f'{avg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
